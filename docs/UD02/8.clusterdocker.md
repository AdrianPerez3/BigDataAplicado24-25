# Configuración de un Clúster Hadoop Pseudo-Distribuido en Docker

Este documento proporciona una guía detallada para configurar un clúster Hadoop en modo pseudo-distribuido utilizando Docker. Al final de esta guía, tendrás un entorno Hadoop completamente funcional en un contenedor Docker, ideal para propósitos de desarrollo y pruebas.

[Preparando la versión 2, con Java 11 y hadoop 3.4.1](<./8.clusterdocker.md>)
## **Tabla de Contenidos**

1. [Introducción](<#introducción>)
2. [Prerrequisitos](<#prerrequisitos>)
3. [Estructura del Proyecto](<#estructura-del-proyecto>)
4. [Configuración de Hadoop](<#configuración-de-hadoop>)
   - 4.1. [core-site.xml](<#core-sitexml>)
   - 4.2. [hdfs-site.xml](<#hdfs-sitexml>)
   - 4.3. [mapred-site.xml](<#mapred-sitexml>)
   - 4.4. [yarn-site.xml](<#yarn-sitexml>)
5. [Archivo Dockerfile](<#archivo-dockerfile>)
6. [Script de Inicio: start-hadoop.sh](<#script-de-inicio-start-hadoopsh>)
7. [Construcción y Ejecución del Contenedor](<#construcción-y-ejecución-del-contenedor>)
   - 7.1. [Construir la Imagen Docker](<#71-construir-la-imagen-docker>)
   - 7.2. [Ejecutar el Contenedor Docker](<#72-ejecutar-el-contenedor-docker>)
8. [Verificación de la Configuración](<#verificación-de-la-configuración>)
   - 8.1. [Comprobar los Procesos de Hadoop](<#81-comprobar-los-procesos-de-hadoop>)
   - 8.2. [Acceder a las Interfaces Web](<#82-acceder-a-las-interfaces-web>)
   - 8.3. [Probar Comandos HDFS](<#83-probar-comandos-hdfs>)
   - 8.4. [Ejecutar un Trabajo de MapReduce](<#84-ejecutar-un-trabajo-de-mapreduce>)
9. [Conclusión](<#conclusión>)
---

## **Introducción**

La configuración de un clúster Hadoop en modo **pseudo-distribuido** permite simular un entorno distribuido en una sola máquina. Utilizando Docker, podemos aislar este entorno, facilitando su gestión y portabilidad.

---

## **Prerrequisitos**

- **Docker** instalado en tu sistema.
- Conocimientos básicos de **Linux** y **Docker**.
- Conexión a Internet para descargar Hadoop y las imágenes base.

---

## **Estructura del Proyecto**

Organiza tu proyecto con la siguiente estructura de directorios y archivos:

```bash
hadoop-pseudo-docker/
├── config/
│   ├── core-site.xml
│   ├── hdfs-site.xml
│   ├── mapred-site.xml
│   └── yarn-site.xml
├── Dockerfile
├── hadoop-3.3.5.tar.gz
└── start-hadoop.sh
```

- **config/**: Directorio que contiene los archivos de configuración de Hadoop.
- **Dockerfile**: Archivo de construcción de la imagen Docker.
- **hadoop-3.3.5.tar.gz**: Archivo comprimido de Hadoop (debe descargarse previamente).
- **start-hadoop.sh**: Script para iniciar los servicios dentro del contenedor.

---

## **Configuración de Hadoop**

Crea los archivos de configuración en el directorio `config/` con el contenido siguiente.

### **core-site.xml**

Configura el sistema de archivos predeterminado.

```xml
<?xml version="1.0"?>
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

### **hdfs-site.xml**

Establece la replicación de datos.

```xml
<?xml version="1.0"?>
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

### **mapred-site.xml**

Define el framework de MapReduce.

```xml
<?xml version="1.0"?>
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

### **yarn-site.xml**

Configura YARN para soportar MapReduce.

```xml
<?xml version="1.0"?>
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

---

## **Archivo Dockerfile**

El `Dockerfile` define cómo se construirá la imagen Docker. A continuación, se presenta el contenido completo:

```dockerfile
# Imagen base
FROM openjdk:8-jdk

# Establecer variables de entorno
ENV HADOOP_VERSION=3.3.5
ENV HADOOP_HOME=/usr/local/hadoop
ENV JAVA_HOME=/usr/local/openjdk-8
ENV PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

# Instalar paquetes necesarios
RUN apt-get update && \
    apt-get install -y openssh-server wget rsync && \
    rm -rf /var/lib/apt/lists/*

# Crear usuario y grupo hadoop
RUN groupadd hadoop && \
    useradd -ms /bin/bash -g hadoop hadoop

# Instalar sudo
RUN apt-get update && apt-get install -y sudo && rm -rf /var/lib/apt/lists/*

# Permitir que el usuario hadoop use sudo sin contraseña
RUN echo "hadoop ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers

# Configurar SSH para el usuario hadoop
RUN mkdir -p /home/hadoop/.ssh && \
    ssh-keygen -t rsa -f /home/hadoop/.ssh/id_rsa -q -N "" && \
    cat /home/hadoop/.ssh/id_rsa.pub >> /home/hadoop/.ssh/authorized_keys && \
    chown -R hadoop:hadoop /home/hadoop/.ssh && \
    chmod 600 /home/hadoop/.ssh/authorized_keys

# Instalar Hadoop
COPY hadoop-3.3.5.tar.gz /tmp/
RUN tar -xzvf /tmp/hadoop-3.3.5.tar.gz -C /usr/local/ && \
    mv /usr/local/hadoop-3.3.5 $HADOOP_HOME && \
    rm /tmp/hadoop-3.3.5.tar.gz && \
    chown -R hadoop:hadoop $HADOOP_HOME

# Configurar variables de entorno de Hadoop
RUN echo "export JAVA_HOME=/usr/local/openjdk-8" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh

# Copiar archivos de configuración
COPY config/* $HADOOP_HOME/etc/hadoop/
RUN chown -R hadoop:hadoop $HADOOP_HOME/etc/hadoop/

# Cambiar al usuario hadoop
USER hadoop

# Formatear HDFS
RUN $HADOOP_HOME/bin/hdfs namenode -format

# Exponer puertos
EXPOSE 9870 8088 9000 8042 22

# Volver al usuario root para copiar el script de inicio
USER root

# Copiar el script de inicio
COPY start-hadoop.sh /start-hadoop.sh
RUN chmod +x /start-hadoop.sh

# Cambiar al usuario hadoop
USER hadoop

# Definir el punto de entrada
CMD ["/start-hadoop.sh"]
```

---

## **Script de Inicio: start-hadoop.sh**

Crea el archivo `start-hadoop.sh` en el directorio raíz de tu proyecto con el siguiente contenido:

```bash
#!/bin/bash

# Iniciar el servicio SSH (requiere privilegios de root)
sudo service ssh start

# Iniciar los servicios de Hadoop
$HADOOP_HOME/sbin/start-dfs.sh
$HADOOP_HOME/sbin/start-yarn.sh

# Mantener el contenedor en ejecución
tail -f /dev/null
```

Concede permisos de ejecución al script:
**¿Hace falta?**
```bash
chmod +x start-hadoop.sh
```

# Construcción y Ejecución del Contenedor

## **7. Construcción y Ejecución del Contenedor**

### **7.1. Construir la Imagen Docker**

Ejecuta el siguiente comando desde el directorio raíz del proyecto para construir la imagen Docker:

```bash
docker build -t hadoop-pseudo .
```

- `-t hadoop-pseudo`: Asigna el nombre `hadoop-pseudo` a la imagen.
- `.`: Especifica el contexto de construcción como el directorio actual.

### **7.2. Ejecutar el Contenedor Docker**

Inicia un contenedor a partir de la imagen creada:

```bash
docker run -it --name hadoop-container \
    -p 9870:9870 \
    -p 8088:8088 \
    -p 9000:9000 \
    -p 8042:8042 \
    hadoop-pseudo
```

- `-it`: Ejecuta el contenedor en modo interactivo.
- `--name hadoop-container`: Asigna el nombre `hadoop-container` al contenedor.
- `-p`: Mapea puertos para permitir el acceso a las interfaces web.

---

## **8. Verificación de la Configuración**

### **8.1. Comprobar los Procesos de Hadoop**

Dentro del contenedor, ejecuta el comando `jps` para verificar los procesos en ejecución:

```bash
jps
```

Deberías obtener una salida similar a:

```
XXXX NameNode
XXXX DataNode
XXXX ResourceManager
XXXX NodeManager
XXXX SecondaryNameNode
XXXX Jps
```

Cada uno de estos procesos representa un componente clave de Hadoop.

### **8.2. Acceder a las Interfaces Web**

Verifica que las interfaces web estén funcionando accediendo a las siguientes URL desde tu navegador:

- **NameNode UI**: [http://localhost:9870](http://localhost:9870)  
  Proporciona información sobre el sistema de archivos distribuido (HDFS).
  
- **ResourceManager UI**: [http://localhost:8088](http://localhost:8088)  
  Muestra información sobre los recursos YARN y las aplicaciones en ejecución.

### **8.3. Probar Comandos HDFS**

Prueba el sistema de archivos HDFS creando un directorio:

```bash
hdfs dfs -mkdir /user/hadoop
hdfs dfs -ls /user
```

Si todo está configurado correctamente, deberías ver el directorio listado sin errores.

### **8.4. Ejecutar un Trabajo de MapReduce**

Ejecuta un ejemplo de cálculo de Pi para probar el framework MapReduce:

```bash
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar pi 2 5
```

Este comando ejecutará un trabajo de MapReduce y mostrará una estimación del valor de Pi.

---

## **9. Conclusión**

Has configurado exitosamente un clúster Hadoop en modo pseudo-distribuido dentro de un contenedor Docker. Este entorno te permite desarrollar y probar aplicaciones Hadoop sin necesidad de un clúster físico distribuido, reduciendo la complejidad.
