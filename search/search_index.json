{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"INICIO","text":""},{"location":"#bigdataaplicado24-25","title":"BigDataAplicado24-25","text":"<p>UD00: Conceptos generales</p> <ol> <li> <p>ConceptosGenerales</p> </li> <li> <p>bash</p> </li> <li> <p>EntornosVirtualesPython</p> </li> </ol> <p>UD01: Hadoop</p> <p>UD02: Cluster Hadoop pseudodistribuido. HDFS.     1. instalacion     2. webdfs</p>"},{"location":"#test","title":"Test","text":"<p>Ejercicios</p> <p>agregar:</p> <ul> <li>admonition</li> <li>pymdownx.details</li> </ul> <p>First, create a directory in your <code>docs</code> directory to hold the event pages:</p> <pre><code>$ mkdir docs/events\n</code></pre> <p>Then, add a file <code>.meta.yml</code> inside this new directory with settings for the page icon and a hot pink background color that will stand out on social media. Note that you can override the background image by setting it to <code>null</code> here since it is not visible anyway because of the opaque coloring.</p> <pre><code>---\nicon: material/calendar-plus\nsocial:\n  cards_layout_options:\n    background_image: null\n    background_color: \"#ff1493\"\n---\n</code></pre> <p>Now add a page within the <code>docs/events</code> directoy. It does not need to have any special content, just a top level header.</p> <p>To turn on the <code>default/variant</code> layout in <code>mkdocs.yml</code>, add the <code>cards_layout</code> option and also add the meta plugin:</p> <pre><code>plugins:\n  - meta\n  - social:\n      cards_layout: default/variant\n</code></pre> <p>After running <code>mkdocs build</code>, you can see that the social card at <code>site/assets/images/social/events/index.png</code> features the page icon.</p> <p>Title</p> <p>Contents</p>"},{"location":"formato/","title":"Formato","text":"<p>\u270f\ufe0f EJERCICIOS</p>"},{"location":"formato/#admonition","title":"Admonition","text":"<p>Title -&gt; Para ejercicios</p> <p>Contents</p> <p>Title -&gt; PENDIENTE</p> <p>Contents</p> <p>Title -&gt; Para ejemplos</p> <p>Contents</p> <p>Title -&gt; Frases</p> <p>Contents</p> <p>Title -&gt; Para errores</p> <p>Contents</p> <p>Title -&gt; Info APP</p> <p>Contents</p> <p>Title</p> <p>Contents</p> <p>Title -&gt; Algo m\u00e1s de informaci\u00f3n</p> <p>Contents</p> <p>Title</p> <p>Contents</p> <p>Title</p> <p>Contents</p> <p>Title</p> <p>Contents</p> <p>Title</p> <p>Contents</p> <p>Title</p> <p>Contents</p>"},{"location":"UD00/1.ConceptosGenerales/","title":"Conceptos Generales","text":""},{"location":"UD00/1.ConceptosGenerales/#imprescindibles","title":"Imprescindibles","text":"<ul> <li> <p>C\u00f3mo utilizar Virtualbox</p> </li> <li> <p>Terminal Linux</p> </li> </ul>"},{"location":"UD00/1.ConceptosGenerales/#discos-duros","title":"Discos Duros","text":"<p>Tipos de discos duros</p> <ul> <li>HDD (Hard Drive Disk): Mec\u00e1nicos</li> <li>Unidad de estado s\u00f3lido o SSD<ul> <li>Conexi\u00f3n SATA o PCIe</li> <li>Conexi\u00f3n NVME m.2</li> </ul> </li> </ul> <p> </p>"},{"location":"UD00/1.ConceptosGenerales/#particiones","title":"Particiones","text":"<p>Una partici\u00f3n</p> <p></p> <p>Varias particiones</p> <p></p> <p>Tipos de particiones  Independientemente del sistema de archivos de una partici\u00f3n (FAT, NTFS, ext3, ext4, etc.), si se habla de un disco duro que use MBR, existen 3 tipos diferentes de particiones:</p> <p>Partici\u00f3n primaria. Son las divisiones primarias del disco. En un disco duro, pueden existir de una a cuatro particiones primarias o hasta tres primarias y una extendida. Depende de una tabla de particiones. Un disco duro f\u00edsico completamente formateado (por ejemplo, una unidad de disco duro externa USB nueva) consiste, en realidad, en una partici\u00f3n primaria que ocupa todo el espacio del disco y posee un sistema de archivos. Pr\u00e1cticamente, cualquier sistema operativo puede detectar este tipo de particiones primarias, y asignarles una unidad, siempre y cuando el sistema operativo reconozca su formato (sistema de archivos).</p> <p>Partici\u00f3n extendida. Tambi\u00e9n conocida como partici\u00f3n secundaria, es otro tipo de partici\u00f3n que act\u00faa como una partici\u00f3n primaria; sirve para contener m\u00faltiples unidades l\u00f3gicas en su interior. Fue ideada para romper la limitaci\u00f3n de 4 particiones primarias en un solo disco f\u00edsico. Solo puede existir una partici\u00f3n de este tipo por disco, y solo sirve para contener particiones l\u00f3gicas. Por lo tanto, es el \u00fanico tipo de partici\u00f3n que no soporta un sistema de archivos directamente.</p> <p>Partici\u00f3n l\u00f3gica. Ocupa una porci\u00f3n de la partici\u00f3n extendida o la totalidad de la misma, y se ha formateado con un tipo espec\u00edfico de sistema de archivos (FAT32, NTFS, ext3, ext4, etc.) y se le ha asignado una unidad, as\u00ed el sistema operativo reconoce las particiones l\u00f3gicas o su sistema de archivos. Se pueden tener un m\u00e1ximo de 23 particiones l\u00f3gicas en una partici\u00f3n extendida. Aunque algunos sistemas operativos pueden ser m\u00e1s restrictivos, como Linux que impone un m\u00e1ximo de 15, incluyendo las 4 primarias, en discos SCSI y en discos IDE 8963.</p> <p>El n\u00famero de particiones que puede crear en un disco b\u00e1sico depende del estilo de partici\u00f3n del disco:</p> <ul> <li>En los discos con registro de inicio maestro (MBR) se pueden crear hasta cuatro particiones primarias por disco o bien se pueden crear hasta tres particiones primarias y una partici\u00f3n extendida. Dentro de la partici\u00f3n extendida se pueden crear un n\u00famero ilimitado de unidades l\u00f3gicas.</li> <li>En los discos con tabla de particiones GUID (GPT) se pueden crear hasta 128 particiones primarias. Con GPT no existe la limitaci\u00f3n a cuatro particiones primarias por lo que no es necesario crear particiones extendidas ni unidades l\u00f3gicas.</li> </ul>"},{"location":"UD00/1.ConceptosGenerales/#programas-para-realizar-particiones","title":"Programas para realizar particiones","text":"<p>Gparted</p> <p></p> <p>cfdisk (consola) o fdisk</p> <p></p> <p>Gestor de disco Windows</p> <p></p> <p>Utilidad de discos MacOS</p> <p></p>"},{"location":"UD00/1.ConceptosGenerales/#sistemas-de-archivos","title":"Sistemas de archivos","text":"<p>Un sistema de archivos indexa toda la informaci\u00f3n de los datos en un dispositivo de almacenamiento, incluyendo el tama\u00f1o del Archivo, los atributos, la ubicaci\u00f3n y la jerarqu\u00eda en el directorio. El sistema de archivos tambi\u00e9n especifica la ruta a un archivo mediante la estructura de directorios con un formato.</p> <ul> <li>Sistema de archivos de Windows\u00a0- FAT, NTFS, exFAT</li> <li>macOS\u00a0- HFS, APFS, HFS+</li> <li>Linux -\u00a0EXT2/3/4, XFS, JFS, Btrfs</li> </ul> <p>Comparativa deferentes sistemas de ficheros.</p>"},{"location":"UD00/1.ConceptosGenerales/#configuracion-red-virtualbox","title":"Configuraci\u00f3n red VirtualBox","text":"VM \u2194 HOST VM1 \u2194 VM2 VM \u2192 INTERNET VM \u2190 INTERNET Solo anfitri\u00f3n SI SI NO NO Interna NO SI NO NO Adaptador puente SI SI SI SI NAT NO NO SI Reenv\u00edo de puertos Red NAT NO SI SI Reenv\u00edo de puertos <p>El modo que nos da m\u00e1s flexibilidad ser\u00eda el adaptador puente, mientras que el resto ser\u00edan m\u00e1s restrictivos.</p> <ul> <li>El adaptador puente hace que la m\u00e1quina virtual se conecte a la misma red que el anfitri\u00f3n, de tal forma que la MV se comportar\u00e1 como si fuera un PC m\u00e1s conectado a la red real. Nos permite conectar entre MV, desde el anfitri\u00f3n, y a Internet bidireccionalmente. Por contra, nos puede ocasionar problemas puesto que estar\u00e1 conectado a la red real (especialmente en caso de montar servidores).</li> <li>En modo solo anfitri\u00f3n podremos conectarnos desde el anfitri\u00f3n a nuestras m\u00e1quinas virtuales y viceversa, as\u00ed como conectar entre m\u00e1quinas virtuales. En todo caso, no tendremos por defecto conexi\u00f3n a internet (ni de salida ni de entrada)</li> <li>El modo NAT ser\u00eda todo lo contrario al modo anterior. Las m\u00e1quinas virtuales tendr\u00edan salida a internet, pero para poder conectar desde internet se tendr\u00edan que mapear puertos mediante NAT. No podr\u00edamos conectarnos entre diferentes m\u00e1quinas virtuales.</li> <li>Para poder conectar tambi\u00e9n entre m\u00e1quinas virtuales existe el modo red NAT, que a\u00f1ade a las caracter\u00edsticas del modo NAT.</li> <li>El modo interno ser\u00eda el m\u00e1s restringido, permitiendo \u00fanicamente conexi\u00f3n entre las m\u00e1quinas virtuales. No podr\u00edamos conectar desde el anfitri\u00f3n a las MV, ni tendr\u00edamos salida a Internet desde las MV.</li> </ul>"},{"location":"UD00/2.bash/","title":"Terminal","text":"<p>La l\u00ednea de comandos de Linux, tambi\u00e9n conocida como terminal o shell, es una herramienta esencial en el mundo de la inform\u00e1tica y la administraci\u00f3n de sistemas. Ofrece un entorno de texto en el que los usuarios pueden interactuar con el sistema operativo mediante comandos escritos en lugar de utilizar una interfaz gr\u00e1fica de usuario.</p> <p>\u00bfPor qu\u00e9 aprender la l\u00ednea de comandos de Linux?</p> <ol> <li>Control Total: La l\u00ednea de comandos proporciona un control preciso sobre el sistema, permiti\u00e9ndote realizar tareas espec\u00edficas con gran flexibilidad.</li> <li>Automatizaci\u00f3n: Automatizar tareas repetitivas mediante scripts, lo que ahorra tiempo y reduce errores.</li> <li>Administraci\u00f3n del Sistema: Gestionar servidores y recursos de manera eficiente.</li> <li>Recuperaci\u00f3n y Resoluci\u00f3n de Problemas: En situaciones de recuperaci\u00f3n de datos o resoluci\u00f3n de problemas, la l\u00ednea de comandos es una herramienta valiosa.</li> </ol> <p>Conceptos B\u00e1sicos:</p> <ul> <li>Comandos: Son instrucciones espec\u00edficas que se ingresan en la l\u00ednea de comandos para realizar tareas, como crear archivos, mover carpetas o mostrar informaci\u00f3n del sistema.</li> <li>Argumentos: Son datos adicionales necesarios para que el comando funcione correctamente.</li> <li>Directorio Actual: Especifica el contexto de trabajo actual.</li> <li>Rutas: Se utilizan para especificar la ubicaci\u00f3n de archivos y directorios en el sistema.</li> </ul> <p>Primeros Pasos:</p> <ol> <li>Abrir la Terminal: En la mayor\u00eda de las distribuciones de Linux, puedes abrir la terminal desde el men\u00fa de aplicaciones o utilizando combinaciones de teclas como \"Ctrl + Alt + T\".</li> <li>Uso de comandos: Utiliza comandos como <code>ls</code> (listar), <code>echo</code> (imprimir por pantalla) y <code>pwd</code> (imprimir directorio de trabajo) para explorar el sistema de archivos.</li> <li>Ayuda y Manuales: <code>man ls</code> muestra el manual para el comando <code>ls</code>.</li> </ol> <pre><code>$ ls\n\n$ pwd\n\n$ echo \"HOLA\"\n\n$ man ls\n\n$ ls -la\n</code></pre> <p>Tipos de shell:</p> <p>Bash (Bourne Again Shell): Es el shell m\u00e1s com\u00fan en Linux y es ampliamente utilizado. Ofrece una amplia gama de caracter\u00edsticas, incluyendo autocompletado de comandos, historial de comandos, y scripts para automatizar tareas.</p> <p>Zsh (Z Shell): Es una extensi\u00f3n de Bash con caracter\u00edsticas adicionales, como sugerencias interactivas y personalizaci\u00f3n avanzada. Se ha vuelto popular entre los usuarios avanzados.</p> <p>Fish es conocido por su facilidad de uso y su sintaxis m\u00e1s intuitiva. Ofrece sugerencias de comandos en tiempo real y es ideal para principiantes.</p>"},{"location":"UD00/2.bash/#11-archivos-carpetas-y-enlaces","title":"1.1. Archivos, carpetas y enlaces","text":"<p>1. Archivos:</p> <ul> <li>Los archivos son unidades b\u00e1sicas de almacenamiento que contienen datos, programas o informaci\u00f3n.</li> <li>Pueden ser de diferentes tipos, como archivos de texto, binarios, de configuraci\u00f3n, etc.</li> <li>Los archivos se identifican por su nombre y extensi\u00f3n (opcional).</li> <li>Algunos comandos: <code>cat</code>, <code>touch</code>, <code>cp</code>, <code>mv</code>, <code>rm</code>, <code>head</code> y <code>tail</code>.</li> <li>Se pueden crear archivos o directorios \u201cocultos\u201d si su nombre empieza por punto (.), ejemplo: .config</li> </ul> <p>2. Carpetas (Directorios):</p> <ul> <li>Las carpetas, tambi\u00e9n llamadas directorios, son contenedores utilizados para organizar y agrupar archivos y otras carpetas.</li> <li>Se utilizan para crear una estructura jer\u00e1rquica en el sistema de archivos.</li> <li>Se utilizan comandos como: <code>mkdir</code>, <code>rmdir</code>, <code>cd</code> y <code>pwd</code>.</li> </ul> <p>3. Carpetas ESPECIALES:</p> <p>Todas las carpetas Linux tienen 2 carpetas \u201cespeciales\u201d en su interior.</p> <ul> <li>Carpeta punto (.) - Hace referencia a la carpeta actual (a ella misma)</li> <li>Carpeta punto punto (..) -  Hace referencia a la carpeta superior (carpeta \u201cpadre\u201d).</li> </ul> <p>4. Enlaces:</p> <ul> <li>Los enlaces son referencias o punteros a archivos o directorios existentes en el sistema de archivos.</li> <li>Hay dos tipos principales de enlaces en sistemas Linux: enlaces duros (hard links) y enlaces simb\u00f3licos (symbolic links o symlinks).</li> <li>Los enlaces duros apuntan al mismo contenido f\u00edsico que el archivo original y no pueden cruzar sistemas de archivos.</li> <li>Los enlaces simb\u00f3licos son m\u00e1s flexibles y pueden apuntar a archivos o directorios en cualquier ubicaci\u00f3n, incluso a trav\u00e9s de sistemas de archivos diferentes.</li> <li>Los enlaces permiten compartir recursos de manera eficiente y mantener la integridad de los datos.</li> </ul>"},{"location":"UD00/2.bash/#11-permisos","title":"1.1. Permisos","text":"<p>En Linux, cada fichero y carpeta tiene tres niveles de permisos: propietario, grupo y otros.</p> <p>El propietario es el usuario que cre\u00f3 el archivo o carpeta, el grupo es un conjunto de usuarios relacionados y \"otros\" incluye a todos los dem\u00e1s usuarios.</p> <p>Tipos:</p> <p>Lectura (r): Permite ver el contenido del archivo o listar el contenido de una carpeta.</p> <p>Escritura (w): Permite modificar o eliminar el archivo o carpeta.</p> <p>Ejecuci\u00f3n (x): Permite ejecutar un archivo o acceder a una carpeta.</p> <p>Representaci\u00f3n:</p> <p>Los permisos se representan con una cadena de nueve caracteres: rwxrwxrwx.</p> <p>Los primeros tres caracteres representan los permisos del propietario, los siguientes tres del grupo y los \u00faltimos tres para otros.</p> <p></p> <p></p> <p></p> <p>Permisos especiales</p> <ul> <li>Algunos archivos y carpetas tienen permisos especiales, como el bit SUID (Set User ID), que permite a un usuario ejecutar el archivo con los privilegios del propietario.</li> <li>El bit SGID (Set Group ID) hace que los archivos se ejecuten con los privilegios del grupo.</li> <li>El bit sticky (t) evita que otros usuarios eliminen o modifiquen archivos en una carpeta, a menos que sean propietarios o tengan permisos especiales.</li> </ul>"},{"location":"UD00/2.bash/#12-carpetas-del-sistema","title":"1.2. Carpetas del sistema","text":"<p>Estas carpetas son fundamentales para la organizaci\u00f3n y el funcionamiento del sistema. Dependiendo del Linux instalado algunas podr\u00edan no existir.</p> <ol> <li>/root:<ul> <li>Es el directorio de inicio del superusuario (root) y contiene los archivos de configuraci\u00f3n y datos del superusuario.</li> </ul> </li> <li>/home:<ul> <li>Contiene directorios personales de los usuarios regulares. Cada usuario tiene su propia carpeta con su nombre de usuario, donde pueden almacenar sus archivos y configuraciones personales.</li> </ul> </li> <li>/etc:<ul> <li>Archivos de configuraci\u00f3n del sistema y de aplicaciones. Aqu\u00ed se encuentran configuraciones importantes como /etc/passwd (informaci\u00f3n de usuarios), /etc/fstab (tablas de montaje de dispositivos), y muchos otros.</li> </ul> </li> <li>/bin y /sbin:<ul> <li>/bin almacena binarios (ejecutables) esenciales para el sistema, que son necesarios incluso en el modo de usuario \u00fanico.</li> <li>/sbin contiene binarios similares, pero est\u00e1n destinados a ser utilizados por el superusuario (root).</li> </ul> </li> <li>/usr:<ul> <li>/usr (abreviatura de \"Unix System Resources\") contiene programas, bibliotecas y archivos de datos que son utilizados por aplicaciones y usuarios.</li> <li>/usr/bin y /usr/sbin contienen binarios de programas instalados, mientras que /usr/lib contiene bibliotecas compartidas.</li> </ul> </li> <li>/var:<ul> <li>/var almacena datos variables, como archivos de registro (logs), correos electr\u00f3nicos y otros datos que cambian con el tiempo. Por ejemplo, /var/log contiene archivos de registro del sistema.</li> </ul> </li> <li>/tmp:<ul> <li>/tmp es un directorio temporal donde los programas y usuarios pueden crear archivos temporales. Los archivos aqu\u00ed se eliminan autom\u00e1ticamente despu\u00e9s de un tiempo o al reiniciar el sistema.</li> </ul> </li> <li>/dev:<ul> <li>/dev contiene archivos especiales que representan dispositivos en el sistema. Estos archivos se utilizan para interactuar con hardware y controladores de dispositivos.</li> </ul> </li> <li>/proc:<ul> <li>/proc es un sistema de archivos virtual que proporciona informaci\u00f3n en tiempo real sobre el sistema y los procesos en ejecuci\u00f3n. Se utiliza para acceder a informaci\u00f3n del kernel y configuraci\u00f3n din\u00e1mica.</li> </ul> </li> <li>/mnt y /media:<ul> <li>/mnt y /media son directorios utilizados para montar dispositivos de almacenamiento, como unidades USB o discos duros externos.</li> </ul> </li> <li>/opt:<ul> <li>/opt es el directorio donde se instalan aplicaciones y paquetes de software adicionales. Algunas aplicaciones de terceros se instalan en esta ubicaci\u00f3n.</li> </ul> </li> <li>/srv:<ul> <li>/srv se utiliza para almacenar datos de servicios proporcionados por el sistema, como sitios web o archivos compartidos a trav\u00e9s de la red.</li> </ul> </li> </ol>"},{"location":"UD00/2.bash/#13-rutas-absolutas-y-relativas","title":"1.3. Rutas absolutas y relativas","text":"<p>Hay dos tipos principales de rutas: rutas absolutas y rutas relativas.</p> <p>1. Rutas Absolutas:</p> <ul> <li>Siempre comienza con <code>/</code> y muestra la ubicaci\u00f3n exacta sin importar el directorio actual desde el que se est\u00e9 trabajando.</li> <li>Ejemplo de ruta absoluta: <code>/home/usuario/archivo.txt</code></li> </ul> <p>2. Rutas Relativas:</p> <ul> <li>No comienza con <code>/</code> y depende del directorio actual para determinar la ubicaci\u00f3n. (Es relativa al directorio actual)</li> <li>Ejemplo de ruta relativa: <code>../carpeta/archivo.txt</code></li> <li>Otro ejemplo: <code>carpeta/archivo.txt</code></li> </ul> <p>Ejemplo:</p> <p>Supongamos que est\u00e1s trabajando desde el directorio <code>/home/usuario/</code> y tienes la siguiente estructura de carpetas y archivos:</p> <pre><code>/home/usuario/\n    \u251c\u2500\u2500 documentos/\n    \u2502   \u251c\u2500\u2500 archivo1.txt\n    \u2502   \u2514\u2500\u2500 archivo2.txt\n    \u251c\u2500\u2500 fotos/\n    \u2502   \u251c\u2500\u2500 imagen1.jpg\n    \u2502   \u2514\u2500\u2500 imagen2.jpg\n    \u2514\u2500\u2500 musica/\n        \u251c\u2500\u2500 cancion.mp3\n        \u2514\u2500\u2500 lista_de_reproduccion.m3u\n</code></pre> <ul> <li>Para acceder al archivo <code>archivo1.txt</code> desde el directorio actual <code>/home/usuario/</code>, puedes utilizar una ruta relativa: <code>documentos/archivo1.txt</code>.</li> <li>Para acceder al mismo archivo desde cualquier ubicaci\u00f3n en el sistema, puedes utilizar una ruta absoluta: <code>/home/usuario/documentos/archivo1.txt</code>.</li> </ul> <p>Las rutas relativas son \u00fatiles cuando deseas trabajar dentro de un contexto espec\u00edfico, mientras que las rutas absolutas son necesarias cuando necesitas acceder a recursos desde cualquier ubicaci\u00f3n en el sistema.</p>"},{"location":"UD00/2.bash/#14-tips-terminal","title":"1.4. Tips terminal","text":"<p>Uso tabulador.</p> <p>Navegaci\u00f3n por flechas.</p>"},{"location":"UD00/2.bash/#15-editores-consola","title":"1.5. Editores consola","text":""},{"location":"UD00/2.bash/#151-nano","title":"1.5.1. nano","text":"<p>Nano es un editor de texto en la l\u00ednea de comandos que es especialmente adecuado para usuarios principiantes.</p> <pre><code>nano nombre_del_archivo # Abrir un archivo (o crear un archivo si no existe)\n</code></pre> <p>\u270f\ufe0f EJERCICIOS</p> <pre><code>1. Crear un archivo llamado \"abecedario.txt\" que contenga todas las letras del abecedario, una por l\u00ednea.\n2. Ejecuta el siguiente comando para tener una copia de seguridad del archivo:\n    cp abecedario.txt abecedario.bk\n</code></pre> <p>Navegaci\u00f3n:</p> <ul> <li>Utiliza las teclas de direcci\u00f3n (flechas) para mover el cursor por el texto.</li> <li>Puedes usar las teclas \"Av P\u00e1g\" y \"Re P\u00e1g\" para desplazarte r\u00e1pidamente hacia arriba y hacia abajo.</li> </ul> <p>Edici\u00f3n de Texto:</p> <ul> <li>Simplemente escribe o borra texto directamente en la ubicaci\u00f3n del cursor.</li> <li>Usa las teclas \"Insert\" o \"Ins\" para alternar entre los modos de inserci\u00f3n y reemplazo.</li> <li>Para copiar y pegar, selecciona el texto con el cursor y luego utiliza las teclas \"Ctrl + K\" para cortar y \"Ctrl + U\" para pegar.</li> </ul> <p>Guardar y Salir:</p> <ul> <li>Para guardar los cambios y salir, presiona \"Ctrl + O\" (te pedir\u00e1 confirmaci\u00f3n, presiona \"Enter\" para confirmar) y luego \"Ctrl + X\" para salir.</li> <li>Si deseas salir sin guardar los cambios, simplemente presiona \"Ctrl + X\" y confirma si es necesario.</li> </ul> <p>Buscar y Reemplazar:</p> <ul> <li>Presiona \"Ctrl + W\" para buscar texto en el archivo.</li> <li>Para buscar y reemplazar, presiona \"Ctrl + \\\" y sigue las instrucciones en la parte inferior de la pantalla.</li> </ul> <p>N\u00fameros de L\u00ednea:</p> <ul> <li>Puedes ver los n\u00fameros de l\u00ednea activando la opci\u00f3n \"Ctrl + _\" (Control + Shift + Barra Invertida).</li> </ul> <p>Guardar Copias de Seguridad:</p> <ul> <li>Para hacer copias de seguridad autom\u00e1ticas mientras editas, usa la opci\u00f3n \"Ctrl + O\" y agrega la opci\u00f3n \"-B\" al final del nombre del archivo.</li> </ul> <p>Resaltado de Sintaxis:</p> <ul> <li>Nano ofrece resaltado de sintaxis para varios lenguajes de programaci\u00f3n. Puedes habilitarlo con \"Ctrl + Y\" durante la edici\u00f3n.</li> </ul> <p>Configuraci\u00f3n Personalizada:</p> <ul> <li>Puedes personalizar Nano creando un archivo de configuraci\u00f3n en tu directorio de inicio llamado \".nanorc\". Aqu\u00ed puedes definir atajos de teclado y otras preferencias.</li> </ul> <p>Ayuda:</p> <ul> <li>Para acceder a la ayuda en l\u00ednea de Nano, presiona \"Ctrl + G\". Aqu\u00ed encontrar\u00e1s una lista de comandos y atajos \u00fatiles.</li> </ul>"},{"location":"UD00/2.bash/#152-vi-vim","title":"1.5.2. vi, vim","text":"<p>El editor de consola Vi es una herramienta poderosa y vers\u00e1til para editar archivos de texto en sistemas basados en Unix y Linux. Aunque puede tener una curva de aprendizaje pronunciada, dominar Vi es esencial para los usuarios avanzados y administradores de sistemas.</p> <pre><code>vi nombre_del_archivo # Abrir un archivo (o crear un archivo nuevo si no existe)\n</code></pre> <p>Modos de Vi:</p> <ul> <li>Modo Normal: Cuando abres Vi, est\u00e1s en el modo normal. En este modo, no puedes editar directamente el texto, pero puedes navegar por el archivo y ejecutar comandos.</li> <li>Modo de Inserci\u00f3n: Para editar el texto, debes cambiar al modo de inserci\u00f3n. Presiona \"i\" para ingresar al modo de inserci\u00f3n antes del cursor. Tambi\u00e9n puedes usar \"a\" para entrar en el modo de inserci\u00f3n despu\u00e9s del cursor.</li> <li>Modo de Comando: Puedes volver al modo normal en cualquier momento presionando la tecla \"Esc\".</li> </ul> <p>Guardar y Salir:</p> <ul> <li>Para guardar los cambios y salir, presiona \"Esc\" para asegurarte de estar en el modo normal, luego escribe <code>:wq</code> y presiona \"Enter\".</li> <li>Para salir sin guardar, utiliza <code>:q!</code>.</li> <li>Si deseas guardar pero no salir, utiliza <code>:w</code>.</li> </ul> <p>Navegaci\u00f3n:</p> <ul> <li>h, j, k, l: Estas teclas se utilizan en el modo normal para mover el cursor hacia la izquierda, abajo, arriba y derecha, respectivamente.</li> <li>G: Salta a la \u00faltima l\u00ednea del archivo.</li> <li>:n: Salta a la l\u00ednea \"n\" del archivo.</li> </ul> <p>B\u00fasqueda y Reemplazo:</p> <ul> <li>/texto: Busca \"texto\" hacia adelante en el archivo.</li> <li>?texto: Busca \"texto\" hacia atr\u00e1s en el archivo.</li> <li>:s/buscar/reemplazar/g: Reemplaza todas las ocurrencias de \"buscar\" con \"reemplazar\" en la l\u00ednea actual.</li> <li>:%s/buscar/reemplazar/g: Reemplaza todas las ocurrencias de \"buscar\" con \"reemplazar\" en todo el archivo.</li> </ul> <p>Copiar, Cortar y Pegar:</p> <ul> <li>yy: Copia (yanks) la l\u00ednea actual.</li> <li>dd: Corta (borra) la l\u00ednea actual.</li> <li>p: Pega el texto copiado o cortado despu\u00e9s del cursor.</li> </ul> <p>Desplazamiento R\u00e1pido:</p> <ul> <li>Ctrl + f: Desplazamiento hacia adelante una p\u00e1gina.</li> <li>Ctrl + b: Desplazamiento hacia atr\u00e1s una p\u00e1gina.</li> </ul> <p>Deshacer y Rehacer:</p> <ul> <li>u: Deshace la \u00faltima acci\u00f3n.</li> <li>Ctrl + r: Rehace la \u00faltima acci\u00f3n deshecha.</li> </ul>"},{"location":"UD00/2.bash/#2-comandos-basicos","title":"2.  Comandos b\u00e1sicos","text":""},{"location":"UD00/2.bash/#21-listado-de-archivos","title":"2.1. Listado de archivos","text":"<p>pwd</p> <ul> <li>Descripci\u00f3n: (\"print working directory\") muestra la ruta completa del directorio en el que te encuentras actualmente en el sistema de archivos.</li> <li>Principales opciones:<ul> <li><code>P</code>: Muestra la ruta f\u00edsica real en lugar de la ruta simb\u00f3lica, si est\u00e1s en un enlace simb\u00f3lico.</li> <li><code>-help</code>: Muestra la ayuda y la informaci\u00f3n de uso del comando \"pwd\".</li> <li><code>-version</code>: Muestra la versi\u00f3n del comando \"pwd\".</li> </ul> </li> <li>Ejemplo de uso:</li> </ul> <pre><code>pwd # Muestra la carpeta actual, la carpeta donde est\u00e1 el usuario\n</code></pre> <p>ls</p> <ul> <li>Descripci\u00f3n: (list) Muestra una lista de archivos y directorios en la ubicaci\u00f3n especificada.</li> <li>Principales opciones:<ul> <li><code>l</code>: Muestra el contenido en formato largo, incluyendo detalles como permisos, propietario, grupo, tama\u00f1o, fecha de modificaci\u00f3n y nombre del archivo.</li> <li><code>a</code>: Muestra archivos ocultos (los que comienzan con un punto <code>.</code>).</li> <li><code>h</code>: Muestra tama\u00f1os de archivos en un formato legible por humanos (por ejemplo, KB, MB, GB).</li> <li><code>R</code>: Lista de manera recursiva, mostrando el contenido de subdirectorios.</li> </ul> </li> <li>Ejemplo de uso:</li> </ul> <pre><code>ls # Listar archivos y directorios en el directorio actual\nls -la # Listar archivos y directorios en formato largo y mostrar archivos ocultos\nls -R /ruta/al/directorio # Lista de manera recursiva\n</code></pre> <p>\u270f\ufe0f EJERCICIOS <pre><code>1. Listar todos los archivos del directorio /bin. \n2. Muestra todos los archivos y directorios de la carpeta actual (tambi\u00e9n los ficheros ocultos)\n3. Muestra solamente los directorios de la carpeta actual\n4. Muestra el contenido de la ra\u00edz del sistema\n5. Muestra el contenido de la carpeta actual utilizando rutas absolutas\n6. Listar todos los archivos del directorio /dev que empiecen por t.\n7. Listar todos los archivos del directorio /dev que empiecen por t y acaben en C1.\n8. Listar recursivamente el contenido de /usr\n9. Listar todos los archivos del directorio /etc que empiecen por t en orden inverso.\n10. Lista todos los archivos de tipo \"log\" del sistema\n11. Mostrar el d\u00eda y la hora actual.\n</code></pre></p>"},{"location":"UD00/2.bash/#22-leer-el-contenido-de-un-archivo","title":"2.2. Leer el contenido de un archivo","text":"<p>cat</p> <p>(concatenate) se utiliza para mostrar el contenido de archivos de texto en la terminal, pero tambi\u00e9n se utiliza para crear, concatenar y mostrar el contenido de archivos.</p> <ul> <li>Principales opciones:<ul> <li><code>n</code>: Numerar las l\u00edneas del archivo.</li> <li><code>E</code>: Mostrar un signo de d\u00f3lar (<code>$</code>) al final de cada l\u00ednea.</li> <li><code>A</code>: Equivalente a <code>vET</code> para mostrar n\u00fameros de l\u00ednea y signos de d\u00f3lar.</li> <li><code>b</code>: Numerar las l\u00edneas en blanco.</li> <li><code>s</code>: Suprimir l\u00edneas en blanco repetidas al mostrar el contenido.</li> </ul> </li> </ul> <pre><code>cat abecedario.txt #Mostrar el contenido de un archivo en la terminal\ncat -n abecedario.txt #Mostrar el contenido de un archivo con n\u00fameros de l\u00ednea\ncat abecedario.txt abecedario.txt #Concatenar dos archivos y mostrar el resultado \n</code></pre> <p>more (less)</p> <p>Visualizar el contenido de archivos de texto uno por uno en la terminal. Permite desplazarse hacia adelante y hacia atr\u00e1s a trav\u00e9s del contenido de un archivo, lo que lo hace \u00fatil para ver archivos largos sin sobrecargar la pantalla.</p> <ul> <li>Principales opciones:<ul> <li>Presiona la barra espaciadora para avanzar una p\u00e1gina.</li> <li>Presiona la tecla \"q\" para salir de <code>more</code> en cualquier momento.</li> <li>Para buscar texto, presiona la tecla \"/\" seguida del texto a buscar y luego presiona \"Enter\". Luego, usa \"n\" para buscar la siguiente coincidencia y \"N\" para buscar la anterior.</li> </ul> </li> </ul> <pre><code>more archivo.txt\n</code></pre> <p>head</p> <p>Mostrar las primeras l\u00edneas de un archivo de texto en la terminal. Por defecto, muestra las primeras 10 l\u00edneas.</p> <ul> <li>Principales opciones:<ul> <li><code>n N</code>: Muestra las primeras N l\u00edneas del archivo.</li> <li><code>c N</code>: Muestra los primeros N bytes del archivo en lugar de l\u00edneas.</li> </ul> </li> </ul> <pre><code>head abecedario.txt #Mostrar las primeras 10 l\u00edneas de un archivo de texto\nhead -n 5 abecedario.txt #Mostrar las primeras 5 l\u00edneas de un archivo de texto\nhead -c 100 abecedario.txt #Mostrar los primeros 100 bytes de un archivo\n</code></pre> <p>tail</p> <p>Mostrar las \u00faltimas l\u00edneas de un archivo de texto en la terminal. Por defecto, muestra las \u00faltimas 10 l\u00edneas.</p> <ul> <li>Principales opciones:<ul> <li><code>n N</code>: Muestra las \u00faltimas N l\u00edneas del archivo.</li> <li><code>f</code>: Muestra el contenido del archivo en tiempo real y se actualiza autom\u00e1ticamente cuando se agregan nuevas l\u00edneas al archivo (\u00fatil para ver archivos de registro en constante cambio).</li> </ul> </li> </ul> <pre><code>tail abecedario.txt #Mostrar las \u00faltimas 10 l\u00edneas de un archivo de texto\ntail -n 5 abecedario.txt #Mostrar las \u00faltimas 5 l\u00edneas de un archivo de texto\ntail -f abecedario.txt #Mostrar el contenido en tiempo real de un archivo de registro\n</code></pre>"},{"location":"UD00/2.bash/#23-gestion-de-archivos","title":"2.3. Gesti\u00f3n de archivos","text":"<p>touch</p> <p>Crear archivos vac\u00edos o actualizar la marca de tiempo de archivos existentes. Su funcionamiento b\u00e1sico es crear un archivo si no existe o actualizar la marca de tiempo del archivo si ya existe.</p> <ul> <li>Principales opciones:<ul> <li><code>c</code>: No crea un nuevo archivo si no existe.</li> <li><code>d</code>: Permite especificar una fecha y hora de marca de tiempo en lugar de usar la actual.</li> <li><code>t</code>: Se utiliza junto con la opci\u00f3n <code>d</code> para establecer una fecha y hora espec\u00edficas.</li> </ul> </li> </ul> <pre><code>touch miarchivo.txt # Crear un archivo vac\u00edo llamado \"miarchivo.txt\"\ntouch -c miarchivo.txt # Actualizar la marca de tiempo de un archivo existente\ntouch -d \"2023-10-02 14:30:00\" miarchivo.txt # Establecer una marca de tiempo personalizada\n\nstat miarchivo.txt\n</code></pre> <p>Operadores &gt; y &gt;&gt;</p> <p>Se utilizan en Bash para redirigir la salida est\u00e1ndar de un comando hacia un archivo en lugar de mostrarla en la pantalla.</p> <p><code>&gt;</code> (Redirecci\u00f3n de salida):</p> <p>Utilizado para redirigir la salida est\u00e1ndar de un comando hacia un archivo. Si el archivo ya existe, su contenido se sobrescribir\u00e1.</p> <pre><code>ls &gt; lista_archivos.txt\n</code></pre> <p><code>&gt;&gt;</code> (Redirecci\u00f3n de salida, modo anexar):</p> <p>Funcionamiento: Similar a <code>&gt;</code>, pero en lugar de sobrescribir el archivo, agrega la salida al final del archivo. Si el archivo no existe, se crea.</p> <pre><code>echo \"Texto adicional\" &gt;&gt; archivo_existente.txt\n</code></pre> <p>Operador | (tuber\u00eda, pipe) \u203c\ufe0f</p> <p>Redirigir la salida de un comando hacia la entrada de otro. Esto permite encadenar varios comandos juntos para realizar operaciones m\u00e1s complejas o procesar datos de manera eficiente.</p> <pre><code>ls -la | head -n 2\n</code></pre> <p>cp</p> <p>Copiar archivos o directorios de un lugar a otro en el sistema de archivos.</p> <ul> <li>Principales opciones:<ul> <li><code>r</code> o <code>R</code>: Copia directorios de manera recursiva.</li> <li><code>i</code>: Pide confirmaci\u00f3n antes de sobrescribir un archivo existente.</li> <li><code>u</code>: Copia solo cuando el archivo de origen sea m\u00e1s reciente que el archivo de destino o cuando el archivo de destino no exista.</li> <li><code>v</code>: Muestra un mensaje para cada archivo copiado, mostrando el progreso.</li> </ul> </li> </ul> <pre><code>cp abecedario.txt /ruta/destino/ # Copiar un archivo a otro directorio\ncp -r directorio_origen/ directorio_destino/ #Copiar un directorio y su contenido recursivamente\ncp -i abecedario.txt /ruta/destino/ #Copiar un archivo con confirmaci\u00f3n antes de sobrescribir\n</code></pre> <p>mv</p> <p>Mover o renombrar archivos y directorios en el sistema de archivos. Puede utilizarse para cambiar el nombre de un archivo o para cambiar su ubicaci\u00f3n en el sistema de archivos.</p> <ul> <li>Principales opciones:<ul> <li><code>i</code>: Pide confirmaci\u00f3n antes de sobrescribir un archivo existente en el destino.</li> <li><code>u</code>: Mueve solo cuando el archivo de origen sea m\u00e1s reciente que el archivo de destino o cuando el archivo de destino no exista.</li> <li><code>v</code>: Muestra un mensaje para cada operaci\u00f3n realizada, mostrando el progreso.</li> </ul> </li> </ul> <pre><code>mv abecedario.txt /ruta/destino/ #Mover un archivo a otro directorio\nmv abecedario.txt abecedario2.txt #Cambiar el nombre de un archivo\nmv directorio_origen/ directorio_destino/ # Mover un directorio y su contenido a otro lugar\nmv directorio_actual/ nuevo_nombre/ #Cambiar el nombre de un directorio\n</code></pre> <p>rm</p> <p>Eliminar archivos o directorios en el sistema de archivos.</p> <ul> <li>Principales opciones:<ul> <li><code>r</code> o <code>R</code>: Elimina directorios y su contenido de manera recursiva.</li> <li><code>i</code>: Pide confirmaci\u00f3n antes de eliminar cada archivo o directorio.</li> <li><code>f</code>: Forzar la eliminaci\u00f3n sin pedir confirmaci\u00f3n, \u00fatil para eliminar archivos sin interacci\u00f3n.</li> <li><code>v</code>: Muestra un mensaje para cada archivo o directorio eliminado, mostrando el progreso.</li> </ul> </li> </ul> <pre><code>rm abecedario.txt #Eliminar un archivo\nrm -r directorio/ #Eliminar un directorio y su contenido de manera recursiva\nrm -f abecedario.txt abecedario2.txt # Eliminar varios archivos sin confirmaci\u00f3n\nrm -i abecedario1.txt abecedario2.txt # Eliminar archivos con confirmaci\u00f3n\n</code></pre> <p>mkdir</p> <p>Crear directorios (carpetas) en el sistema de archivos.</p> <ul> <li>Principales opciones:<ul> <li><code>p</code>: Crea directorios padres necesarios de manera recursiva. Si un directorio padre no existe, lo crear\u00e1 autom\u00e1ticamente.</li> <li><code>m</code>: Establece permisos (modo) para el directorio creado.</li> </ul> </li> </ul> <pre><code>mkdir nombre_directorio #Crear un directorio en la ubicaci\u00f3n actual\nmkdir -m 755 nombre_directorio #Crear un directorio con permisos espec\u00edficos\nmkdir -p directorio_padre/directorio_hijo/subdirectorio # Crear directorios anidados de manera recursiva\n</code></pre> <p>ln</p> <p></p> <ul> <li>Descripci\u00f3n: El comando <code>ln</code> se utiliza para crear enlaces (links) entre archivos en sistemas Unix y Linux. Puede crear enlaces duros (hard links) o enlaces simb\u00f3licos (symbolic links o symlinks).</li> <li>Principales opciones:<ul> <li><code>s</code>: Crea un enlace simb\u00f3lico en lugar de un enlace duro. Los enlaces simb\u00f3licos son referencias a archivos o directorios y pueden apuntar a ubicaciones fuera del sistema de archivos actual.</li> <li><code>b</code>: Realiza una copia de seguridad de los archivos existentes antes de reemplazarlos.</li> <li><code>f</code>: Fuerza la creaci\u00f3n de enlaces, incluso si el archivo de destino ya existe.</li> </ul> </li> </ul> <pre><code>ln archivo_existente enlace_duro #Crear un enlace duro (hard link) para un archivo existente\nln -s /ruta/al/origen enlace_simbolico #Crear un enlace simb\u00f3lico (symlink) a un archivo o directorio\nln -b archivo_existente enlace_duro #Crear un enlace duro y realizar una copia de seguridad del archivo de destino si ya existe\n</code></pre>"},{"location":"UD00/2.bash/#ejercicios","title":"\u270f\ufe0f Ejercicios","text":"<pre><code>0. Crea el siguiente sistema de ficheros en tu home:\n\nPara crear los ficheros y que tengan algo de contenido puedes utilizar el comando:\necho $RANDOM &gt; fichero_a_crear.txt\n\n\u2514\u2500\u2500 home/\n  \u2514\u2500\u2500 tu_usuario/\n      \u2514\u2500\u2500 ejercicios/\n          \u251c\u2500\u2500 carpeta1/\n          \u2502   \u251c\u2500\u2500 archivo1.txt\n          \u2502   \u251c\u2500\u2500 archivo2.txt\n          \u2502   \u251c\u2500\u2500 subcarpeta1/\n          \u2502   \u2502   \u2514\u2500\u2500 archivo3.txt\n          \u2502   \u2514\u2500\u2500 subcarpeta2/\n          \u2502       \u2514\u2500\u2500 archivo4.txt\n          \u251c\u2500\u2500 carpeta2/\n          \u2502   \u251c\u2500\u2500 subcarpeta1/\n          \u2502   \u2502   \u2514\u2500\u2500 archivo5.txt\n          \u2502   \u2514\u2500\u2500 subcarpeta2/\n          \u2502       \u2514\u2500\u2500 archivo6.txt\n          \u2514\u2500\u2500 documentos/\n              \u251c\u2500\u2500 documento1.txt\n              \u2514\u2500\u2500 documento2.txt\n\n1. Vuelve a tu home (cd)\n\n**// Utilizando rutas relativas**\n2. Elimina el archivo \"archivo1.txt\"\n3. Borra la carpeta \"subcarpeta2\"\n4. Mueve el archivo \"archivo2.txt\" a la carpeta \"documentos\"\n5. Crea una carpeta llamada \"tmp/\" dentro de ejercicios.\n6. Copia la carpeta \"subcarpeta1\" a la carpeta \"tmp\"\n\n**// Utilizando rutas absolutas**\n7. Utiliza el comando rm para eliminar el archivo \"archivo5.txt\"\n8. Copia el archivo \"documento1.txt\" a la carpeta \"subcarpeta1\"\nNO-&gt;&gt;&gt;&gt; 9. Borra el archivo \"archivo5.txt\"\n10. Copia la carpeta \"carpeta1\" dentro de la carpeta \"tmp\"\n11. Borra la carpeta \"tmp/carpeta1\"\n\n**// Enlaces**\n12. Crea un enlace llamado \"enlace1\" dentro de ejercicios, al archivo \"archivo6.txt\"\n13. Muestra el contenido de \"enlace1\"\n14. Modifica el contenido de \"archivo6.txt\"\n15. Muestra el contenido de \"enlace1\"\n16. Borra \"archivo6.txt\"\n17. Realiza un ls -la para ver qu\u00e9 ha ocurrido\n18. Muestra el contenido de \"enlace1\"\n\n**Extra**\n1. Mu\u00e9vete a tu home (/home/tu_usuario) sin especificar la carpeta (utilizando un alias). \n        https://es.wikipedia.org/wiki/Virgulilla\n2. Cambia a la carpeta /tmp y regresa al directorio anterior.\n        https://www.ibm.com/docs/en/zos/2.2.0?topic=descriptions-cd-change-working-directory\n3. Ejecuta los siguientes comandos (dentro de tu home)\n    $   mkdir extra\n    $   cd extra\n    $   echo \"Hola\" &gt; 1\n    $   echo \"Hola\" &gt; 2\n    $   echo \"Hola\" &gt; -3\n    $   mkdir 4 5 6 \n    **** Escribe un comando que borre TODOS los archivos y directorios **** \n</code></pre>"},{"location":"UD00/2.bash/#24-division-de-archivos","title":"2.4. Divisi\u00f3n de archivos","text":"<p>cut</p> <p>Seleccionar y mostrar partes espec\u00edficas de l\u00edneas de texto en archivos o la entrada est\u00e1ndar. Es \u00fatil para dividir o filtrar datos basados en campos delimitados por separadores, como tabulaciones o comas.</p> <ul> <li>Principales opciones:<ul> <li><code>f N</code>: Especifica el n\u00famero de campo que deseas extraer (por ejemplo, <code>f 2</code> para el segundo campo).</li> <li><code>d DELIMITADOR</code>: Especifica el delimitador utilizado para separar campos en las l\u00edneas (por defecto, es la pesta\u00f1a).</li> </ul> </li> </ul> <pre><code>cut -f 1 -d ',' archivo.csv #Extraer el primer campo de un archivo CSV (coma como delimitador)\ncut -f 3 -d $'\\t' archivo.txt #Extraer el tercer campo de un archivo de texto tabulado\ncut -c 1-5 archivo.txt #Extraer los primeros cinco caracteres de cada l\u00ednea de un archivo\n</code></pre> <p>split</p> <p>Dividir archivos grandes en fragmentos m\u00e1s peque\u00f1os, lo que puede ser \u00fatil para manejar archivos extensos o para la transferencia m\u00e1s eficiente de datos.</p> <ul> <li>Principales opciones:<ul> <li><code>b N</code>: Divide el archivo en fragmentos de tama\u00f1o fijo especificado (por ejemplo, <code>b 1M</code> divide en fragmentos de 1 megabyte).</li> <li><code>l N</code>: Divide el archivo en fragmentos con un n\u00famero fijo de l\u00edneas (por ejemplo, <code>l 100</code> divide en fragmentos de 100 l\u00edneas).</li> <li><code>d</code>: Utiliza nombres de archivo num\u00e9ricos para los fragmentos (por ejemplo, <code>x00</code>, <code>x01</code>, <code>x02</code>, ...).</li> <li><code>a N</code>: Especifica el n\u00famero de caracteres a utilizar en los nombres de archivo num\u00e9ricos (por ejemplo, <code>a 3</code> para <code>x001</code>, <code>x002</code>, ...).</li> </ul> </li> </ul> <pre><code>split -b 1M archivo_grande.txt #Dividir un archivo en fragmentos de 1 megabyte\nsplit -l 100 archivo_grande.txt #Dividir un archivo en fragmentos con 100 l\u00edneas cada uno\nsplit -a 3 archivo_grande.txt #Dividir un archivo en fragmentos con nombres num\u00e9ricos de tres caracteres\n</code></pre>"},{"location":"UD00/2.bash/#ejercicios_1","title":"\u270f\ufe0f Ejercicios","text":"<pre><code>1. Crea un archivo llamado \"resultado.txt\" que contenga un listado largo (opci\u00f3n -la) de la carpeta /etc \n2. Muestra la columna de los permisos del archivo anterior.\n3. Muesta el nombre de los archivos de \"resultado.txt\". &lt;--- (tr)\n4. Muesta los nombres de los usuarios registrados en el sistema.\n\n---\n5. Crea un archivo que contenga:\n\nNombre,Edad,Profesi\u00f3n,Tel\u00e9fono,Ciudad,Pa\u00eds,Primer Apellido,Segundo Apellido\nJuan,30,Ingeniero,123-456-789,Madrid,Espa\u00f1a,P\u00e9rez,G\u00f3mez\nMar\u00eda,25,M\u00e9dica,987-654-321,Barcelona,Espa\u00f1a,Rodr\u00edguez,L\u00f3pez\nCarlos,35,Abogado,555-555-555,Valencia,Espa\u00f1a,Fern\u00e1ndez,Mart\u00ednez\nAna,28,Profesora,444-333-222,Sevilla,Espa\u00f1a,L\u00f3pez,S\u00e1nchez\nDavid,40,Arquitecto,111-222-333,Bilbao,Espa\u00f1a,Mart\u00ednez,Ruiz\nLaura,29,Periodista,777-888-999,Granada,Espa\u00f1a,Garc\u00eda,P\u00e9rez\nPedro,45,M\u00e9dico,555-123-456,Toledo,Espa\u00f1a,Garc\u00eda,Jim\u00e9nez\nIsabel,32,Ingeniera,333-666-999,Zaragoza,Espa\u00f1a,Torres,Rodr\u00edguez\nSergio,27,Dise\u00f1ador,666-999-444,Barcelona,Espa\u00f1a,Ruiz,Gonz\u00e1lez\nLuisa Gonz\u00e1lez,38,Psic\u00f3loga,222-444-666,Valencia,Espa\u00f1a,Gonz\u00e1lez,Ruiz\n\n6. Muestra el primer apellido de todos\n7. Muestra la profesi\u00f3n de todos\n8. Muestra el tel\u00e9fono de todos\n7. Muestra el Nombre y primer apellido de todos\n8. Mustra el Tel\u00e9fono de los 2 \u00faltimos\n9. Muestra todos los datos del primero\n10. Muestra todos los datos del \u00faltimo separados por espacios\n11. Muestra el segundo grupo de d\u00edgitos del tel\u00e9fono de Laura (888)\n12. Muestra unicamente los campos Tel\u00e9fono, ciudad y pa\u00eds de todos \n</code></pre>"},{"location":"UD00/2.bash/#25-busqueda-y-sustitucion-en-archivos","title":"2.5. B\u00fasqueda y sustituci\u00f3n en archivos","text":"<p>tr</p> <p>Toma una cadena de texto de entrada y realiza transformaciones en los caracteres seg\u00fan las especificaciones proporcionadas por el usuario. Puede utilizarse para reemplazar caracteres, eliminar caracteres, cambiar may\u00fasculas a min\u00fasculas o viceversa, entre otros.</p> <ul> <li>Principales opciones:<ul> <li><code>d</code>: Elimina los caracteres especificados en lugar de traducirlos.</li> <li><code>c</code>: Complementa el conjunto de caracteres especificados en lugar de traducirlos.</li> <li><code>s</code>: Sustituye secuencias repetidas de caracteres con un solo car\u00e1cter.</li> <li><code>u</code>: Unicode. Permite especificar rangos de caracteres Unicode para la traducci\u00f3n.</li> </ul> </li> </ul> <pre><code>cat archivo.txt | tr 'a-z,' 'A-Z ' # Cambia min\u00fasculas por may\u00fasculas\nls -la | tr -s ' ' # Sustituye m\u00faltiples espacios por uno\n</code></pre> <p>grep</p> <p>Buscar patrones de texto en archivos o en la entrada est\u00e1ndar. Se pueden buscar l\u00edneas que coincidan con un patr\u00f3n especificado en un archivo o una serie de archivos.</p> <ul> <li>Principales opciones:<ul> <li><code>i</code>: Realiza b\u00fasquedas insensibles a may\u00fasculas y min\u00fasculas.</li> <li><code>v</code>: Invierte la b\u00fasqueda para mostrar las l\u00edneas que NO coinciden con el patr\u00f3n.</li> <li><code>r</code> o <code>R</code>: Realiza b\u00fasquedas recursivas en directorios.</li> <li><code>l</code>: Muestra solo los nombres de los archivos que contienen coincidencias.</li> <li><code>n</code>: Muestra n\u00fameros de l\u00ednea junto con las coincidencias.</li> <li><code>e PATR\u00d3N</code>: Permite buscar m\u00faltiples patrones utilizando expresiones regulares.</li> </ul> </li> </ul> <pre><code>grep \"palabra\" archivo.txt #Buscar una palabra espec\u00edfica en un archivo\ngrep -i \"palabra\" archivo.txt #Buscar una palabra insensible a may\u00fasculas y min\u00fasculas en un archivo\ngrep -rl \"palabra\" /ruta/al/directorio/ #Buscar una palabra en todos los archivos de un directorio de manera recursiva y mostrar los nombres de los archivos que contienen coincidencias\ngrep -e \"patr\u00f3n1\" -e \"patr\u00f3n2\" archivo.txt #Buscar m\u00faltiples patrones utilizando expresiones regulares\n</code></pre> <p>sed</p> <p>(Stream Editor) Realizar transformaciones en el texto de entrada (ya sea desde un archivo o la entrada est\u00e1ndar) y escribir la salida en la pantalla o en un archivo. Es especialmente \u00fatil para la b\u00fasqueda y sustituci\u00f3n de texto, as\u00ed como para realizar otras ediciones en el contenido del archivo.</p> <ul> <li>Principales opciones:<ul> <li><code>e SCRIPT</code>: Permite especificar un script de edici\u00f3n de <code>sed</code> para realizar m\u00faltiples operaciones.</li> <li><code>i</code>: Modifica el archivo de entrada directamente (in-place) en lugar de mostrar la salida en la pantalla.</li> <li><code>n</code>: Suprime la salida predeterminada de <code>sed</code> y solo muestra las l\u00edneas modificadas seg\u00fan el script.</li> <li><code>r</code> o <code>E</code>: Habilita las expresiones regulares extendidas.</li> </ul> </li> </ul> <pre><code>sed 's/antiguo_texto/nuevo_texto/g' archivo.txt &gt; nuevo_archivo.txt #Sustituir una cadena de texto por otra en un archivo y guardar el resultado en un nuevo archivo\nsed -i '/^$/d' archivo.txt #Eliminar l\u00edneas vac\u00edas de un archivo y modificar el archivo en su lugar (in-place)\nsed -e 's/palabra1/reemplazo1/g' -e 's/palabra2/reemplazo2/g' archivo.txt #Utilizar un script de edici\u00f3n sed para realizar m\u00faltiples operaciones\nsed 's/ \\+/\\ /g' ls -la # reemplazar espacios\n</code></pre> <p>sed VS tr</p> <p>Si necesitas realizar ediciones complejas o transformaciones avanzadas en el texto, \"sed\" es la opci\u00f3n adecuada (permite el uso de expresiones regulares). Si solo necesitas realizar traducciones simples de caracteres o eliminar caracteres espec\u00edficos, \"tr\" es m\u00e1s adecuado debido a su simplicidad y velocidad.</p>"},{"location":"UD00/2.bash/#ejercicios_2","title":"\u270f\ufe0f Ejercicios","text":"<pre><code>Crea un archivo con el siguiente contenido (ejemplotexto.txt):\nLa camioneta es     vieja\nLa estUfa es nueva\nLa cesta de nueva\nLa camisa es vieja\nLa sudadera es nueva\n\n// Utiliza la opci\u00f3n -i para sobreescribir el fichero original\n1. Cambiar la U may\u00fascula por min\u00fascula.\n2. Reemplaza la palabra nueva por vieja.\n3. Reemplaza la palabra vieja por nueva solamente en la l\u00ednea 4 del archivo\n4. La primera l\u00ednea tiene muchos espacios antes de \"vieja\", sustituyelos por 1 espacio\n5. Sustituye todos los espacios por #\n6. Eliminar los saltos de l\u00ednea del archivo\n</code></pre> <pre><code># Soluciones\n\nsed 's/U/u/g' ejemplotexto.txt    \nsed -i '4 s/nueva/vieja/g' ejemplotexto.txt\nsed 's/ /#/g' ejemplotexto.txt\n\u2192 Mejora: sed 's/ \\+/#/g' ejemplotexto.txt\nsed -z 's/\\n/ /g' a.txt\n</code></pre>"},{"location":"UD00/2.bash/#26-ordenar","title":"2.6. Ordenar","text":"<p>sort</p> <p>Ordenar l\u00edneas de texto en un archivo o la entrada est\u00e1ndar. Puede ordenar l\u00edneas alfab\u00e9ticamente o num\u00e9ricamente, en orden ascendente o descendente.</p> <ul> <li>Principales opciones:<ul> <li><code>r</code>: Ordena en orden descendente (de mayor a menor).</li> <li><code>n</code>: Realiza una ordenaci\u00f3n num\u00e9rica en lugar de una ordenaci\u00f3n alfab\u00e9tica.</li> <li><code>u</code>: Elimina l\u00edneas duplicadas en la salida.</li> <li><code>k N[,M]</code>: Especifica un campo o rango de campos a considerar al ordenar, donde N y M son n\u00fameros de columna.</li> </ul> </li> </ul> <pre><code>sort archivo.txt #Ordenar l\u00edneas alfab\u00e9ticamente en orden ascendente\nsort -rn archivo.txt #Ordenar l\u00edneas num\u00e9ricamente en orden descendente\nsort -n -k 2 archivo.txt #Ordenar un archivo por el segundo campo (columna) num\u00e9rico\nsort -u archivo.txt &gt; archivo_sin_duplicados.txt #Eliminar l\u00edneas duplicadas en un archivo y guardar el resultado en un nuevo archivo\n</code></pre>"},{"location":"UD00/2.bash/#27-gestion-de-usuarios-y-grupos","title":"2.7. Gesti\u00f3n de usuarios y grupos","text":"<p>useradd *vs *adduser</p> <p>useradd es un comando que ejecuta un binario del sistema, mientras que adduser es un script en perl que utiliza el binario useradd.</p> <p>La mayor ventaja del comando adduser es que crea el directorio home (/home/usuario/) del usuario de manera autom\u00e1tica, cosa que no hace useradd (hay que usar la opci\u00f3n -m).</p> <p>userdel *vs *deluser</p> <p>Ambos comandos sirven para borrar usuarios. Y al igual que useradd y adduser: el comando userdel es un fichero binario, mientras que deluser es un script en perl que usa el binario userdel.</p> <p>groupadd</p> <p>Creaci\u00f3n de grupos</p> <pre><code>groupadd grupo1\n\n# comprueba el fichero /etc/group\n</code></pre> <p>usermod</p> <p>A\u00f1adir un usuario a un grupo</p> <pre><code>usermod -aG grupo1 usuario1\n</code></pre>"},{"location":"UD00/2.bash/#28-gestion-de-permisos","title":"2.8. Gesti\u00f3n de Permisos","text":"<p>chmod</p> <p>Cambiar los permisos (lectura, escritura, ejecuci\u00f3n) de archivos o carpetas en Linux.</p> <ul> <li>Principales Opciones:<ul> <li><code>R</code> (o <code>-recursive</code>): Aplica los cambios de permisos de manera recursiva a todos los archivos y carpetas dentro de una carpeta.</li> <li><code>+</code> (m\u00e1s) y `` (menos): Permite agregar (+) o quitar (-) permisos.</li> <li><code>u</code>, <code>g</code>, <code>o</code> y <code>a</code>: Representan al propietario (user), grupo (group), otros (others) y todos (all) respectivamente.</li> <li>Permisos en formato octal: Se pueden establecer permisos utilizando n\u00fameros octales, como 755 o 644.</li> </ul> </li> </ul> <pre><code># Cambiar los permisos de un archivo para que el propietario tenga permisos de lectura y escritura, el grupo tenga solo permisos de lectura y otros no tengan ning\u00fan permiso\nchmod u=rw,g=r,o= archivo.txt \n\n# Cambiar de manera recursiva los permisos de una carpeta y su contenido para que todos tengan permisos de lectura y escritura\nchmod -R a=rw carpeta/\n</code></pre> <p>Ejemplo con notaci\u00f3n octal:</p> <p>Supongamos que deseas establecer los siguientes permisos en un archivo llamado \"mi_archivo.txt\":</p> <p>El propietario debe tener permisos de lectura, escritura y ejecuci\u00f3n (7).</p> <p>El grupo debe tener permisos de lectura y ejecuci\u00f3n, pero no de escritura (5).</p> <p>Otros usuarios deben tener solo permisos de lectura (4).</p> <pre><code>chmod 755 mi_archivo.txt\n</code></pre> <p></p> <p>umask</p> <p>Establecer y mostrar la m\u00e1scara de creaci\u00f3n de archivos por defecto. La m\u00e1scara de creaci\u00f3n de archivos determina los permisos predeterminados que se asignar\u00e1n a los archivos y carpetas cuando se creen.</p> <ul> <li>Principales Opciones:<ul> <li>Sin opciones, el comando <code>umask</code> muestra la m\u00e1scara de creaci\u00f3n de archivos actual en notaci\u00f3n octal.</li> <li><code>S</code> (o <code>-symbolic</code>): Muestra la m\u00e1scara de creaci\u00f3n de archivos en notaci\u00f3n simb\u00f3lica (por ejemplo, \"u=rw,go=rx\").</li> <li>Puedes establecer una m\u00e1scara de creaci\u00f3n de archivos espec\u00edfica proporcionando un n\u00famero octal como argumento.</li> </ul> </li> </ul> <pre><code>umask #Mostrar la m\u00e1scara de creaci\u00f3n de archivos actual en notaci\u00f3n octal\numask 022 #Establecer una m\u00e1scara de creaci\u00f3n de archivos que permita al propietario tener permisos completos (lectura, escritura, ejecuci\u00f3n) y al grupo y otros tener solo permisos de lectura:\numask -S #Mostrar la m\u00e1scara de creaci\u00f3n de archivos actual en notaci\u00f3n simb\u00f3lica\n</code></pre> <p>chown</p> <p>Cambiar el propietario y el grupo de archivos y carpetas en sistemas Unix y Linux.</p> <ul> <li>Principales Opciones:<ul> <li><code>R</code> (o <code>-recursive</code>): Aplica los cambios de propietario y grupo de manera recursiva a todos los archivos y carpetas dentro de una carpeta.</li> <li><code>usuario:grupo</code> (o <code>usuario</code>) especifica el nuevo propietario y, opcionalmente, el nuevo grupo para los archivos y carpetas.</li> <li>Puedes utilizar el nombre de usuario o el identificador num\u00e9rico de usuario (UID) y el nombre de grupo o el identificador num\u00e9rico de grupo (GID) como argumentos.</li> </ul> </li> </ul> <pre><code># Cambiar el propietario y el grupo de un archivo llamado \"mi_archivo.txt\" a un usuario llamado \"nuevo_usuario\" y un grupo llamado \"nuevo_grupo\"\nchown nuevo_usuario:nuevo_grupo mi_archivo.txt\n\n# Cambiar de manera recursiva el propietario y el grupo de una carpeta llamada \"mi_carpeta\" y su contenido:\nchown -R nuevo_usuario:nuevo_grupo mi_carpeta/\n</code></pre> <p>chgrp</p> <p>Cambiar el grupo de archivos y carpetas sin cambiar el propietario.</p> <ul> <li>Principales Opciones:<ul> <li><code>R</code> (o <code>-recursive</code>): Aplica los cambios de grupo de manera recursiva a todos los archivos y carpetas dentro de una carpeta.</li> </ul> </li> </ul> <pre><code>chgrp nuevo_grupo mi_archivo.txt # Cambiar el grupo de un archivo llamado \"mi_archivo.txt\" a un grupo llamado \"nuevo_grupo\"\nchgrp -R nuevo_grupo mi_carpeta/ # Cambiar de manera recursiva el grupo de una carpeta llamada \"mi_carpeta\" y su contenido\n</code></pre>"},{"location":"UD00/2.bash/#ejercicios_3","title":"\u270f\ufe0f Ejercicios","text":"<pre><code>1. Crea un usuario utilizando useradd y comprueba si se ha creado su home.\n2. Borra un usuario utilizando deluser y comprueba si se ha borrado su home.\n3. Muestra las \u00faltimas l\u00edneas de /etc/passwd\n4. Crea un grupo grupo1\n5. A\u00f1ade a los dos usuarios creados a este grupo.\n6. Borra los grupos creados\n7. Borra los usuarios creados\n</code></pre>"},{"location":"UD00/2.bash/#29-ayuda","title":"2.9. Ayuda","text":"<p>man</p> <p>Acceder al sistema de p\u00e1ginas del manual en Unix y Linux. Proporciona documentaci\u00f3n detallada y ayuda sobre otros comandos y utilidades disponibles en el sistema.</p> <ul> <li>Principales opciones:<ul> <li><code>man NOMBRE_COMANDO</code>: Muestra la p\u00e1gina del manual de un comando espec\u00edfico. Reemplaza \"NOMBRE_COMANDO\" con el nombre del comando del que deseas obtener informaci\u00f3n.</li> <li><code>k PALABRA_CLAVE</code>: Busca comandos relacionados con una palabra clave en la descripci\u00f3n del comando.</li> <li><code>f NOMBRE_COMANDO</code>: Muestra una descripci\u00f3n breve del comando sin acceder a la p\u00e1gina completa del manual.</li> <li><code>man -k .</code>: Muestra una lista de todos los comandos disponibles en el sistema.</li> </ul> </li> </ul> <pre><code>man ls #Ver la p\u00e1gina del manual del comando ls\nman -f grep #Mostrar una descripci\u00f3n breve del comando grep\n</code></pre> <p>tldr</p> <p>https://github.com/tldr-pages/tldr</p> <p>Proporciona versiones simplificadas y m\u00e1s f\u00e1ciles de entender de las p\u00e1ginas del manual de otros comandos. Est\u00e1 dise\u00f1ado para brindar informaci\u00f3n r\u00e1pida y concisa sobre c\u00f3mo usar comandos comunes de Unix y Linux sin necesidad de leer las p\u00e1ginas completas del manual.</p> <ul> <li>Principales opciones:<ul> <li><code>tldr NOMBRE_COMANDO</code>: Muestra una descripci\u00f3n simplificada y ejemplos de uso para el comando especificado. Reemplaza \"NOMBRE_COMANDO\" con el nombre del comando que deseas consultar.</li> <li><code>tldr --list</code>: Lista todos los comandos disponibles en el sistema para los que se proporcionan descripciones en <code>tldr</code>.</li> </ul> </li> </ul> <pre><code>tldr ls # Ver una descripci\u00f3n simplificada del comando ls con ejemplos\ntldr --list # Listar todos los comandos disponibles en tldr\n</code></pre>"},{"location":"UD00/3.ssh-soluciones/","title":"Varios: ssh - scp - screen - sshfs","text":"<p>\u270f\ufe0f Ejercicios</p> <ol> <li> <p>Modifica la configuraci\u00f3n del servidor SSH para que se pueda acceder como root. <pre><code>vi /etc/ssh/sshd_config\n\nPermitRootLogin yes\n\nservice sshd restart\n</code></pre></p> </li> <li> <p>Modifica el puerto del servicio SSH para que escuche por el 2222. <pre><code>vi /etc/ssh/sshd_config\n\nPort 22\nPort 2222\n</code></pre></p> </li> <li> <p>Realiza las modificaciones necesarias para que al conectarte al ssh de tu m\u00e1quina virtual no te pida contrase\u00f1a.</p> </li> </ol> <pre><code>1- Como usuario hadoop:\nssh-keygen -t rsa\n(Enter a todo)\n\ncd .ssh\n\nssh-copy-id -i id_rsa.pub hadoop@localhost\n</code></pre> <p>A partir de este momento, podremos ejecutar como usuario hadoop el comando: <code>ssh root@localhost</code>  Y no ser\u00e1 necesario escribir ninguna contrase\u00f1a</p>"},{"location":"UD00/3.ssh/","title":"Varios: ssh - scp - screen - sshfs","text":""},{"location":"UD00/3.ssh/#1-ssh","title":"1. ssh","text":"<p>A la m\u00e1quina virtual podemos acceder de dos formas:</p> <ol> <li>Desde la misma m\u00e1quina virtual.</li> <li>A trav\u00e9s de ssh (debe estar el servicio activo).</li> </ol> <pre><code># Para comprobar que est\u00e1 activo el servicio, desde la m\u00e1quina virtual ejecutamos\n$ ssh localhost\n$ systemctl status ssh # otra manera de comprobarlo\n\n# Si el servicio no est\u00e1 activo lo activamos con (como root)\n/sbin/service ssh start\n\n# Para que se inicie siempre que reiniciemos\nsystemctl enable ssh\n\n# ssh nombre_de_usuario@ip_maquina\n$ ssh user@192.168.64.14\n\n# para salir de la conexi\u00f3n ssh (ctrl + d) o el comando\n$ exit\n\n# Intenta acceder a la m\u00e1quina virtual como root\n$ ssh root@192.168.64.14\n</code></pre> <p>\u270f\ufe0f Ejercicios</p> <pre><code>1. Modifica la configuraci\u00f3n del servidor SSH para que se pueda acceder como root.\nEl usuario hadoop ha de poder iniciar sesi\u00f3n como root sin contrase\u00f1a.\n\n2. Modifica el puerto del servicio SSH para que escuche por el 2222.\n</code></pre>"},{"location":"UD00/3.ssh/#2-scp","title":"2. scp","text":"<p>Se utiliza para copiar archivos y directorios de forma segura entre sistemas remotos a trav\u00e9s de SSH (Secure Shell). Es especialmente \u00fatil para transferir archivos de un sistema local a uno remoto o viceversa de manera segura y eficiente.</p> <p>Principales opciones:</p> <ul> <li><code>r</code>: Copia directorios y sus contenidos de manera recursiva.</li> <li><code>P</code>: Especifica el puerto SSH a utilizar.</li> <li><code>i</code>: Permite especificar un archivo de clave privada en lugar de la clave por defecto.</li> <li><code>v</code>: Ejecuta <code>scp</code> en modo verbose para obtener informaci\u00f3n detallada sobre la transferencia.</li> </ul> <pre><code># Copiar un archivo local a un servidor remoto\nscp archivo.txt usuario@servidor.com:/ruta/destino/\n\n# Copiar un archivo remoto a la m\u00e1quina local\nscp usuario@servidor.com:/ruta/archivo-remoto.txt /ruta/local/\n\n# Copiar un directorio y su contenido de manera recursiva\nscp -r directorio_local/ usuario@servidor.com:/ruta/destino/\n</code></pre>"},{"location":"UD00/3.ssh/#3-screen","title":"3. screen","text":"<p>Permite crear sesiones de terminal multiplexadas en sistemas Unix y Linux. Esto significa que puedes iniciar m\u00faltiples sesiones de terminal dentro de una sola ventana y alternar entre ellas. Adem\u00e1s, las sesiones de <code>screen</code> pueden ejecutarse en segundo plano, lo que permite desacoplarlas de la sesi\u00f3n de terminal actual.</p> <p>La principal ventaja de <code>screen</code> es que podemos:</p> <ul> <li>Conectarnos a un servidor ssh.</li> <li>Ejecutar un proceso largo.</li> <li>Salir del servidor ssh (el proceso continua ejecut\u00e1ndose).</li> <li>Volver a conectar al servidor ssh y recuperar la ejecuci\u00f3n anterior.</li> </ul> <p>Hold a session open on a remote server. Manage multiple windows with a single SSH connection.</p> <p>Start a new screen session: <code>screen</code></p> <p>Start a new named screen session: <code>screen -S session_name</code></p> <p>Start a new daemon and log the output to <code>screenlog.x</code>:  <code>screen -dmLS session_name command</code></p> <p>Show open screen sessions: <code>screen -ls</code></p> <p>Reattach to an open screen: <code>screen -r session_name</code></p> <p>Detach from inside a screen: <code>Ctrl + A, D</code></p> <p>Kill the current screen session: <code>Ctrl + A, K</code></p> <p>Kill a detached screen: <code>screen -X -S session_name quit</code></p> <p>M\u00e1s info: https://www.youtube.com/watch?v=_ZJiEX4rmN4</p> <pre><code>$ sudo apt install screen\n$ screen \u2013version\n</code></pre> <pre><code># Iniciamos\n$ screen\n\n# Alternativa: Tambi\u00e9n podemos iniciar una sesi\u00f3n y darle un nombre\n# usando la variable -S. Por ejemplo\n$ screen -S session1\n</code></pre> <p>Comandos para realizar la multiplexaci\u00f3n de la terminal. </p>"},{"location":"UD00/3.ssh/#ejercicio","title":"Ejercicio","text":"<pre><code>- Realiza las modificaciones necesarias para que al conectarte al ssh de tu m\u00e1quina virtual no te pida contrase\u00f1a.\n</code></pre>"},{"location":"UD00/3.ssh/#4-sshfs","title":"4. sshfs","text":"<p><code>sshfs</code> nos permite montar carpetas de m\u00e1quinas remotas a trav\u00e9s de ssh.</p> <p>https://www.digitalocean.com/community/tutorials/how-to-use-sshfs-to-mount-remote-file-systems-over-ssh</p> <p>Instalaci\u00f3n en m\u00e1quina remota</p> <pre><code>apt update\n\napt install sshfs\n</code></pre> <p>Montar en local</p> <pre><code>sudo mkdir /mnt/remoto\n\nsudo sshfs -o allow_other,default_permissions sammy@your_other_server:~/ /mnt/droplet\n\nsudo umount /mnt/droplet\n</code></pre> <ul> <li><code>o</code>\u00a0precedes miscellaneous mount options (this is the same as when running the\u00a0<code>mount</code>\u00a0command normally for non-SSH disk mounts). In this case, you are using\u00a0<code>allow_other</code>\u00a0to allow other users to have access to this mount (so that it behaves like a normal disk mount, as\u00a0<code>sshfs</code>\u00a0prevents this by default), and\u00a0<code>default_permissions</code>\u00a0(so that it otherwise uses regular filesystem permissions).</li> <li><code>sammy@your_other_server:~/</code>\u00a0provides the full path to the remote directory, including the remote username,\u00a0<code>sammy</code>, the remote server,\u00a0<code>your_other_server</code>, and the path, in this case\u00a0<code>~/</code>\u00a0for the remote user\u2019s home directory. This uses the same syntax as SSH or SCP.</li> <li><code>/mnt/droplet</code>\u00a0is the path to the local directory being used as a mount point.</li> </ul>"},{"location":"UD00/3.ssh/#5-open-vpn","title":"5. Open VPN","text":"<p>Script que nos facilita la instalaci\u00f3n de una VPN</p> <p>https://github.com/Nyr/openvpn-install</p>"},{"location":"UD00/4.BashScripting/","title":"Creaci\u00f3n de scripts en bash","text":""},{"location":"UD00/4.BashScripting/#1-introduccion","title":"1. Introducci\u00f3n","text":"<p>Un script es un archivo de texto que contiene una serie de comandos y/o instrucciones que se pueden ejecutar de manera secuencial para realizar una tarea espec\u00edfica o automatizar una serie de tareas. Estos scripts generalmente est\u00e1n escritos en lenguajes de scripting como Bash, Python, Perl o incluso lenguajes de programaci\u00f3n como C o C++.</p> <p><code>copia_seguridad.sh</code></p> <pre><code>#!/bin/bash\n\n# Definir directorio de origen y destino\ndirectorios_origen=\"/ruta/del/directorio/a/copiar\"\ndirectorio_destino=\"/ruta/del/directorio/de/destino\"\n\n# Crear un nombre de archivo con marca de tiempo\nfecha=$(date +\"%Y%m%d%H%M%S\")\nnombre_archivo_backup=\"backup_$fecha.tar.gz\"\n\n# Crear una copia de seguridad comprimida con tar\ntar -czvf \"$directorio_destino/$nombre_archivo_backup\" \"$directorios_origen\"\n\n# Verificar si la operaci\u00f3n de copia de seguridad fue exitosa\nif [ $? -eq 0 ]; then\n  echo \"Copia de seguridad completada con \u00e9xito en $nombre_archivo_backup\"\nelse\n  echo \"Error al realizar la copia de seguridad\"\nfi\n</code></pre> <p>Para ejecutar un script, hemos de darle permisos de ejecuci\u00f3n:</p> <pre><code>chmod +x copia_seguridad.sh # le damos permisos de ejecuci\u00f3n\n./copia_seguridad.sh # lo ejecutamos\n</code></pre>"},{"location":"UD00/4.BashScripting/#binbash","title":"#!/bin/bash","text":"<p>Al iniciar un script ponemos en la primera l\u00ednea #!/bin/bash, \u00bfPor qu\u00e9?</p> <p>La l\u00ednea #!/bin/bash al principio de un script en Bash es conocida como \"shebang\" o \"hashbang\". </p> <p>Si ejecutas un script como <code>./nombre-del-scrip.extension</code>, el sistema buscar\u00e1 en la l\u00ednea superior del archivo para determinar el int\u00e9rprete,  (generalmente <code>/bin/bash</code>) y utiliza ese programa para interpretar y ejecutar el script. Esto es especialmente \u00fatil cuando tienes varios int\u00e9rpretes de comandos disponibles en tu sistema (por ejemplo, Bash, sh, zsh, etc.), y deseas asegurarte de que el script sea ejecutado con un int\u00e9rprete espec\u00edfico.</p> <p>Al ejecutar el script como <code>bash nombre_del_script.sh</code>, la primera l\u00ednea se ignorar\u00e1.</p> <pre><code>**Ejecuci\u00f3n de un script**\n$ bash script.sh  # Ejecuci\u00f3n modo 1\n\n$ ./script.sh # Ejecuci\u00f3n modo 2 falla no tiene permisos\nzsh: permission denied: ./script.sh\n$ chmod +x script.sh\n$ ./script.sh # OK\n</code></pre>"},{"location":"UD00/4.BashScripting/#caracteres-especiales","title":"Car\u00e1cteres especiales","text":"<p># Comentarios</p> <p>Las l\u00edneas que comienzan con # (con excepci\u00f3n del primer #!) son comentarios y no ser\u00e1n interpretadas</p> <pre><code># echo \"Esta linea no se imprime por pantalla\"\n</code></pre> <p>; Separador de comandos</p> <pre><code>echo \"hola\"; ls\n\necho \"HOLA\"; \"ADIOS\"\n\nif [ -f file.txt ]; then\n    echo \"SI\"\nfi; echo \"Comparaci\u00f3n finalizada\"\n</code></pre> <p>$ Mostrar el contenido de una variable</p> <pre><code>var1=5 # sin espacios\necho $var1 #5\n</code></pre> <p>| pipe</p> <p>Redirige la salida de un comando a la entrada del siguiente, encadena \u00f3rdenes y comandos.</p> <pre><code>ls -la | wc -l\n</code></pre> <p>Otros <pre><code>${ } \u2192 \u00a0permite referenciar, modificar, o manipular variables\n$? \u2192 Hace referencia al \u00faltimo comando ejecutado, si contiene un 0 la ejecuci\u00f3n ha sido correcta, si es distinto de 0 hubo alg\u00fan error en la ejecuci\u00f3n del comando anterior.\n$! \u2192 Contiene el ID del proceso del \u00faltimo proceso subordinado. Resulta \u00fatil cuando un shellscript necesita eliminar un proceso subordinado que ha iniciado previamente.\n$_ \u2192 Devuelve el argumento final del comando previo ejecutado\n$$ \u2192 Contiene el PID del proceso\n\\ \u2192 (escape) Hace que el shell interprete el car\u00e1cter de forma literal\n\\n \u2192 Nueva l\u00ednea\n\\t \u2192 Tabulador\n&gt; &amp;&gt; &gt;&amp; &gt;&gt; &lt; \u2192 Redirecci\u00f3n\n</code></pre></p> <pre><code>name=\"Mundo\"\necho \"Hola ${name}!\" -&gt; pa\necho \"${text:0:3}\" -&gt; extracci\u00f3n texto\necho \"${var:-ValorPorDefecto}\"\n</code></pre> <pre><code>#!/bin/bash\nname=\"Usuario\"\ndirectory=\"/home/${name}/documentos\"\necho \"Hola ${name}, tu directorio es: ${directory}\"\necho \"Longitud del nombre: ${#name}\"\necho \"Tu nombre en min\u00fasculas: ${name,,}\"\u00a0 # \"usuario\"\necho \"Primeras 3 letras de tu nombre: ${name:0:3}\"\n</code></pre> <pre><code>#!/bin/bash\nsleep 30 &amp;\npid=$!\necho \"El proceso en segundo plano tiene el PID: $pid\"\nps -p $pid\n</code></pre> <pre><code>cp archivo1.txt archivo2.txt\necho \"Archivo copiado: $_\"\n</code></pre> <pre><code>#!/bin/bash\ntouch ejemplo.txt\necho \"Archivo creado: $_\"\necho \"Hola Bash\" &gt;&gt; $_\necho \"Contenido agregado a: $_\"\ncat $_\n</code></pre>"},{"location":"UD00/4.BashScripting/#2-variables-y-argumentos","title":"2.  Variables y argumentos","text":""},{"location":"UD00/4.BashScripting/#variables","title":"Variables","text":"<p>Se crean mediante una asignaci\u00f3n sin espacios. El shell es \u201ccase sensitive\u201d, sensible a may\u00fasculas y min\u00fasculas (a y A son distintas) Se accede a su valor anteponiendo $</p> <pre><code>$ a=\"hola\"\n$ b=20\n$ echo $A\n$ echo $a $b\n$ echo $a \\$b\n</code></pre> <p>Variables y comillas Comillas simples, los car\u00e1cteres especiales no se interpretan. Comillas dobles, permiten la interpretaci\u00f3n de car\u00e1cteres especiales como \u201c$\u201d (permiten mostrar el valor de una variable\u201d Comillas inversas: permiten asignar el resultado de una ejecuci\u00f3n de una orden (subshell), igual que con $( )</p> <pre><code>$ a=20; b='Variable: $a'\n$ echo $b\n---\n$ a=30; b=\"Variable: $a\"\n$ echo $b\n---\nd=`date`\necho $d\n</code></pre>"},{"location":"UD00/4.BashScripting/#variables-predefinidas","title":"Variables predefinidas","text":"<p>Crea y ejecuta el siguiente script (variables_predefinidas.sh) <pre><code>echo $HOME\necho $PATH\necho $PWD\necho $RANDOM\necho $LOGNAME\necho $UID\necho $HOSTNAME\n</code></pre></p>"},{"location":"UD00/4.BashScripting/#ejercicio","title":"\u270f\ufe0f Ejercicio","text":"<pre><code>Busca un comando que muestre todas las variables predefinidas\n</code></pre>"},{"location":"UD00/4.BashScripting/#parametros-argumentos","title":"Par\u00e1metros - argumentos","text":"<p>Al ejecutar un script podemos acceder a cada uno de los argumentos de la llamada del mismo </p>"},{"location":"UD00/4.BashScripting/#ejercicio_1","title":"\u270f\ufe0f Ejercicio","text":"<p>Copia y ejecuta el siguiente script <code>argumentos.sh</code> <pre><code>#!/bin/bash\necho '$_' $_\necho '$0' $0\necho '$1' $1\necho '$2' $2\necho '$3' $3\necho '$*' $*\necho '$@' $@\necho '$#' $#\necho '$_' $_\necho '$$' $$\necho '$?' $?\n</code></pre></p> <p>Ejecuta el script utilizando diferentes argumentos: <code>./argumentos.sh hola</code> <code>./argumentos.sh hola adios</code> <code>./argumentos.sh hola 123 asdf</code></p>"},{"location":"UD00/4.BashScripting/#3-condicionales","title":"3. Condicionales","text":"<p>Permiten decidir entre una o varias opciones seg\u00fan una condici\u00f3n l\u00f3gica. <pre><code>if [ 1 = 1]; then # Se suele poner el ; as\u00ed el then no queda en la l\u00ednea de abajo\n    echo \"Son iguales\"\nfi\n##########################################\nif [ 2 = 1]; then\n    echo \"Son iguales\"\nelse\n    echo \"Son distintos\"\nfi\n</code></pre></p> <p>Hay varias formas de especificar la condici\u00f3n l\u00f3gica Instrucci\u00f3n de test b\u00e1sica <code>[]</code> \u2192 Instrucciones simples <pre><code>if [$# -lt 3] &amp;&amp; [-a \"$2\"]; then\n</code></pre></p> <p>Instrucci\u00f3n de test extendida <code>[[]]</code> \u2192 Permite combinar varias expresiones, previene la separaci\u00f3n de palabras y la expansi\u00f3n de comodines <pre><code>if [[ $# -lt 3 &amp;&amp; -a $2 ]]; then ...\n</code></pre></p>"},{"location":"UD00/4.BashScripting/#operadores-condicionales","title":"Operadores condicionales","text":"<p>Enteros</p> <p></p> <p>Ficheros</p> <p></p> <p>Cadenas</p> <p></p> <p>Podemos utilizar &lt; y &gt; dentro del constructor [[./4.BashScripting]]</p>"},{"location":"UD00/4.BashScripting/#operadores-logicos","title":"Operadores l\u00f3gicos","text":"<p> Dentro del constructor <code>[[]]</code> se pueden utilizar &amp;&amp; y ||</p>"},{"location":"UD00/4.BashScripting/#condicional-multiple-case","title":"Condicional m\u00faltiple case","text":"<p>Copia y ejecuta el siguiente script: <pre><code>echo \"Est\u00e1s seguro (s/n)? [n]\"\nread resp\ncase ${resp} in\n    [sS]) echo \"En fin, t\u00fa lo has querido...\" ;;\n    n|N) echo \"Estupendo, menos trabajo!\";;\n    *) echo \"Voy a considerar eso como un no!\";;\nesac\n</code></pre></p>"},{"location":"UD00/4.BashScripting/#ejercicios","title":"\u270f\ufe0f Ejercicios","text":"<pre><code>1. Crea un script al que se le pasen 2 argumentos (n\u00fameros, no validar) y nos diga cu\u00e1l es el mayor.\n2. Modifica el script para en vez de pasar 2 argumentos nos los pida. (comando read)\n3. Crea un script al que se le pase un argumento que sea un nombre de fichero y compruebe  si existe.\n4. Crea un script al que se le pase un argumento que sea un nombre de directorio y  compruebe si existe.\n5. Crea un script al que se le pasen 2 argumentos, un fichero y un directorio y compruebe si existen (utilizando operadores l\u00f3gicos). Respuestas: Los 2 existen, Los 2 no existen.\n6. Modifica el script que hemos utilizado en el punto 3.3 para que tambi\u00e9n acepte como respuesta \u201csi\u201d \u201cSI\u201d \u201cno\u201d \u201cNO\u201d y otras variaciones\n</code></pre>"},{"location":"UD00/4.BashScripting/#4-bucles","title":"4. Bucles","text":"<p>Iteran mientras o hasta que se cumple una condici\u00f3n. La instrucci\u00f3n de test o expresi\u00f3n l\u00f3gica se expresa de la misma manera que con las condiciones, por lo que podemos hacer test de \"si existe un archivo y es ejecutable\" o \"si el archivo existe y es un enlace simb\u00f3lico\" por ejemplo.</p>"},{"location":"UD00/4.BashScripting/#while-until","title":"While - until","text":"<pre><code>while [ expresi\u00f3n\u00a0]; do\n    echo \"Comandos a ejecutar\"\ndone\n\nuntil [ expresi\u00f3n ]; do\n    echo \"Comandos a ejecutar\"\ndone\n</code></pre> <pre><code>#!/bin/bash\nvar0=0\nLIMIT=10\n\nwhile [ $var0 -lt $LIMIT ]; do\n  echo -n $var0\n  let var0++\ndone\n</code></pre>"},{"location":"UD00/4.BashScripting/#tipo-for","title":"Tipo for","text":"<p>Opci\u00f3n 1, iterar sobre una lista</p> <pre><code>for item in &lt;lista&gt;; do\n    echo \"Comandos a ejecutar\"\ndone\n</code></pre> <pre><code>for i in 1 4 6 7; do\n    echo $i\ndone\n\nfor d in $(ls); do\n    echo $d\ndone\n</code></pre>"},{"location":"UD00/4.BashScripting/#ejercicios_1","title":"\u270f\ufe0f Ejercicios","text":"<pre><code>1. Crea un script que nos pida 10 n\u00fameros y los sume.\n2. Crea un script que imprima y sume 50 n\u00fameros aleatorios.\n3. Crea un script que nos muestre los n\u00fameros pares del 1 al 100.\n</code></pre>"},{"location":"UD00/4.BashScripting/#utilidades-de-los-bucles","title":"Utilidades de los bucles","text":"<p>Gracias a que los bucles pueden recorrer listas, podemos ejecutarlos para recorrer la salida de otros comandos:</p> <pre><code>## Recorrer los ficheros y directorios de la carpeta actual\nfor i in $(ls); do\n  echo $i\ndone\n\n----------------------\n## Recorrer los par\u00e1metros que se le pasan.\nfor i in \"$@\"; do\n   if ! [ -d ./$i ]; then\n       echo \"Directorio \\\"$i\\\" no existe en este lugar\"\n       exit 2\n   fi\ndone\n</code></pre>"},{"location":"UD00/4.BashScripting/#ejercicios_2","title":"\u270f\ufe0f Ejercicios","text":"<pre><code>1. Crea un script que verifique si hay **directorios** en la carpeta actual desde donde se ejecuta el script (no hay que considerar a punto y punto punto como directorio).\n\n2. Crea un script que muestre el nombre de usuario de todos los usuarios del sistema que tengan una shell v\u00e1lida. (hay que comprobar que la shell existe)\nSi un usuario tiene como shel (/bin/xxxx) no lo mostrar\u00e1.\n</code></pre>"},{"location":"UD00/4.BashScripting/#5-funciones","title":"5. Funciones","text":"<pre><code>#!/bin/bash\n# funcion-error arg1 arg2 (imprime el mayor entre 2 valores)\nfunction error () {\n    msg=$1 # Pase de par\u00e1metros (posicional) echo $msg\n    exit 1\n}\nif [ ! $1 ] || [ ! $2 ] then\n    error \"Error! Uso correcto: mayor arg1 arg2\"\nfi\nif [ $1 -gt $2 ]; then echo $1; else echo $2 \nfi\n</code></pre> <pre><code>#!/bin/bash\n# funcion-mayor arg1 arg2 (imprime el mayor entre 2 valores)\nfunction mayor () {\n    x=$1; y=$2 # Pase de par\u00e1metros (posicional) \n    if [ $x -gt $y ]; then\n        echo $x \n    else\n        echo $y \n    fi\n    return 0 # Retorno de la orden, no valor de salida \n}\n\nresultado=$(mayor $1 $2) # Se invoca como una orden para recuperar el valor de retorno\necho $resultado\n</code></pre>"},{"location":"UD00/4.BashScripting/#6-otros","title":"6. Otros","text":""},{"location":"UD00/4.BashScripting/#obtener-valores-pipeline-desde-script","title":"Obtener valores pipeline desde script","text":"<p>https://stackoverflow.com/questions/19408649/pipe-input-into-a-script/46726373#46726373 Podemos recoger lo que nos llega de una tuber\u00eda (PIPE) en un script bash: <pre><code>printf \"stuff\\nmore stuff\\n\" &gt; test.txt\n\ncat test.txt | ./testPipe.sh\n</code></pre></p> <pre><code>#!/bin/bash\n# Check to see if a pipe exists on stdin.\n# Filename testPipe.sh\nif [ -p /dev/stdin ]; then\n        echo \"Data was piped to this script!\"\n        # If we want to read the input line by line\n        while IFS= read line; do\n                echo \"Line: ${line}\"\n        done\n        # Or if we want to simply grab all the data, we can simply use cat instead\n        # cat\nelse\n        echo \"No input was found on stdin, skipping!\"\n        # Checking to ensure a filename was specified and that it exists\n        if [ -f \"$1\" ]; then\n                echo \"Filename specified: ${1}\"\n                echo \"Doing things now..\"\n        else\n                echo \"No input given!\"\n        fi\nfi\n</code></pre>"},{"location":"UD00/4.BashScripting/#7-comandos-avanzados","title":"7. Comandos avanzados","text":""},{"location":"UD00/4.BashScripting/#grep","title":"grep","text":"<p>Ya no se utiliza egrep Busca palabras o patrones en el contenido de uno o varios ficheros y vuelca por su salida las l\u00edneas que contienen dichas palabras o patrones.</p> <pre><code>grep [-inHv] patr\u00f3n [ficheros(s)]\n\n-i ignora la diferencia entre may\u00fasculas y min\u00fasculas \n-n imprime la l\u00ednea del fichero\n-H imprime el nombre del fichero\n-v b\u00fasqueda inversa (l\u00edneas que no contienen el patr\u00f3n)\n\n**tldr**\n- Search for a pattern within a file:\n    grep \"search_pattern\" path/to/file\n\n- Search for an exact string (disables regular expressions):\n    grep --fixed-strings \"exact_string\" path/to/file\n\n- Search for a pattern in all files recursively in a directory, showing line numbers of matches, ignoring binary files:\n    grep --recursive --line-number --binary-files=without-match \"search_pattern\" path/to/directory\n\n- Use extended regular expressions (supports `?`, `+`, `{}`, `()` and `|`), in case-insensitive mode:\n    grep --extended-regexp --ignore-case \"search_pattern\" path/to/file\n\n- Print 3 lines of context around, before, or after each match:\n    grep --context|before-context|after-context=3 \"search_pattern\" path/to/file\n\n- Print file name and line number for each match with color output:\n    grep --with-filename --line-number --color=always \"search_pattern\" path/to/file\n\n- Search for lines matching a pattern, printing only the matched text:\n    grep --only-matching \"search_pattern\" path/to/file\n\n- Search `stdin` for lines that do not match a pattern:\n    cat path/to/file | grep --invert-match \"search_pattern\"\n</code></pre> <p>Ejemplos:</p> <pre><code>- Busca la palabra \u201cnombre\u201d en los ficheros con extensi\u00f3n txt: \n$ grep -Hn nombre *.txt\n\n- Busca las l\u00edneas que comienzan por \u201ca\u201d o \u201cc\u201d may\u00fasculas o min\u00fasculas: \n$ grep -iHn ^[ac] *.txt\n\n- Busca l\u00edneas que terminan por una coma: \n$ grep -Hn ,$ *.txt\n\n- Busca l\u00edneas que no contienen un punto: \n$ grep -Hnv '\\.' *.txt\n</code></pre> <p>El car\u00e1cter \u201c.\u201d tiene un significado especial para el shell y para grep. Las comillas simples evitan la interpretaci\u00f3n por el shell, y la \u201c\\\u201d por grep.</p>"},{"location":"UD00/4.BashScripting/#find","title":"find","text":"<p>Permite explorar el sistema de archivos - Habitualmente se utiliza para localizar aquellos ficheros o directorios que cumplen con una condici\u00f3n. - Adicionalmente, pueden ejecutar acciones sobre ellos.</p> <p>Es \u00fatil en combinaci\u00f3n con bucles for o while.</p> <pre><code>**tldr**\n\n- Find files by extension:\n    find root_path -name '*.txt'\n\n- Find files matching multiple path/name patterns:\n    find root_path -path '**/path/**/*.ext' -or -name '*pattern*'\n\n- Find directories matching a given name, in case-insensitive mode:\n    find root_path -type d -iname '*lib*'\n\n- Find files matching a given pattern, excluding specific paths:\n    find root_path -name '*.py' -not -path '*/site-packages/*'\n\n- Find files matching a given size range, limiting the recursive depth to \"1\":\n    find root_path -maxdepth 1 -size +500k -size -10M\n\n- Run a command for each file (use `{}` within the command to access the filename):\n    find root_path -name '*.txt' -exec wc -l {} \\;\n\n- Find files modified in the last 7 days:\n    find root_path -daystart -mtime -7\n\n- Find empty (0 byte) files and delete them:\n    find root_path -type f -empty -delete\n</code></pre> <p>Ejemplos:</p> <pre><code>find . -type f -print\n\nfind . -name \\*.txt -exec basename {} \\;\n\n------- OTROS -------\n\nfind . -empty -type d\nfind . -empty -type f\nfind . -size +10M\n  * c: bytes, k:Kb, M:Mb, G:Gb\nfind . -type f -mmin -5\nfind . -perm 777\nfind . -maxdepth 1 -type f\n\nhttps://ciberninjas.com/15-ejemplos-del-comando-find-en-linux/\n</code></pre> <p>Ejecuta el siguente script <code>find-bucles.sh</code></p> <pre><code>#!/bin/bash\n# find-bucles.sh, 3 versiones alternativas\ndir=$HOME\n\necho \"Versi\u00f3n 1 ----------------------------\"\nfind $dir -name \\*.txt -exec grep -inH nombre {} \\;\n\necho \"Versi\u00f3n 2 ----------------------------\" \nfind $dir -name \\*.txt  -print | while read f do\n       grep -inH nombre $f\ndone\n\necho \"Versi\u00f3n 3 ----------------------------\" \noldifs=$IFS\nIFS=$'\\n'\nfor f in $(find $dir -name \\*.txt  -maxdepth 1 -print) do\n       grep -inH nombre $f\ndone\nIFS=$oldifs\n</code></pre> <p>Contesta a las siguientes preguntas: <pre><code>1. \u00bfQu\u00e9 diferencia hay en cada una?\n2. \u00bfPara qu\u00e9 se ha utilizado \u201cIFS\u201d?\n</code></pre></p>"},{"location":"UD00/4.BashScripting/#ejercicios_3","title":"\u270f\ufe0f Ejercicios","text":"<p>Creaci\u00f3n de ficheros y directorios para hacer las pr\u00e1cticas, ejecuta cada uno de los siguientes comandos para preparar el entorno para los ejercicios:</p> <pre><code>mkdir ~/find_grep\ncd ~/find_grep\n\nwget https://gist.githubusercontent.com/jsdario/6d6c69398cb0c73111e49f1218960f79/raw/8d4fc4548d437e2a7203a5aeeace5477f598827d/el_quijote.txt\nmv el_quijote.txt ..\n\nmkdir dir{uno,2,tres,4,5}\nls\n\nsplit -n 50 -d ../el_quijote.txt quijote\nfor f in ./quijote??; do mv $f diruno/\"$f.txt\"; done\n\nsplit -n 20 -d ../el_quijote.txt el_qui\nfor f in ./el_qui??; do mv $f dir2/\"$f.doc\"; done\n\nwget https://gutenberg.org/cache/epub/84/pg84.txt -O ../Frankenstein.txt\n\nsplit -n 60 -d ../Frankenstein.txt Frankenstein.libro.completo.\nfor f in Frankenstein.libro.completo.??; do mv $f dirtres/\"$f.txt.avi\"; done\n\n## Dir 4\nCorta el libro de Frankenstein en fragmentos de 1000 l\u00edneas, mu\u00e9velos a la carpeta \ndir4,\nel nombre de archivo ser\u00e1: \"The_modern_Prometheus\" seguido de la numeraci\u00f3n \nque pone split\nCambia o pon la extensi\u00f3n .docx\n\ntouch sin_contenido.txt\ndd if=/dev/urandom of=fich20mb bs=1M count=20\n</code></pre> <p>\u270f\ufe0f EJERCICIOS find - grep</p> <pre><code>#### FIND\n1. Busca el archivo Frankenstein.libro.completo.31.txt.avi\n2. Buscar el archivo QUIJOTE14.txt sin importar si est\u00e1 escrito en may\u00fasculas o min\u00fasculas\n3. Busca todos los archivos que terminen en .doc o en .txt\n4. Busca directorios vac\u00edos\n5. Busca si existe alg\u00fan fichero vac\u00edo\n6. Busca si existe alg\u00fan fichero de m\u00e1s de 10 Mb\n7. Ejecuta el comando `touch archivo.txt`\n     Busca los archivos que se han modificado en los \u00faltimos 5 minutos\n8. Ejecuta el comando `chmod 777 dirtres/Frankenstein.libro.completo.18.txt.avi`\n     Busca alg\u00fan archivo con permisos 777\n9. Busca los archivos del directorio actual\n10. Ejecuta:\n        mkdir dir6\n      cd dir6\n    touch archivo{0..100}\n    ls\n    A\u00f1ade la extensi\u00f3n .txt a todos estos archivos\n\n#### GREP\n\n#### FIND + GREP\n</code></pre>"},{"location":"UD00/4.BashScripting/#resumen","title":"Resumen","text":""},{"location":"UD00/5.BashEjercicios-soluciones/","title":"Ejercicios Bash","text":""},{"location":"UD00/5.BashEjercicios-soluciones/#ejercicio-1-solucion","title":"Ejercicio 1 Soluci\u00f3n","text":"<p>Falta revisar. ```bash     #!/bin/bash     if [ $# -ne 2 ]; then         echo \"Error parametros\"         exit 1     fi     # Comprobar puedo leer fichero     if [[ ! -r $1 || ! -r $2 ]]; then         echo 'e'     fi     #no funciona en mac, problema espacios al principio     #LINEAS_UNO=$( wc -l $1 | cut -d \" \" -f 1)     LINEAS_UNO=$( cat $1 | wc -l | tr -d \" \")     LINEAS_DOS=$( cat $2 | wc -l | tr -d \" \")     CAR_UNO=$( cat $1 | wc -c | tr -d \" \")     CAR_DOS=$( cat $2 | wc -c | tr -d \" \")</p> <pre><code>if [[ $LINEAS_UNO -gt $LINEAS_DOS ]]; then\n    echo \"$1 ($LINEAS_UNO) tiene m\u00e1s l\u00edneas que $2 ($LINEAS_DOS)\"\nelif [[ $LINEAS_UNO -lt $LINEAS_DOS ]]; then\n    echo \"$1 ($LINEAS_UNO) tiene menos l\u00edneas que $2 ($LINEAS_DOS)\"\nelse\n    echo \"$1 ($LINEAS_UNO) tiene las mismas l\u00edneas que $2 ($LINEAS_DOS)\"\nfi\n\nexit 0\n```\n</code></pre>"},{"location":"UD00/5.BashEjercicios-soluciones/#ejercicio-2-solucion","title":"Ejercicio 2 Soluci\u00f3n","text":""},{"location":"UD00/5.BashEjercicios-soluciones/#ejercicio-3-solucion","title":"Ejercicio 3 Soluci\u00f3n","text":"<p>```bash     #!/bin/bash</p> <pre><code>echo -e \"Nombre a buscar:\"\nread usuario\n\negrep ${usuario}: /etc/passwd &amp;&gt;/dev/null\n```\n</code></pre>"},{"location":"UD00/5.BashEjercicios-soluciones/#ejercicio-4-solucion","title":"Ejercicio 4 Soluci\u00f3n","text":""},{"location":"UD00/5.BashEjercicios-soluciones/#ejercicio-5-solucion","title":"Ejercicio 5 Soluci\u00f3n","text":""},{"location":"UD00/5.BashEjercicios-soluciones/#ejercicio-6-solucion","title":"Ejercicio 6 Soluci\u00f3n","text":""},{"location":"UD00/5.BashEjercicios-soluciones/#ejercicio-7-solucion","title":"Ejercicio 7 Soluci\u00f3n","text":""},{"location":"UD00/5.BashEjercicios-soluciones/#ejercicio-8-solucion","title":"Ejercicio 8 Soluci\u00f3n","text":""},{"location":"UD00/5.BashEjercicios-soluciones/#ejercicio-9-solucion","title":"Ejercicio 9 Soluci\u00f3n","text":""},{"location":"UD00/5.BashEjercicios-soluciones/#ejercicio-10-solucion","title":"Ejercicio 10 Soluci\u00f3n","text":""},{"location":"UD00/5.BashEjercicios/","title":"Ejercicios Bash","text":""},{"location":"UD00/5.BashEjercicios/#ejercicio-1","title":"Ejercicio 1","text":"<p>Crear un programa al que se le pasen 2 ficheros de texto y diga cu\u00e1l es el que tiene m\u00e1s l\u00edneas.</p> <ul> <li>Debe asegurarse que se le pasan 2 argumentos, que son ficheros de texto y que existen.</li> <li>PISTA: comando <code>wc</code></li> </ul> <pre><code>#### Lo ejecutaremos de la siguiente manera:\n\n./cuenta_lineas.sh fichero1 fichero2\n</code></pre> <p>1b. Modifica el programa para que, si no le pasamos ning\u00fan par\u00e1metro nos pida el nombre de los 2 ficheros.</p>"},{"location":"UD00/5.BashEjercicios/#ejercicio-2","title":"Ejercicio 2","text":"<p>Realiza un script que lea un valor entero que representa una nota hasta que se escriba la palabra SALIR.</p> <ul> <li>compruebe si est\u00e1 en el rango adecuado (0 a 10)</li> <li>Si lo est\u00e1, debe imprimirlo en modo texto (suspendido, suficiente, notable, sobresaliente...)</li> <li>Si no lo est\u00e1, debe mostrar un mensaje de error.</li> <li>Si no se introduce ning\u00fan n\u00famero, el script debe asumir un valor por defecto de 0.</li> </ul>"},{"location":"UD00/5.BashEjercicios/#ejercicio-3","title":"Ejercicio 3","text":"<p>Crea un script que pregunte por un nombre de usuario y que devuelva por pantalla si existe o no en el sistema.</p>"},{"location":"UD00/5.BashEjercicios/#ejercicio-4","title":"Ejercicio 4","text":"<p>Crear una tarea peri\u00f3dica para que cada 1 minutos, cree un archivo en /tmp/informe El nombre del archivo ser\u00e1, anyo-mes-dia_hora:minutos:segundos.txt En el archivo habr\u00e1 informaci\u00f3n del sistema en ese momento:  - total procesos en ejecuci\u00f3n, memoria disponible, almacenamiento, total de usuarios logueados, etc... Tambi\u00e9n contendr\u00e1 informaci\u00f3n sobre si hay determinados procesos en marcha en ese momento:  - sshd  - systemd  - top</p>"},{"location":"UD00/5.BashEjercicios/#ejercicio-5","title":"Ejercicio 5","text":"<p>Lee una secuencia de l\u00edneas de su entrada enviadas desde una tuber\u00eda mediante <code>cat fichero</code> - Divide las l\u00edneas en palabras - Elimina los posibles signos de puntuaci\u00f3n (comas, puntos, exclamaciones) - Muestra cada una de las palabras</p>"},{"location":"UD00/5.BashEjercicios/#ejercicio-6","title":"Ejercicio 6","text":"<p>Realiza una copia de seguridad de los archivos de $HOME</p> <ul> <li>La copia debe hacerse en /tmp/$HOME/</li> <li>Si es la primera vez que se hace el backup, deben copiarse todos los directorios y archivos</li> <li>Pero si ya hay una copia previa, s\u00f3lo deben copiarse los directorios y archivos que sean nuevos (o modificados) desde la \u00faltima copia. Para ello, utiliza un fichero oculto en /tmp/$HOME, que act\u00fae de marca temporal.</li> </ul> <p>Sugerencia: Se sugiere crear primero los directorios (mkdir) y luego copiar los archivos (cp). En ambos casos, estudia la utilizaci\u00f3n de la opci\u00f3n -p</p>"},{"location":"UD00/5.BashEjercicios/#ejercicio-7","title":"Ejercicio 7","text":"<p>Implementa un script que imprima un listado de los usuarios que tienen procesos en ejecuci\u00f3n, indicando para cada uno:</p> <ul> <li>La cantidad de procesos que esta\u0301 ejecutando</li> <li>La suma de sus consumos actuales de CPU (en %)</li> <li>La suma de sus consumos actuales de memoria (en %)</li> </ul> <p>Sugerencia: Se sugiere utilizar la orden ps para averiguar la informaci\u00f3n de base.</p>"},{"location":"UD00/5.BashEjercicios/#ejercicio-8","title":"Ejercicio 8","text":"<p>Implementa un script que se ejecute cada 5 minutos y compruebe que siguen ejecut\u00e1ndose los procesos necesarios para hadoop y yarn.  Si al ejecutarse no encuentra alguno de los procesos necesarios ha de dejar un registro (log) Si al ejecutarse encuentra todos los procesos necesarios tambi\u00e9n ha de indicarlo en el log.</p> <ul> <li> <p>Pistas:</p> <ul> <li>Ejecutar un script cada X minutos o segundos\u2026 utilizaremos \u201ccron\u201d<ul> <li>https://nksistemas.com/crear-un-script-simple-y-ejecutarlo-con-cron-crontab-en-tu-linux/</li> <li>Para ayudarnos a generar el cron correctamente: https://crontab.guru/</li> </ul> </li> <li>Procesos activos en el sistema <code>ps -aux</code> , o para hadoop <code>jps</code></li> </ul> <p>Ejemplo de log creado:</p> <pre><code>lun 11 dic 2023 18:10:00 CET     Ejecuci\u00f3n correcta [OK]\nlun 11 dic 2023 18:15:00 CET     Error NodeManager  [ERROR]\nlun 11 dic 2023 18:15:00 CET     Error SecondaryNameNode  [ERROR]\nlun 11 dic 2023 18:15:00 CET     Error ResourceManager  [ERROR]\nlun 11 dic 2023 18:20:00 CET     Ejecuci\u00f3n correcta [OK]\n</code></pre> </li> </ul>"},{"location":"UD00/5.BashEjercicios/#ejercicio-9","title":"Ejercicio 9","text":"<p>Mandar los logs del script anterior por telegram. 1. Crear bot con BotFather Obtener token HTTP API 6482272093:AAEWWA3hfaZ0O6t4tC4TCpP5ewPVSjpQNL0jj</p> <ol> <li>Entrar en el bot Start bot</li> <li>Obtener chatID a trav\u00e9s de una URL     https://api.telegram.org/bot${token}/getUpdates</li> <li>Obtener chatID https://ungineer.github.io/chatid.html 25156175583</li> <li>Mandar mensaje a trav\u00e9s de bash:</li> </ol> <pre><code>API_TOKEN=\"&lt;your_api_token&gt;\"\nCHAT_ID=\"&lt;your_chat_id&gt;\"\n\n# Set the message text\nMESSAGE=\"This is a test message\"\n\n# Use the curl command to send the message\ncurl -s -X POST https://api.telegram.org/bot$API_TOKEN/sendMessage -d chat_id=$CHAT_ID -d text=\"$MESSAGE\"\n</code></pre>"},{"location":"UD00/5.BashEjercicios/#ejercicio-10","title":"Ejercicio 10","text":"<p>Un sistema inform\u00e1tico almacena en varios ficheros \u201clog\u201d los usuarios y la fecha de conexi\u00f3n (usuario:mes:dia).</p> <p>Hay que hacer un script al que se le puedan pasan 2 par\u00e1metros, el primero un nombre de usuario y el segundo un fichero log y comprobar\u00e1 (mostrando por pantalla) cu\u00e1ntos accesos ha realizado el usuario el mes actual.</p> <p>Control de errores:</p> <ul> <li>2 par\u00e1metros requeridos</li> <li>El fichero de logs no existe</li> </ul> <p>Ejemplo datos.log</p> <pre><code>pedro:ENE:21\nana:JUN:13\njuan:ABR:16\nroberto:JUN:01\njuan:MAR:13\npedro:FEB:01\nlucas:ENE:07\npedro:JUN:15\nroberto:JUN:02\nana:JUN:13\nlucas:ENE:07\njuan:JUN:16\npedro:MAY:01\njuan:MAR:13\n</code></pre> <p>Ejemplos de ejecuci\u00f3n</p> <pre><code>## Teniendo en cuenta que el mes actual es ENERO\n\n./conexiones.sh ana datos.log\n\nEl usuario ana se ha conectado este mes 0 veces.\n\n./conexiones.sh pedro datos.log\n\nEl usuario pedro se ha conectado este mes 1 vez.\n</code></pre>"},{"location":"UD00/6.BashChuleta/","title":"UD00 4. Chuleta bash","text":""},{"location":"UD00/6.BashChuleta/#1-variables","title":"1. Variables","text":"<pre><code>A=10\necho $A\necho ${A}DIOS\necho ${#A} // devuelve 2 (longitud)\nunset A\n\nb=\u201cHOLA\u201d; echo ${#b) -&gt; longitud de la variable (4)\n\nlocal A -&gt; variable local dentro de una funci\u00f3n\n\nreadonly A \nA=20\n     -bash: A: readonly variable\n</code></pre>"},{"location":"UD00/6.BashChuleta/#variables-de-entorno","title":"Variables de entorno","text":"<p> Para ver todas las variables que est\u00e1n definidas se puede utilizar el comando <code>env</code></p>"},{"location":"UD00/6.BashChuleta/#2-ejecucion-scripts","title":"2. Ejecuci\u00f3n scripts","text":""},{"location":"UD00/6.BashChuleta/#permisos","title":"Permisos","text":"<pre><code>chmod u+x nombre_script.sh\n</code></pre>"},{"location":"UD00/6.BashChuleta/#parametros-argumentos","title":"Par\u00e1metros, argumentos","text":"<p> <pre><code>$0 -&gt; nombre script\n$# -&gt; n\u00famero de par\u00e1metros\n$* -&gt; todos los par\u00e1metros vistos como una palabra\n$@ -&gt; todos los par\u00e1metros posicionales, cada uno est\u00e1 entrecomillado\n</code></pre></p>"},{"location":"UD00/6.BashChuleta/#redirecciones","title":"Redirecciones","text":"<pre><code>ls 2&gt; fichero    ls 2&gt;/dev/null -&gt; Redirecci\u00f3n salida error\nls 2&gt;&amp;1 -&gt; Redirecci\u00f3n salida error a est\u00e1ndard (muestra el error, como si no estuviese el 2)\nls /aa &amp;&gt; fich -&gt; todas las salidas a fich \nls /aa &amp;&gt; /dev/null -&gt; Ocultar todas las salidas, error y OK\nls /saa &lt; fich // redirecci\u00f3n entrada\nls /saaa &amp;&gt;fich // redirecci\u00f3n salida est\u00e1ndar y errores\n\nORDEN DE EVALUACI\u00d3N\nRedirecci\u00f3nes E/S\nSustituci\u00f3n, expansi\u00f3n variables\nSustituci\u00f3n, expansi\u00f3n nombres ficheros\n\ncmd &lt; fichero -&gt; coge como entrada standard un fichero\n\ncat &lt;&lt; end\n   Escriure el que vols\u2026\nend\n</code></pre>"},{"location":"UD00/6.BashChuleta/#3-entrada-salida-de-datos","title":"3. Entrada Salida de datos","text":""},{"location":"UD00/6.BashChuleta/#entrada","title":"Entrada","text":"<pre><code>echo \u00adn \"Escriu DNI i lletra separats per un espai\" \nread DNI LLETRA\n\nread -p \"Type something: \" text   // -p mostrar prompt -e linea entera\nType something: josep garcia  // se guarda en $text\n\nread -p \"PASS\" -s VAR  // s-&gt; silence\nPASS: // no se muestran caracteres que se escriben, guarda en VAR\n</code></pre>"},{"location":"UD00/6.BashChuleta/#4-control-de-flujo","title":"4. Control de flujo","text":""},{"location":"UD00/6.BashChuleta/#bucles","title":"Bucles","text":"<pre><code>seq valor_inicio   valor_fin\nseq valor_inicio   incremento valor_fin\n\nfor i in $(seq 1 10); do echo $i; done #1 2 3 4 5 6 7 8 9 10\nfor i in $(seq 1 2 10); do echo $i; done #1 3 5 6 9\n</code></pre>"},{"location":"UD00/6.BashChuleta/#5-filtros","title":"5. Filtros","text":""},{"location":"UD00/6.BashChuleta/#tr","title":"tr","text":"<pre><code>TR (significa: translate o transliterate)\n-s sustituye conjunto car\u00e1cteres repetidos por uno solo\n-c sustituye car\u00e1cteres espec\u00edficos: tr -c \u201c[a-z]\u201d x -&gt; traduce a x\n-d borra: tr -d [a-z]\ncat datos_demo.txt | tr -s \" \" | cut -f6 -d \"#\"\n\n# Cambia espacios por \\n\necho \u201ca b c d e\u201d | tr \u2018 \u2019 \u2018\\n\u2018 \n\n# BORRA la aparici\u00f3n de localhost en el fich\n# cat /etc/hosts | tr -d \u2018localhost'\n\n# Deja un solo :\n# echo \u201cAA::::::::B\u201d | tr -s \u201c:\u201d -&gt; AA:B\n\n# convertir a min\u00fasculas\necho \"EaaaEM\" | tr '[:upper:]' \u2018[:lower:]\u2019\necho \"EaaaEM\" | tr \"a-z\" \"A-Z\"\n#\ny=\"this Is A test\"\necho \"${y^^}\" -&gt; THIS IS A TEST\necho \"${y,,}\" -&gt; this is a test\n</code></pre>"},{"location":"UD00/6.BashChuleta/#sed","title":"sed","text":"<pre><code>sed \u2019s/a_sustitutir/a_sustituto/g\u2019 fich.txt\n\n** SED reemplaza cadenas, TR car\u00e1cteres\necho \"good good\" | sed 's/good/bad/g'\nbad bad\necho \"good good\" | tr \u2019good\u2019 \u2018x'\nxxxx xxxx\n\nObtener l\u00ednea 2: sed -n 2l fich.txt\nObtener todos menos 12 y 18: sed 12,18d fich.txt\nBorrar l\u00edneas en blanco: sed \u2019s/^$ /d\u2019 fich.txt\nNo mostrar l\u00edneas que tengan hola: sed \u2018/hola/d\u2019 fich.txt\n</code></pre>"},{"location":"UD00/6.BashChuleta/#cut","title":"cut","text":"<pre><code>CUT\n-d car\u00e1cter delimitador\n-b,-c,-f corta por bytes, car\u00e1cteres o campos\n\ncut -f6- -d \u201c#\u201d -&gt; saca la 6 y la siguiente\ncut -f1-6 -d \u201c#\" -&gt; de la 1 a la 6\ncut -f1,6 -d \u201c#\" -&gt; la 1 y la 6\n\n# cat datos_demo.txt | cut -f1-3 -d \u201c#\"\n1#josep#garcia\n2#ana#martin\n3#olivia#garcia\n</code></pre>"},{"location":"UD00/6.BashChuleta/#head","title":"head","text":"<pre><code>HEAD -&gt; Muestra 10 primeras lineas\nHead -n2 fich.txt -&gt; muestra 2 primeras l\u00edneas\n</code></pre>"},{"location":"UD00/6.BashChuleta/#tail","title":"tail","text":"<pre><code>Muestra las 10 \u00faltimas l\u00edneas\nTail -n3 fich.txt -&gt; muestra las 3 \u00faltimas\n</code></pre>"},{"location":"UD00/6.BashChuleta/#sort","title":"sort","text":"<pre><code>SORT -&gt; ordenar\n-f no distingue May\u00fas/min\u00fas\n-b (ignora blancos al principio l\u00ednea)\n-r (orden inverso)\n\nFitxer:\naa aabb:x\naaa abb:y\naaa aaa:z\n\ncat fich | sort -k3n -t\u201d:\u201d\nn-&gt; compara con campo num\u00e9rico -&gt;&gt; orden num\u00e9rico\nK3 -&gt; seg\u00fan tercer campo (campos seg\u00fan espacios)\n-t\u201d:\u201d -&gt; campos delimitados por dos puntos\n</code></pre> <pre><code># cat ordenar.txt | sort -k1\naa aabb:x\naaa aaa:z\naaa abb:y\n# cat ordenar.txt | sort -k2\naaa aaa:z\naa aabb:x\naaa abb:y\n# cat ordenar.txt | sort -k2 -t\":\"\naa aabb:x\naaa abb:y\naaa aaa:z\n</code></pre>"},{"location":"UD00/6.BashChuleta/#uniq","title":"uniq","text":"<p>Descarta repeticiones de l\u00ednea sucesivas</p> <pre><code>Fitxer:\naaa\nasf\naaa\nasfasdf\nasdff\naaa\naaa\n\n# cat unicos.txt | uniq\naaa\nasf\naaa\nasfasdf\nasdff\naaa\n</code></pre> <pre><code># cat unicos.txt | uniq -c -&gt; cuenta ocurrencias\n      1 aaa\n      1 asf\n      1 aaa\n      1 asfasdf\n      1 asdff\n      2 aaa\n\n# cat unicos.txt | uniq -u -&gt; muestra l\u00edneas \u00fanicas\naaa\nasf\naaa\nasfasdf\nasdff\n</code></pre>"},{"location":"UD00/6.BashChuleta/#operaciones-con-ficheros","title":"Operaciones con ficheros","text":""},{"location":"UD00/6.BashChuleta/#comprimir","title":"Comprimir","text":"<pre><code>gzip fichero.txt -&gt; fichero.txt.gz\n\nbzip bigfile -&gt; bigfile.bz2\n\ntar cfz bigfile.tgz bigfile\n\nzip ./bigfile.zip bigfile\n\ntar -czvf archive.tar.gz /home/ubuntu --exclude=*.mp4\n\n#Varios directorios i ficheros\ntar -czvf archive.tar.gz /home/ubuntu/Downloads /usr/local/stuff /home/ubuntu/Documents/notes.txt\n</code></pre>"},{"location":"UD00/6.BashChuleta/#descomprimir","title":"Descomprimir","text":"<pre><code>tar xf bigfile.tgz\ntar -xzvf archive.tar.gz\n\nunzip bigfile.zip\ngunzip bigfile.gz\nbunzip2 bigfile.gz2\n</code></pre>"},{"location":"UD00/7.docker/","title":"Repaso docker","text":""},{"location":"UD00/7.docker/#1-arquitectura","title":"1. Arquitectura","text":""},{"location":"UD00/7.docker/#2-instalacion","title":"2. Instalaci\u00f3n","text":"<p>https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-20-04-es</p> <p>Requisitos previos:</p> <ul> <li>apt-transport-https:\u00a0permite que el administrador de paquetes transfiera datos a trav\u00e9s de https</li> <li>ca-certificates:\u00a0permite que el navegador web y el sistema verifiquen los certificados de seguridad</li> <li>curl:\u00a0transfiere datos (similar a wget)</li> <li>software-properties-common:\u00a0agrega scripts para administrar el software</li> </ul> <pre><code>sudo apt-get install  curl apt-transport-https ca-certificates software-properties-common\n</code></pre> <p>Agregamos repositorio</p> <pre><code># Primero clave GPG\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n\nsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\"\n\nsudo apt update\n\nsudo apt install docker-ce\n\nsudo systemctl status docker\n</code></pre> <p>Por defecto, el comando docker solo puede ser ejecutado por el usuario root o un usuario del grupo docker, que se crea autom\u00e1ticamente durante el proceso de instalaci\u00f3n de Docker.</p> <p>Para evitar escribir sudo al ejecutar el comando docker, agregue su nombre de usuario al grupo docker:</p> <pre><code>sudo usermod -aG docker ${USER}\n\n# Cerramos y abrimos sesi\u00f3n de nuevo o ejecutamos\nsu - ${USER}\n\n# Confirmamos los grupos de nuestro usuario\nid -nG\n</code></pre>"},{"location":"UD00/7.docker/#21-comandos-basicos","title":"2.1. Comandos b\u00e1sicos","text":""},{"location":"UD00/7.docker/#gestion-de-imagenes","title":"Gesti\u00f3n de imagenes","text":"<pre><code>docker image\ndocker history\ndocker inspect\ndocker save/load\ndocker rmi\n</code></pre>"},{"location":"UD00/7.docker/#gestion-de-contenedores","title":"Gesti\u00f3n de contenedores","text":"<pre><code>docker attach\ndocker exec\ndocker inspect\ndocker kill\ndocker logs\ndocker pause/unpause\ndocker port\ndocker ps\ndocker rename\ndocker start/stop/restart\ndocker rm\ndocker run\ndocker stats\ndocker top\ndocker update\n</code></pre>"},{"location":"UD00/7.docker/#ejemplo","title":"Ejemplo","text":"<pre><code># Ver los contenedores que tenemos\ndocker ps\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n\n# Ver las imagenes que tenemos\ndocker images\nREPOSITORY                             TAG       IMAGE ID       CREATED        SIZE\n\n# Crear un contenedor con una imagen b\u00e1sica de debian\n# Como no tenemos ninguna imagen de debian, la descarga y la ejecuta\ndocker run debian\n# Intentamos ver el contenedor en ejecuci\u00f3n, no aparece nada porque ya se ha cerrado\ndocker ps\n# Podemos verlo con\ndocker ps -a\nCONTAINER ID   IMAGE     COMMAND       CREATED              STATUS                          PORTS     NAMES\n09b14daab800   debian    \"bash\"        2 seconds ago        Exited (0) 1 second ago                   pensive_wozniak\n\n# Ejecutar un comando en un contenedor\ndocker run debian /bin/echo \"Hello World\"\nHello World\n\n# Informaci\u00f3n\ndocker inspect debian\n</code></pre>"},{"location":"UD00/7.docker/#11-crear-contenedor-interactivo-y-con-nombre","title":"1.1. Crear contenedor interactivo y con nombre.","text":"<p>https://jolthgs.wordpress.com/2019/09/25/create-a-debian-container-in-docker-for-development/</p> <p>Para que docker no se invente un nombre como \u201cpensive_wozniak\u201d (comando anterior) podemos definir el nombre que queremos.</p> <p>Utilizaremos una de las im\u00e1genes de: https://hub.docker.com/_/debian/tags</p> <pre><code># Obtenemos la imagen, en el apartado aterior la hemos ejecutado directamente con \"run\", esto\n# la obtiene impl\u00edcitamente. En este caso la vamos a descargar.\ndocker pull debian:10-slim\n\n# --name\n# -h hostname que tendr\u00e1 el contenedor\n# -e codificaci\u00f3n de caracteres\n# -it modo interactivo\n# /bin/bash -l  la shell que se ejecutar\u00e1\ndocker run --name debian-mini -h equipo1 -e LANG=C.UTF-8 -it debian:10-slim /bin/bash -l\n\n# Una vez dentro del contenedor podemos actualizarlo e instalar los paquetes que creamos necesarios\napt update &amp;&amp; apt upgrade --yes &amp;&amp; apt install sudo locales --yes\n# Configurar timezone\ndpkg-reconfigure tzdata\n\n# Vamos a nuestra home y creamos un archivo\ncd\necho \"hola\" &gt; prueba.txt\n\n# Salimos del contenedor\nexit (o control + d)\n\n---\ndocker ps\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n\ndocker ps -a\nCONTAINER ID   IMAGE            COMMAND          CREATED          STATUS                      PORTS     NAMES\n97d8dc048093   debian:10-slim   \"/bin/bash -l\"   2 minutes ago    Exited (0) 24 seconds ago             debian-mini\n</code></pre> <p>Una vez personalizado el contenedor podremos  </p>"},{"location":"UD00/7.docker/#2-imagenes","title":"2. Imagenes","text":"<p>Es un instalador donde podemos incorporar nuestra aplicaci\u00f3n. Es el punto de inicio para crear contenedores. Hay im\u00e1genes oficiales de por ejemplo Ubuntu, Apache, etc, que fueron creadas por sus creadores oficiales.</p> <p>P\u00e1gina oficial para imagenes: https://hub.docker.com </p> <p>Vamos a utilizar la siguiente imagen para pruebas:</p> <p>https://hub.docker.com/_/hello-world</p> <p>Para ejecutar este contenedor \u201chello-word\u201d escribimos en la terminal:</p> <pre><code>docker run hello-world\n</code></pre> <p>Una vez ejecutado, ya dispondremos de la imagen descargada, podemos ver todas las imagenes que tenemos decargadas con:</p> <pre><code>docker images\n\nREPOSITORY                              TAG           IMAGE ID       CREATED        SIZE\nhello-world                             latest        ee301c921b8a   9 months ago   9.14kB\n</code></pre> <p>Desde la p\u00e1gina web de docker hub, podemos ver diferentes versiones de la misma imagen en la pesta\u00f1a \u201cTAGS\u201d</p> <p></p> <p>Podemos descargar una imagen espec\u00edfica y ejecutarla:</p> <pre><code>docker run hello-world:linux\n\ndocker images\nREPOSITORY                              TAG           IMAGE ID       CREATED        SIZE\nhello-world                             latest        ee301c921b8a   9 months ago   9.14kB\nhello-world                             linux         ee301c921b8a   9 months ago   9.14kB\n\ndocker run hello-world:linux\n</code></pre> <p>Para eliminar una imagen utilizamos el par\u00e1metro <code>rmi</code> por ejemplo:</p> <pre><code>docker pull alpine\n\ndocker images\nREPOSITORY                              TAG           IMAGE ID       CREATED        SIZE\nalpine                                  latest        ace17d5d883e   3 weeks ago    7.73MB\nhello-world                             latest        ee301c921b8a   9 months ago   9.14kB\nhello-world                             linux         ee301c921b8a   9 months ago   9.14kB\n\n# Eliminamos, opci\u00f3n 1\ndocker rmi ace17d5d883e\n\n# Eliminamos, opci\u00f3n 2\ndocker rmi alpine\n\n# Eliminamos, opci\u00f3n 3\ndocker rmi ace1\n</code></pre> <p>Tambi\u00e9n se pueden buscar im\u00e1genes desde consola.</p> <pre><code>docker search ubuntu\n\nNAME                             DESCRIPTION                                     STARS     OFFICIAL\nubuntu                           Ubuntu is a Debian-based Linux operating sys\u2026   16888     [OK]\nwebsphere-liberty                WebSphere Liberty multi-architecture images \u2026   298       [OK]\nopen-liberty                     Open Liberty multi-architecture images based\u2026   64        [OK]\nneurodebian                      NeuroDebian provides neuroscience research s\u2026   106       [OK]\nubuntu-debootstrap               DEPRECATED; use \"ubuntu\" instead                52        [OK]\nubuntu-upstart                   DEPRECATED, as is Upstart (find other proces\u2026   115       [OK]\nubuntu/nginx                     Nginx, a high-performance reverse proxy &amp; we\u2026   112\nubuntu/squid                     Squid is a caching proxy for the Web. Long-t\u2026   83\nubuntu/cortex                    Cortex provides storage for Prometheus. Long\u2026   4\nubuntu/prometheus                Prometheus is a systems and service monitori\u2026   56\nubuntu/apache2                   Apache, a secure &amp; extensible open-source HT\u2026   70\n...\n</code></pre>"},{"location":"UD00/7.docker/#3-volumenes","title":"3. Vol\u00famenes","text":"<p>Los vol\u00famenes sirven para almacenar informaci\u00f3n de manera persistente en uno o varios contenedores. Es \u00fatil para que los archivos ya est\u00e9n integrados en el propio contenedor y podamos disponer de dichos archivos en diferentes contenedores diferentes.</p> <p>Tambi\u00e9n nos permiten compartir archivos con el contenedor. Modificarlos en local y que se modifiquen en el contenedor.</p>"},{"location":"UD00/7.docker/#31-operaciones-con-volumenes","title":"3.1. Operaciones con vol\u00famenes","text":"<pre><code># Ver disponibles\ndocker volume ls\nDRIVER    VOLUME NAME\n\n# Creamos un volumen\ndocker volume create almacen\nalmacen\n\ndocker volume ls\nDRIVER    VOLUME NAME\nlocal     almacen\n\ndocker volume inspect almacen\n[\n    {\n        \"CreatedAt\": \"2024-02-20T11:10:58Z\",\n        \"Driver\": \"local\",\n        \"Labels\": null,\n        \"Mountpoint\": \"/var/lib/docker/volumes/almacen/_data\",\n        \"Name\": \"almacen\",\n        \"Options\": null,\n        \"Scope\": \"local\"\n    }\n]\n\n# Lo borramos\ndocker volume rm almacen\n</code></pre>"},{"location":"UD00/7.docker/#32-ejemplo-compartir-volumenes-con-host","title":"3.2. Ejemplo: compartir vol\u00famenes con host","text":"<pre><code># Creamos un punto de montaje\ndocker run --rm -it -v /tmp/puntomontaje:/home ubuntu\n</code></pre>"},{"location":"UD00/7.docker/#32-ejemplo-compartir-volumenes-con-contenedores","title":"3.2. Ejemplo: compartir vol\u00famenes con contenedores","text":"<p>Vamos a crear un volumen para compartir archivos entre nuestro sistema de ficheros local y 2 contenedores (ubuntu y fedora).</p> <pre><code>docker volume create almacen\n\n# Descargamos la imagen de ubuntu\ndocker pull ubuntu\n# Descargamos la imagen de fedora\ndocker pull fedora\n\ndocker images\nREPOSITORY                             TAG       IMAGE ID       CREATED        SIZE\nubuntu                                 latest    a50ab9f16797   7 days ago     69.2MB\nfedora                                 latest    46243415778a   2 months ago   259MB\n\n## Creamos un contenedor, modo interactivo\ndocker run --rm -it -v almacen:/home ubuntu\n# dentro del contenedor\ncd /home\ntouch prueba.txt\nexit # -&gt; Salimos del contenedor\n\n## Creamos otro contenedor, modo interactivo\ndocker run --rm -it -v almacen:/home fedora\n# dentro del contenedor\ncd /home\nls -&gt; existe el archivo prueba.txt\n</code></pre>"},{"location":"UD00/7.docker/#33-compartir-volumenes-con-contenedores-y-en-local","title":"3.3. Compartir volumenes con contenedores y en local","text":"<pre><code>$ docker volume ls\nDRIVER    VOLUME NAME\nlocal     almacen\n</code></pre>"},{"location":"UD00/7.docker/#4-docker-compose-vs-dockerfile","title":"4. docker-compose vs DockerFile","text":"<p>https://blog.elhacker.net/2022/01/gestion-contenedores-dockerfile-y-docker-compose.html</p>"},{"location":"UD00/7.docker/#41-diferencias","title":"4.1. Diferencias","text":""},{"location":"UD00/7.docker/#42-docker-compose","title":"4.2. Docker Compose","text":"<p>Docker Compose es una herramienta que permite simplificar el uso de Docker. A partir de archivos YAML es mas sencillo crear contenedores, conectarlos, habilitar puertos, vol\u00famenes, etc.</p> <p>Con Compose puedes crear diferentes contenedores y al mismo tiempo, en cada contenedor, diferentes servicios, unirlos a un vol\u00famen com\u00fan, iniciarlos y apagarlos, etc. Es un componente fundamental para poder construir aplicaciones y microservicios</p> <p>Par\u00e1metros docker-compose.yml</p> <ul> <li>\u201cversion\u00a0\u20183\u2019: Los archivos docker-compose.yml son versionados, lo que significa que es muy importante indicar la versi\u00f3n de las instrucciones que queremos darle. A medida de que Docker evoluciona, habr\u00e1 nuevas versiones, pero de todos modos, siempre hay compatibilidad hacia atr\u00e1s, al indicar la versi\u00f3n</li> <li>\u201cbuild\u00a0.\u201d: Se utiliza para indicar donde est\u00e1 el Dockerfile que queremos utilizar para crear el contenedor. Al definier \u201c.\u201d autom\u00e1ticamente considerar\u00e1 el Dockerfile existente en directorio actual.</li> <li>\u201ccommand\u201d: Una vez creado el contenedor, aqui lanzamos el comando que permite ejecutar Jekyll, en modo servidor. El comando \u201c\u2013host 0.0.0.0\u201d sirve para mapear el contenedor al sistema operativo host</li> <li>\u201cports\u201d: mapeamos los puertos locales, por ejemplo 4000 (webserver jekyll) y 35729 (livereload) al servidor host. Esto permite que accediendo a Localhost:4000 podamos probar el sitio generador por Jekyll</li> <li>\u201cvolumes\u201d: lo que hacemos es mapear el directorio local se mapee directamente con el /directoriox, lugar donde hemos creado la aplicaci\u00f3n. De este modo, cualquier cambio en el directorio local en el host, se har\u00e1 de inmediato en el contenedor.</li> </ul> <p></p> <p>Ejemplo, creaci\u00f3n contenedor con wordpress:</p> <pre><code>mkdir /tmp/wp\ncd /tmp/wp\n\nvi docker-compose.yml\n</code></pre> <pre><code>version: '3' # Utilizamos la versi\u00f3n 3\n\n## Nos saltamos la secci\u00f3n network \n\nservices:\n    db:\n        image: mariadb:10.3.9\n        volumes:\n            - data:/var/lib/mysql\n        environment:\n            - MYSQL_ROOT_PASSWORD=secret\n            - MYSQL_DATABASE=wordpress\n            - MYSQL_USER=manager\n            - MYSQL_PASSWORD=secret\n                ## Equivalente a\n                ## docker run -d --name wordpress-db \\\n        ## --mount source=wordpress-db,target=/var/lib/mysql \\\n        ## -e MYSQL_ROOT_PASSWORD=secret \\\n        ## -e MYSQL_DATABASE=wordpress \\\n        ## -e MYSQL_USER=manager \\\n        ## -e MYSQL_PASSWORD=secret mariadb:10.3.9\n\n    web:\n        image: wordpress:4.9.8\n        depends_on:\n            - db\n        volumes:\n            - ./target:/var/www/html\n        environment:\n            - WORDPRESS_DB_USER=manager\n            - WORDPRESS_DB_PASSWORD=secret\n            - WORDPRESS_DB_HOST=db\n        ports:\n            - 8080:80\n                ## Equivalente a\n                ## docker run -d --name wordpress \\\n            ## --link wordpress-db:mysql \\\n            ## --mount type=bind,source=\"$(pwd)\"/target,target=/var/www/html \\\n            ## -e WORDPRESS_DB_USER=manager \\\n            ## -e WORDPRESS_DB_PASSWORD=secret \\\n            ## -p 8080:80 \\\n            ## wordpress:4.9.8\n\nvolumes:\n    data: # creci\u00f3n de volumen, compose a\u00f1ade un prefijo por lo que se llamar\u00e1 worpdress_data\n</code></pre> <pre><code># Levantamos la aplicaci\u00f3n\ndocker-compose up -d\n# El par\u00e1metro -d es similar al de docker run: nos permite levantar los servicios en segundo plano.\n\ndocker-compose ps\n## docker-compose ps solo muestra informaci\u00f3n de los servicios que se define en docker-compose.yaml, mientras que docker muestra todos.\n\n# Detener servicios\ndocker-compose stop\n\n# Borrar\ndocker-compose down\n\n# Borrar vol\u00famenes\ndocker-compose down -v\n</code></pre> <p>Cuando creamos contenedores con\u00a0<code>docker</code>\u00a0sin indicar un nombre, por defecto asigna uno aleatorio; mientras que en\u00a0Compose\u00a0el prefijo es el nombre del directorio y el sufijo el nombre del servicio:\u00a0wordpress*_db*_1. El n\u00famero indica el n\u00famero de instancia. Es posible levantar m\u00e1s de una instancia de un mismo servicio.</p> <p>Equivalencia de par\u00e1metros</p> par\u00e1metro\u00a0Docker par\u00e1metro\u00a0Composer --link depends_on --mount volumes -e environment -p,--publish ports image <p>Si reiniciamos el ordenador, los contenedores estar\u00e1n detenidos (stop), podremos reiniciarlos con\u00a0<code>docker start</code>\u00a0o\u00a0<code>docker-compose start</code>. Este es el comportamiento predeterminado y el que nos interesa en un entorno de desarrollo.</p> <p>Sin embargo, en otros entornos, o para casos concretos, igual queremos que un contenedor tenga el mismo estado en el que estaba antes de reiniciar la m\u00e1quina (iniciado o parado).</p> <p>Para eso usaremos el par\u00e1metro\u00a0<code>restart</code>. En el caso de la base de datos de nuestro ejemplo, la configuraci\u00f3n quedar\u00eda como:</p> <pre><code>services:\n    db:\n        image: mariadb:10.3.9\n        **restart: unless-stopped**\n        volumes:\n            - data:/var/lib/mysql\n        environment:\n            - MYSQL_ROOT_PASSWORD=secret\n            - MYSQL_DATABASE=wordpress\n            - MYSQL_USER=manager\n            - MYSQL_PASSWORD=secret\n</code></pre> <p>Otros valores son:\u00a0<code>no</code>\u00a0(por defecto),\u00a0<code>always</code>\u00a0y\u00a0<code>on-failure</code>.</p>"},{"location":"UD00/7.docker/#43-dockerfile","title":"4.3. DockerFile","text":""},{"location":"UD00/7.docker/#ejemplo-basico","title":"Ejemplo b\u00e1sico","text":"<p>Nos ubicamos en la carpeta donde vayamos a trabajar con la imagen, por ejemplo voy a crear un directorio llamado docker-images.</p> <p>Y creamos una archivo Dockerfile con un editor de texto.</p> <pre><code>FROM ubuntu\nRUN apt update\nRUN apt install python 3 -y\nRUN apt install netris -y\n</code></pre> <p>Creamos la imagen seg\u00fan las \u00f3rdenes anteriores:</p> <pre><code>docker build -t python-ubuntu .\n</code></pre> <p>Hay un error en el Dockerfile, corregir y volver a ejecutar el build.</p> <p>Ya tenemos una imagen de ubuntu pero con python3 instalado:</p> <pre><code>docker run -it python-ubuntu\n\npython3\n\nPython 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt;\n</code></pre> <p>Una vez salimos podemos ver todas las \u201ccapas\u201d de la imagen:</p> <pre><code>docker history -H python-ubuntu\n\nIMAGE          CREATED         CREATED BY                                      SIZE      COMMENT\n78732fd773c4   2 minutes ago   RUN /bin/sh -c apt install netris # buildkit    1MB       buildkit.dockerfile.v0\n&lt;missing&gt;      2 minutes ago   RUN /bin/sh -c apt install python3 -y # buil\u2026   29.5MB    buildkit.dockerfile.v0\n&lt;missing&gt;      3 minutes ago   RUN /bin/sh -c apt update # buildkit            45.1MB    buildkit.dockerfile.v0\n&lt;missing&gt;      3 weeks ago     /bin/sh -c #(nop)  CMD [\"/bin/bash\"]            0B\n&lt;missing&gt;      3 weeks ago     /bin/sh -c #(nop) ADD file:8d91b8bd386e0cc34\u2026   69.2MB\n&lt;missing&gt;      3 weeks ago     /bin/sh -c #(nop)  LABEL org.opencontainers.\u2026   0B\n&lt;missing&gt;      3 weeks ago     /bin/sh -c #(nop)  LABEL org.opencontainers.\u2026   0B\n&lt;missing&gt;      3 weeks ago     /bin/sh -c #(nop)  ARG LAUNCHPAD_BUILD_ARCH     0B\n&lt;missing&gt;      3 weeks ago     /bin/sh -c #(nop)  ARG RELEASE                  0B\n</code></pre>"},{"location":"UD00/7.docker/#creacion-de-imagenes-propias","title":"Creaci\u00f3n de im\u00e1genes propias","text":"<ul> <li>Para construir una imagen, se crea un\u00a0<code>Dockerfile</code>\u00a0con las instrucciones que especifican lo que va a ir en el entorno, dentro del contenedor (redes, vol\u00famenes, puertos al exterior, archivos que se incluyen.</li> <li>Indica c\u00f3mo y con qu\u00e9 construir la imagen.</li> <li>Podemos utilizar la imagen en tantos contenedores como queramos.</li> </ul> <p>El DockerFile nos permitir\u00e1 definir las funciones b\u00e1sicas del contenedor.</p> <p>Todo Dockerfile debe terminar en un comando CMD o en un ENTRYPOINT, pero en este caso, no lo utilizamos, ya que lanzaremos un comando directamente desde la receta de Docker Compose. Es decir, este Dockerfile se utiliza solamente para construir el contenedor y configurarlo. No es autoejecutable.</p>"},{"location":"UD00/7.docker/#from","title":"FROM","text":"<p>Imagen del sistema operativo donde va a correr el contenedor.</p> <p>** Las versiones \u201cAlpine linux\u201d ocupan muy poco espacio.</p>"},{"location":"UD00/7.docker/#run","title":"RUN","text":"<p>El comando\u00a0RUN\u00a0se ejecuta cuando se est\u00e1 construyendo una imagen personalizada para realizar una acci\u00f3n, creando una capa nueva. Este comando tiene el siguiente formato:</p> <p>RUN\u00a0comando </p> <p>RUN\u00a0[\u201cejecutable\u201d, \u201cparametro1\u201d, \u2026] </p> <p>Ejemplo en windows:</p> <p>RUN\u00a0[\u201cPowershell\u201d, \u201cGet-Services\u201d, \u201c*\u201d] </p>"},{"location":"UD00/7.docker/#copy","title":"COPY","text":"<p>Sirve para copiar archivos desde nuestra m\u00e1quina al contenedor. Podemos pasar un documento de texto de la m\u00e1quina anfitri\u00f3n al conenedor de python-ubuntu.</p> <pre><code>FROM ....\nRUN ....\nRUN ....\nCOPY prueba.txt /\n</code></pre> <p>Volvemos a construir la imagen y accedemos a ella para buscar el archivo.</p>"},{"location":"UD00/7.docker/#env","title":"ENV","text":"<p>Podemos crear una variable y enviarla a nuestro contenedor, en mi caso por ejemplo voy a definir una variable llamada contenido que va a ir dirigida a un bloc de notas que est\u00e1 dentro del contenedor:</p> <pre><code>....\nENV NUEVO_PATH /etc\n</code></pre> <p>Una vez regenerado la imagen y dentro del contenedor:</p> <pre><code>echo $NUEVO_PATH\n/etc\n</code></pre> <p>Podemos combinar RUN con ENV</p> <pre><code>ENV NUEVO_PATH /etc\nRUN echo $NUEVO_PATH &gt; /prueba.txt\n</code></pre>"},{"location":"UD00/7.docker/#workdir","title":"WORKDIR","text":"<p>Nos situamos en un directorio determinado, nos puede ayudar en la copia de ficheros.</p> <pre><code>.....\nWORKDIR /home\nCOPY prueba.txt .  # Lo copia en /home\n</code></pre>"},{"location":"UD00/7.docker/#expose","title":"EXPOSE","text":"<p>Permite exponer los puertos que queramos</p>"},{"location":"UD00/7.docker/#label","title":"LABEL","text":"<p>Creamos etiquetas, por ejemplo:</p> <pre><code>FROM ubuntu\nLABEL version=1.0\nLABEL autor=JosepGarcia\n.....\n</code></pre>"},{"location":"UD00/7.docker/#user","title":"USER","text":"<p>Sirve para establecer el usuario, debe existir. (Por defecto se utiliza root).</p> <pre><code>....\nRUN echo $(whoami) &gt; /tmp/usuarioantes.txt\n\nRUN useradd -m josepgarcia\nUSER josepgarcia\nWORKDIR /home/josepgarcia\nRUN echo $(whoami) &gt; /tmp/usuarioahora.txt\n</code></pre>"},{"location":"UD00/7.docker/#cmd","title":"CMD","text":"<p>Ejecuta comandos una vez se ha inicializado el conenedor (RUN se utiliza para crear la imagen de un contenedor).</p> <pre><code>## Ejecutamos el comando top cuando se inicie el contenedor\n.....\nCMD top\n</code></pre>"},{"location":"UD00/7.docker/#ignore","title":"IGNORE","text":"<p>Sirve para ignorar aquello que tengamos en nuestro directorio actual.</p> <p>Por ejemplo:</p> <p>Creamos una imagen que copie todo nuestro directorio actual al contenedor.</p> <pre><code>ls\n\uf308 Dockerfile  \uf15c prueba.txt\n\nvi Dockerfile\n\n...\nCOPY . /tmp\n...\n</code></pre> <p>Ahora le decimos que copie todo menos el archivo Dockerfile, para ello creamos un fichero llamado <code>.dockerignore</code></p> <pre><code>vi .dockerignore\n\nDockerfile\n</code></pre> <p>Ejercicio1.</p> <p>Modificar Dockerfile para que el usuario creado anteriormente pueda ejectuar sudo.</p> <p>PENDIENTE</p> <p>Pendiente a partir de este punto</p>"},{"location":"UD00/7.docker/#entrypoint","title":"ENTRYPOINT","text":"<p>Este comando se ejecuta cuando se quiere ejecutar un ejecutable en el contenedor en su arranque. Los ejemplos tipo de su uso, son cuando se quiere levantar un servidor web, una base de datos, etc \u2026.</p> <p>Este comando tiene dos sintaxis:</p> <p>ENTRYPOINT\u00a0[\u201ccomando\u201d, \u201cParametro1\u201d, \u201cParametro2\u201d, \u2026] </p> <p>Esta es la forma recomendada.</p> <p>ENTRYPOINT\u00a0comando parametro1 parametro2 </p> <p>Con esta forma el comando se ejecuta en la Shell del contenedor.</p> <p>Utilizaci\u00f3n de varios comandos de forma conjunta</p> <p>Como se ha comentado anteriormente el comando CMD se puede utilizar para pasar par\u00e1metros al comando ENRYPOINT. Una posible forma de realizarlo es:</p> <p>ENRYPOINT\u00a0[\u201cPowershell\u201d, \u201cGet-Services\u201d]CMD\u00a0[\u201cMySql] </p> <p>En el ejemplo, se est\u00e1 invocando al comando Get-Services para recuperar informaci\u00f3n de los servicios Windows y como en el comando CMD se est\u00e1 indicando el servicio en concreto del que se quiere recuperar la informaci\u00f3n que en este caso es del servicio Windows de MySql.</p> <p>Nota: cuando los comandos o par\u00e1metros son pasados entre corchetes siempre van entre comillas. Esto es porque el comando correspondiente lo interpreta como una cadena JSON.</p>"},{"location":"UD00/7.docker/#5-casos-de-uso","title":"5. Casos de uso","text":""},{"location":"UD00/7.docker/#compatibilidad-de-codigo-entre-diferentes-versiones-de-un-lenguaje","title":"Compatibilidad de c\u00f3digo entre diferentes versiones de un lenguaje","text":"<pre><code>mkdir /tmp/php\ncd /tmp/php\n</code></pre> <p>Crear el siguiente archivo (test.php)</p> <pre><code>&lt;?php\n// Funciona bien en php5 ya que list hace la asignaci\u00f3n desde el \u00faltimo al primero\n// En PHP 5, list() asigna los valores empezando desde el par\u00e1metro m\u00e1s a la derecha. En PHP 7, list() empieza desde el par\u00e1metro m\u00e1s a la izquierda.\n// https://www.php.net/manual/es/function.list.php\n$info = array('cafe\u00edna','marr\u00f3n', 'caf\u00e9');\n\n// Enumerar todas las variables\nlist($datos[], $datos[], $datos[]) = $info;\necho \"El $datos[0] es $datos[1] y la $datos[2] lo hace especial.\\n\";\n</code></pre> <p>A continuaci\u00f3n vamos a crear dos contenedores que sirva este c\u00f3digo usando im\u00e1genes distintas , para cada versi\u00f3n de PHP y usando puertos distintos para acceder a cada versi\u00f3n de la aplicaci\u00f3n:</p> <pre><code>docker run -d -p 8081:80 --name php56 -v /tmp/php:/var/www/html:ro php:5.6-apache\n## Accedemos al contenedor: docker exec -it eb326ffd1b66 /bin/bash\n## Ejecutamos test.php\n\n**docker run -d -p 8082:80 --name php74 -v /tmp/php:/var/www/html:ro php:7.4-apache**\n## Ejecutamos test.php desde web\n## http://localhost:8082/test.php\n</code></pre>"},{"location":"UD00/7.docker/#crear-una-imagen-de-un-repositorio-de-github","title":"Crear una imagen de un repositorio de github","text":"<p>Ejemplo repositorio:</p> <p>https://github.com/k4m4/kickthemout</p> <pre><code>FROM ubuntu:focal\n\nRUN apt update -y &amp;&amp; apt upgrade -y &amp;&amp; apt install python3 -y\nRUN apt install -y git\nRUN apt install -y python3-pip\nRUN git clone https://github.com/k4m4/kickthemout.git\n\nWORKDIR /kickthemout\n\nRUN pip3 install -r requirements.txt\n\nCMD python3 kickthemout.py\n</code></pre>"},{"location":"UD00/7.docker/#aplicacion-de-python-dentro-de-un-contenedor","title":"Aplicaci\u00f3n de python dentro de un contenedor","text":""},{"location":"UD00/7.docker/#crear-una-imagen-personalizada-pendiente","title":"Crear una imagen personalizada  \u2014 PENDIENTE \u2014","text":"<p>https://jolthgs.wordpress.com/2019/09/25/create-a-debian-container-in-docker-for-development/</p> <p>Para crear una imagen personalizada utilizaremos el contenedor que hab\u00edamos creado en el punto 1, con una debian actualizada y con un fichero de texto prueba.txt</p> <pre><code># Iniciamos el contenedor\ndocker start debian-mini\n\ndocker ps\nCONTAINER ID   IMAGE            COMMAND          CREATED          STATUS         PORTS     NAMES\n97d8dc048093   debian:10-slim   \"/bin/bash -l\"   10 minutes ago   Up 2 seconds             debian-mini\n\n# Entramos en el contenedor iniciado\ndocker exec -it debian-mini bash\n\n# Instalamos paquetes\napt install netris sl ninvaders\n\n# \u00bfD\u00f3nde est\u00e1n?\nfind / -name ninvaders\n\nls /usr/games\n\n# Salimos\ncontrol + d\n\n# Nuestra imagen\ndocker image ls\nREPOSITORY                             TAG       IMAGE ID       CREATED        SIZE\ndebian                                 10-slim   6016bddc4bad   9 days ago     63.5MB\n</code></pre>"},{"location":"UD00/7.docker/#otro-nombre-para-dockerfile","title":"Otro nombre para Dockerfile","text":"<pre><code>docker build -t test -f **otronombre** .\n</code></pre>"},{"location":"UD00/7.docker/#6-copias-de-seguridad","title":"6. Copias de seguridad","text":""},{"location":"UD00/7.docker/#copias-de-contenedores","title":"Copias de contenedores","text":"<p>Ya est\u00e9n encendidos o apagados, podemos realizar respaldos de seguridad de los contenedores. Utilizando la opci\u00f3n \u201cexport\u201d empaquetar\u00e1 el contenido, generando un fichero con extensi\u00f3n \u201c.tar\u201d de la siguiente manera:</p> <p>docker export -o fichero-resultante.tar nombre-contenedor </p> <p>o</p> <p>docker export nombre-contenedor &gt; fichero-resultante.tar </p>"},{"location":"UD00/7.docker/#restauracion-de-copias-de-seguridad-de-contenedores","title":"Restauraci\u00f3n de copias de seguridad de contenedores","text":"<p>Hay que tener en cuenta, antes de nada, que no es posible restaurar el contenedor directamente, de forma autom\u00e1tica. En cambio, s\u00ed podemos crear una imagen, a partir de un respaldo de un contenedor, mediante el par\u00e1metro \u201cimport\u201d de la siguiente manera:</p> <p>docker import fichero-backup.tar nombre-nueva-imagen </p>"},{"location":"UD00/7.docker/#copias-de-imagenes","title":"Copias de im\u00e1genes","text":"<p>Aunque no tiene mucho sentido por que se bajan muy r\u00e1pido, tambi\u00e9n tenemos la posibilidad de realizar copias de seguridad de im\u00e1genes. El proceso se realiza al utilizar el par\u00e1metro \u2018save\u2018, que empaquetar\u00e1 el contenido y generar\u00e1 un fichero con extensi\u00f3n \u201ctar\u201c, as\u00ed:</p> <p>docker save nombre_imagen &gt; imagen.tar </p> <p>o</p> <p>docker save -o imagen.tar nombre_imagen </p>"},{"location":"UD00/7.docker/#restaurar-copias-de-seguridad-de-imagenes","title":"Restaurar copias de seguridad de im\u00e1genes","text":"<p>Con el par\u00e1metro \u2018load\u2019, podemos restaurar copias de seguridad en formato \u2018.tar\u2019 y de esta manera recuperar la imagen.</p> <p>docker load -i fichero.tar </p>"},{"location":"UD00/7.docker/#7-contenedores-ejemplo","title":"7. Contenedores ejemplo","text":"<p>netdata</p> <p>Nginx Proxy Manager - acceso https con certificados v\u00e1lidos para mi red local, no la tengo abierta al exterior.</p> <p>Jellyfin - multimedia</p> <p>Nextcloud - nube</p> <p>Syncserver - sincronizar datos de firefox entre dispositivos (este est\u00e1 absoleto, publicaron otra herramienta pero hay poca informaci\u00f3n y a\u00fan no he conseguido hacerla funcionar)</p> <p>Vaultwarden - contrase\u00f1as</p> <p>Camera.ui - Para ver las c\u00e1maras e integrarlas en la casa de Apple.</p> <p>Homebridge - para poder usar dispositivos no compatibles en la casa de Apple</p> <p>HomeAssistant - ahora mismo la uso poco porque uso m\u00e1s la de Apple, pero ser\u00eda el equivalente en software libre</p> <p>Portainer - para gestionar los contenedores</p> <p>Photoprism - para ver las fotos</p> <p>Homepage - como p\u00e1gina de inicio con los contenedores y dem\u00e1s aplicaciones instaladas en el nas</p> <p>soulseek - para m\u00fasica</p> <p>youtubedl - para bajar musica de youtube</p> <p>glances - para ver informacion del estado del servidor v\u00eda web</p> <p>linkding - para guardar enlaces</p> <p>acestream - para ver canales en jellyfin</p> <p>gitbucket - para listas de acestream y de pihole</p> <p>libreddit - reedit sin publicidad (aunque en modo s\u00f3lo lectura, no se puede enviar contenido)</p> <p>invidious - para ver youtube</p> <p>uptime kuma - para ver si alguno de los contenedores o aplicaciones se caen</p> <p>searxng - un metabuscador para tener google, duckdns y otros en un mismo sitio</p> <p>watchtower - para actualizar autom\u00e1ticamente algunos contenedores</p>"},{"location":"UD00/7.docker/#8-ejercicios","title":"8. Ejercicios","text":""},{"location":"UD00/7.docker/#python","title":"Python","text":"<p>Crea 2 contenedores, uno con python 3.11 y otro con python 3.9</p> <pre><code>docker run -d --name python3.11 -v /tmp/php:/app python:3.11\n</code></pre>"},{"location":"UD00/8.EntornosVirtualesPython/","title":"Entornos virtuales python","text":""},{"location":"UD00/8.EntornosVirtualesPython/#entorno-por-defecto","title":"Entorno por defecto","text":"<pre><code>$ pip list\nPackage                   Version\n------------------------- ------------\naiohttp                   3.9.1\naiosignal                 1.3.1\naltair                    5.2.0\naltgraph                  0.17.2\nannotated-types           0.6.0\nanyio                     4.2.0\nappnope                   0.1.3\nasttokens                 2.4.1\n...\n...\n...\n</code></pre> <pre><code>$ mkdir entornos\n$ cd entornos\n\n$ pip install faker #instalamos en global\n$ pip list | grep Faker\nFaker                     20.1.0\n\n# Tenemos instalada la versi\u00f3n 20.1.0 en global\n</code></pre>"},{"location":"UD00/8.EntornosVirtualesPython/#creacion-entorno-virtual","title":"Creaci\u00f3n entorno virtual","text":"<pre><code>$ python3 -m venv entorno_virtual\n$ ls\nentorno_virtual\n</code></pre> <p>Lo activamos</p> <pre><code>$ source entorno_virtual/bin/activate\n\n**(entorno_virtual)** &lt;\u25b8&gt; ~/W/py/entornos\n</code></pre> <p>Mostramos los paquetes instalados en este entorno</p> <pre><code>$ pip list\nPackage Version\n------- -------\npip     24.0\n(entorno_virtual)\n</code></pre> <p>Instalamos otra versi\u00f3n de faker</p> <pre><code>$ pip install faker==25.2\n\n$ pip list\n</code></pre> <p>Salimos del entorno virtual</p> <pre><code>$ deactivate\n</code></pre> <p>Volvemos a entrar al entorno y congelamos los paquetes utilizados</p> <pre><code>$ source entorno_virtual/bin/activate\n\n**(entorno_virtual)** &lt;\u25b8&gt; ~/W/py/entornos\n\n$ pip freeze &gt; requirements.txt\n\n$ cat requirements.txt\n</code></pre> <p>Creamos un script con python.</p> <pre><code>'''test.py'''\nfrom faker import Faker\nfake = Faker()\n\nprint(fake.name())\n</code></pre>"},{"location":"UD00/8.EntornosVirtualesPython/#cual-es-la-utilidad-de-requirementstxt","title":"\u00bfCu\u00e1l es la utilidad de requirements.txt?","text":"<p>Ahora podemos compartir nuestro proyecto (github u otro ordenador), subiendo \u00fanicamente los archivos requirements.txt y el script que hemos creado (test.py).</p> <p>Para simular esta acci\u00f3n, vamos a borrar nuestro entorno.</p> <pre><code>$ deactivate\n\n$ rm -rf entorno_virtual\n</code></pre> <p>Restauramos el entorno que ten\u00edamos</p> <pre><code>$ python3 -m venv entorno2\n\n$ source entorno2/bin/activate # Lo activamos\n(entorno2)\n\n# Instalamos las dependencias que ten\u00edamos\n$ pip install -r requirements.txt\n</code></pre> <p>Cuando creamos un entorno virtual con venv solemos llamar a la carpeta del entorno \u201cvenv\u201d</p> <pre><code>$ python3 -m venv venv\n</code></pre> <p>Al utilizar git, podemos crear un archivo .gitignore que contenga entre otras cosas:</p> <pre><code># Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n</code></pre> <p>Ejemplo .gitignore para python:</p> <p>https://raw.githubusercontent.com/github/gitignore/main/Python.gitignore</p>"},{"location":"UD00/9.ModificarApuntes/","title":"Realizar pull request","text":"<p>Para a\u00f1adir una correcci\u00f3n o mejora a los apuntes, nos vamos a la parte superior de la p\u00e1gina que queremos editar.  A continuaci\u00f3n nos dirige a github, hay que hacer un fork del repositorio:  Ahora ya podemos editar el archivo, una vez finalizado click en \"commit changes\":  Describimos los cambios realizados (importante)  Creamos una pull request </p>"},{"location":"UD00/9.ModificarApuntes/#como-aprobar-un-pull-request","title":"\u00bfC\u00f3mo aprobar un pull request?","text":""},{"location":"UD00/_TODO/","title":"PENDENT","text":"<p>Hardware - Grupos de discos LVM (ubuntu)</p> <p>Big data Scripts - https://markobigdata.com/2018/04/25/bash-script-for-creating-new-user-in-hadoop-and-ambari-views/</p>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/","title":"UD01 - Big Data. Hadoop.","text":""},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/#teoria","title":"Teor\u00eda","text":"<p>UD01 - Hadoop. Introduccio\u0301n.pdf</p> <p>Presentaci\u00f3n, diapositivas</p> <p></p> <p>https://docs.google.com/presentation/d/1M3rEkf7FvIfpyjGgWZ-rXq5TxPM_zb1xgQF8WBmRPmk/edit?usp=sharing</p>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/#practica","title":"Pr\u00e1ctica","text":"<p>https://www.profesionalreview.com/2020/08/16/como-usar-virtualbox/</p> <p>UD01 1. Instalaci\u00f3n Ubuntu server. Configuraci\u00f3n entorno.</p> <p>UD01 2. Descarga y configuraci\u00f3n Hadoop.</p> <p>UD01 3. Hadoop, ejercicios.</p> <p>UD01 3b. Hadoop, ejercicios (soluciones).</p>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%201%20Instalacio%CC%81n%20Ubuntu%20server%20Configuracio%CC%81n%20e%20118e913de6c48108a732f4e1dad8e84d/","title":"UD01 1. Instalaci\u00f3n Ubuntu server. Configuraci\u00f3n entorno.","text":""},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%201%20Instalacio%CC%81n%20Ubuntu%20server%20Configuracio%CC%81n%20e%20118e913de6c48108a732f4e1dad8e84d/#1-descargar-e-instalar","title":"1. Descargar e instalar","text":"<p>https://ubuntu.com/download/server#manual-install</p> <p>LTS: The latest LTS version of Ubuntu, for desktop PCs and laptops. LTS stands for long-term support \u2014 which means five years of free security and maintenance updates</p> <p></p>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%201%20Instalacio%CC%81n%20Ubuntu%20server%20Configuracio%CC%81n%20e%20118e913de6c48108a732f4e1dad8e84d/#2-configuracion-del-entorno","title":"2. Configuraci\u00f3n del entorno","text":"<p>Una vez instalada la m\u00e1quina ubuntu pasamos a la configuraci\u00f3n de la misma.</p>  \ud83d\udca1 **INFO:** Para editar los ficheros utilizar\u00e9 el editor de consola vi o vim, puedes utilizar cualquier otro (como nano)."},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%201%20Instalacio%CC%81n%20Ubuntu%20server%20Configuracio%CC%81n%20e%20118e913de6c48108a732f4e1dad8e84d/#21-preparar-el-sistema","title":"2.1. Preparar el sistema","text":"<p>a) Podemos desactivar el entorno gr\u00e1fico al iniciar sesi\u00f3n ejecutando el siguiente comando como root:</p> <p>Si hemos instalado Ubuntu Server no es necesario, no tiene entorno gr\u00e1fico.</p> <pre><code>/sbin/systemctl set-default multi-user.target\n\n/sbin/sysctl set-default multi-user.target\n</code></pre> <p>b) Crear un usuario llamado hadoop, ese usuario lo utilizaremos para instalar hadoop.</p> <pre><code>adduser hadoop\n# Si no encuentra el comando /sbin/adduser\n# $PATH\n# No te olvides del password\n\ncat /etc/password # Mostrar\u00e1 el usuario creado\nls -la /home/ # Aparecer\u00e1 la \"home\" del usuarios\n</code></pre> <p>c) Poner el teclado en espa\u00f1ol, en caso de que la instalaci\u00f3n nos haya dejado un layout ingl\u00e9s (Si te funciona la \u00d1 salta este paso)</p> <pre><code>sudo apt-get install console-data\n\n# localectl set-keymap es\n</code></pre> <p>d) Comprobamos que ssh est\u00e9 funcionando, en caso contrario hay que instalarlo y configurarlo.</p> <pre><code>ssh localhost\n</code></pre>  \u26a0\ufe0f Pendiente, ssh sin contrase\u00f1a   <p>e) Para conocer nuestra IP</p> <pre><code>## Opci\u00f3n 1\n$ hostname -I\n\n## Opci\u00f3n 2\n$ ip addr\n\n## Opci\u00f3n 3\n# en /sbin/ifconfig ???\n$ apt install net-tools\n$ sudo ifconfig\n</code></pre> <p></p> <p></p>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%201%20Instalacio%CC%81n%20Ubuntu%20server%20Configuracio%CC%81n%20e%20118e913de6c48108a732f4e1dad8e84d/#22-instalar-paquetes-en-debian","title":"2.2. Instalar paquetes en debian","text":"<p>Como root o utilizando sudo</p> <pre><code># Actualizar \u00edndice de paquetes (para ver si hay nuevas versiones)\nsudo apt update\n\n# Instalar un paquete o programa\nsudo apt install [package_name]\n\n# Borrar un paquete\napt remove [package_name]\n\n# Borrar un paquete y ficheros de configuraci\u00f3n\napt purge [package_name]\n\n# Actualizar paquetes a la \u00faltima versi\u00f3n\napt upgrade\n\n# B\u00fasqueda de paquetes\napt search [text_to_search]\n\n# \"Arreglar\" paquetes rotos\napt -f install\n</code></pre> <p>M\u00e1s info en:</p> <p>https://www.2daygeek.com/debian-ubuntu-apt-command-guide/</p>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%201%20Instalacio%CC%81n%20Ubuntu%20server%20Configuracio%CC%81n%20e%20118e913de6c48108a732f4e1dad8e84d/#23-instalar-java","title":"2.3. Instalar Java","text":"<p>https://hadoop.apache.org/release/3.4.0.html</p>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%201%20Instalacio%CC%81n%20Ubuntu%20server%20Configuracio%CC%81n%20e%20118e913de6c48108a732f4e1dad8e84d/#231-openjdk","title":"2.3.1 openjdk","text":"<p>OpenJDK es la versi\u00f3n libre de la plataforma de desarrollo Java bajo concepto de lenguaje orientado a objetos.</p> <ul> <li>Es opensource</li> <li>Implementaci\u00f3n de referencia</li> <li>Detr\u00e1s hay empresas como: IBM, Apple, SAP, Mac, Azul, Intel, RedHat etc.</li> <li>\u2026</li> </ul> <pre><code># Actualizar paquetes\napt update\n# Instalamos la versi\u00f3n openjdk-11 (compatible con hadoop, la 17 da problemas)\napt install openjdk-11-jdk\n\n# Comprobamos el path de instalaci\u00f3n de la aplicaci\u00f3n\n# Este path lo utilizaremos en el punto posterior (.bashrc)\nls -la /usr/lib/jvm/java-11-openjdk-amd64\n\njava -version\njavac -version\n# Estos comandos nos devuelven informaci\u00f3n sobre la versi\u00f3n de java que hemos instalado\n</code></pre>  \u26a0\ufe0f **ERROR - ERROR - ERROR - ERROR - ERROR - ERROR - ERROR - ERROR**  La  versi\u00f3n 17 de openjdk da error con `webdfs` (Lo veremos en la UD02). Utilizar java 11: [https://cfdownload.adobe.com/pub/adobe/coldfusion/java/java11/java11020/jdk-11.0.20_linux-x64_bin.deb](https://cfdownload.adobe.com/pub/adobe/coldfusion/java/java11/java11020/jdk-11.0.20_linux-x64_bin.deb)"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%201%20Instalacio%CC%81n%20Ubuntu%20server%20Configuracio%CC%81n%20e%20118e913de6c48108a732f4e1dad8e84d/#24-bashrc","title":"2.4.  .bashrc","text":"<p>Se ejecuta cada vez que se inicia sesi\u00f3n.</p> <p>Contiene una serie de configuraciones para la sesi\u00f3n de terminal. Esto incluye configurar o habilitar: colorear, completar, historial de shell, alias de comando y m\u00e1s.</p> <pre><code>**Ejercicio**\n\nEdita el archivo .bashrc de tu usuario, a\u00f1ade un saludo y una variable, por ejemplo:\n\necho \"*** Bienvenido A $HOSTNAME ***\"\nNUMERO=50\n\nSal de la sesi\u00f3n y vuelve a entrar, \u00bfAparece el saldo? \u00bfPuedes acceder a la variable?\n</code></pre> <p>Para poder utilizar JAVA tenemos que crear la variable JAVA_HOME y a\u00f1adir su path a PATH.</p> <p>A\u00f1adimos diferentes variables necesarias para utilizar java a .bashrc</p> <p>Accedemos al sistema con el usuario hadoop que hemos creado anteriormente.</p> <pre><code>## ACCEDEMOS COMO HADOOP\nid \n\n# Volvemos a casa\ncd\n\n# Editamos el archivo\nnano .bashrc\n\n# A\u00f1adimos al final...\n\nexport JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64\nexport PATH=$PATH:/usr/lib/jvm/java-17-openjdk-amd64/bin\n</code></pre> <p>export permite que la variable est\u00e9 disponible para subprocesos de la shell en ejecuci\u00f3n. Pone la variable en el ambiente para que otros procesos puedan hacer uso de estas.</p> <p>La variable PATH contiene una lista de directorios separados por dos puntos. Estos son los directorios en los que el shell busca el comando que el usuario escribe desde el teclado.</p> <pre><code>**Ejercicio**\n\nVamos a borrar la variable path para la sesi\u00f3n actual, cuando reiniciemos la sesi\u00f3n continuar\u00e1 igual\n\n1. Ejecutamos el comando ls -la\n2. echo $PATH\n3. Modificamos el valor de PATH\n        PATH=\n4. Ejecutamos de nuevo el comando ls -la\n5. Modificamos el valor de PATH\n        PATH=/bin/\n6. echo $PATH\n7. ls -la\n</code></pre>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%202%20Descarga%20y%20configuracio%CC%81n%20Hadoop%20118e913de6c48021ba84c3a24ca46539/","title":"UD01 2. Descarga y configuraci\u00f3n Hadoop.","text":""},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%202%20Descarga%20y%20configuracio%CC%81n%20Hadoop%20118e913de6c48021ba84c3a24ca46539/#1-descarga-instalacion-de-hadoop","title":"1. Descarga + \u201cinstalaci\u00f3n\u201d de hadoop","text":"<p>Informaci\u00f3n y descargas:</p> <p>https://hadoop.apache.org/</p> <p></p>  \u2139\ufe0f Tutorial digitalocean [https://www.digitalocean.com/community/tutorials/how-to-install-hadoop-in-stand-alone-mode-on-ubuntu-20-04](https://www.digitalocean.com/community/tutorials/how-to-install-hadoop-in-stand-alone-mode-on-ubuntu-20-04)   <p>Descargamos Hadoop (Binary download)</p> <p>https://hadoop.apache.org/releases.html</p> <p></p> <ul> <li> <p>Copiamos la URL con la \u00faltima versi\u00f3n, \u00bfQu\u00e9 version descargar?</p> <p>Instalaciones por defecto</p> <p>https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz</p> <p>Instalaci\u00f3n en un MAC m1 o m2 (procesador ARM)</p> <p>https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6-aarch64.tar.gz</p> <p> \u26a0\ufe0f Pendiente, verificar archivo descargado con la firma <p>Desde ssh a la m\u00e1quina virtual, como root:</p> <pre><code>cd /opt\n\n# Descargamos\nwget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\n\n# Descomprimimos\ntar -zxvf hadoop-3.3.6.tar.gz\nls -la\n\n# Creamos un enlace para trabajar de manera m\u00e1s c\u00f3moda\nln -s hadoop-3.3.6 hadoop\nls -la\n\n# Cambiamos el propietario y grupo de la carpeta y enlace creado\n# En el documento anterior creamos el usuario hadoop\nchown -R hadoop:hadoop hadoop-3.3.6 hadoop\n\n# Entramos a la carpeta descomprimida (a trav\u00e9s del enlace creado)\ncd hadoop\n</code></pre> <p>Accedemos ahora a la m\u00e1quina con usuario hadoop y modificamos de nuevo el archivo .bashrc, le a\u00f1adimos las siguientes l\u00edneas:</p> <pre><code># HADOOP_HOME sin barra final\nexport HADOOP_HOME=/opt/hadoop\nexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\nexport PATH=$PATH:$HADOOP_HOME/bin\nexport PATH=$PATH:$HADOOP_HOME/sbin\n</code></pre> <p>#### NO A\u00d1ADIR DE MOMENTO ESTAS VARIABLES</p> <p>export HADOOP_MAPRED_HOME=$HADOOP_HOME export YARN_HOME=$HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export HADOOP_OPTS=\"-Djava.library.path=$HADOOP_HOME/lib/native\" export HADOOP_STREAMING=$HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.2.3.jar export HADOOP_LOG_DIR=$HADOOP_HOME/logs export PDSH_RCMD_TYPE=ssh</p> <p>Recargamos .bashrc saliendo y volviendo a entrar o mediante:</p> <pre><code>source .bashrc\n</code></pre> <p>Si todo ha ido bien ya podremos ejecutar hadoop:</p> <pre><code>hadoop -h\n\nhadoop version\n</code></pre>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%202%20Descarga%20y%20configuracio%CC%81n%20Hadoop%20118e913de6c48021ba84c3a24ca46539/#2-directorios-dentro-de-hadoop","title":"2. Directorios dentro de Hadoop","text":"<pre><code>/opt/hadoop/bin -&gt; \"ejecutables\"\n    hadoop, hdfs, mapred, yar\n\n/opt/hadoop/etc -&gt; ficheros de configuracion xml\n\n/opt/hadoop/lib -&gt; librer\u00edas nativas\n\n/opt/hadoop/sbin -&gt; scripts, utilidades que me permiten entre otras cosas arrancar y parar hadoop\n\n/opt/hadoop/share -&gt; paquetes, ejemplos ...\n</code></pre>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%202%20Descarga%20y%20configuracio%CC%81n%20Hadoop%20118e913de6c48021ba84c3a24ca46539/#3-comprobar-que-hadoop-funciona","title":"3. Comprobar que hadoop funciona","text":"<p>Para comprobar que <code>mapreduce</code> funciona, vamos a ejecutar unos ejemplos que podemos encontrar dentro de share.</p> <pre><code>$ pwd\n/opt/hadoop/share/hadoop/mapreduce\n\n# Podemos ver los ejemplos que se pueden ejecutar ejecutando sobre el paquete de ejemplos mapreduce\n$ jar tf hadoop-mapreduce-examples-3.3.6.jar\n# Nos sale un listado de todos los comandos u opciones de este paquete\n\n#### Vamos a ejecutar por ejemplo: \n#### org/apache/hadoop/examples/Grep.class\n\n# Preparamos los directorios donde estar\u00e1n los datos de entrada (en /tmp) y copiamos datos de entrada \"demo\",\n# por ejemplo ficheros de configuraci\u00f3n de hadoop\n$ mkdir /tmp/entrada\n$ cd /tmp/entrada\n$ cp /opt/hadoop/etc/hadoop/*.xml .\n\n## Vamos a buscar (tal y como hace grep), las palabras que contengan un determiando texto, en este caso\n## palabras que contengan el texto kms\n$ cd /opt/hadoop/share/hadoop/mapreduce/\n\n## Invocamos al paquete de ejemplos, comando grep\n$ hadoop jar hadoop-mapreduce-examples-3.3.6.jar grep /tmp/entrada /tmp/salida/ 'kms'\n\n## Hace una serie de procesos mapper y reducer (lo veremos m\u00e1s adelante)\n$ cd /tmp/salida/\n$ ls\npart-r-00000  _SUCCESS\n\n# _SUCCESS -&gt; ha sido satisfactorio\n\n# \u00bfCu\u00e1ntas veces ha encontrado la palabra kms?\n$ cat part-r-00000\n9   kms\n\n-------------------------------------------------\n# Se trata de un programa b\u00e1sico inicial para comprobar que funciona, podemos hacer lo mismo desde bash:\ncd /tmp/entrada\negrep kms * | wc -l\n</code></pre>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%202%20Descarga%20y%20configuracio%CC%81n%20Hadoop%20118e913de6c48021ba84c3a24ca46539/#4-posibles-errores","title":"4. Posibles Errores","text":"<p>ERROR 1 El directorio /tmp/salida ya existe, dar\u00e1 error si no se borra</p> <p>ERROR 2 Cannot execute /home/debian/hadoop-3.2.3//libexec/hadoop-config.sh En .bashrc hemos a\u00f1adido una barra al final de HADOOP_HOME Modificar archivo, guardar cambios y luego ejecutar: source .bashrc (para que los cambios se apliquen a la sesi\u00f3n) ERROR: JAVA_HOME /usr/lib/jvm/java-17-openjdk-amd64 does not exist La variable de sesi\u00f3n JAVA_HOME no es correcta, revisa la carpeta de java</p> <p>ERROR 3 ERROR: JAVA_HOME /usr/lib/jvm/java-17-openjdk-amd64 does not exist La variable de sesi\u00f3n JAVA_HOME no es correcta, revisa la carpeta de java</p>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%203%20Hadoop%2C%20ejercicios%2011ce913de6c4801d9a1fecb53c37ad66/","title":"UD01 3. Hadoop, ejercicios.","text":""},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%203%20Hadoop%2C%20ejercicios%2011ce913de6c4801d9a1fecb53c37ad66/#1-ejemplos-de-mapreduce","title":"1. Ejemplos de mapreduce:","text":"<p>El fichero de ejemplos hadoop-mapreduce-examples, contiene los siguientes:</p> aggregatewordcount Cuenta las palabras de los archivos de entrada. aggregatewordhist Calcula el histograma de las palabras de los archivos de entrada. <code>bbp</code> Uusa una f\u00f3rmula Bailey-Borwein-Plouffe para calcular los d\u00edgitos exactos de Pi. dbcount Cuenta los registros de vistas de p\u00e1gina almacenados en una base de datos. distbbp Usa una f\u00f3rmula de tipo BBP para calcular los bits exactos de Pi. grep Cuenta las coincidencias de una expresi\u00f3n regular en la entrada. join Realiza una uni\u00f3n de conjuntos de datos ordenados con particiones equiparables. multifilewc Cuenta las palabras de varios archivos. pentomino Programa para la colocaci\u00f3n de mosaicos con el fin de encontrar soluciones a problemas de pentomin\u00f3. pi Calcula Pi mediante un m\u00e9todo cuasi Monte Carlo. randomtextwriter Escribe 10\u00a0GB de datos de texto aleatorios por nodo. <code>randomwriter</code> Escribe 10\u00a0GB de datos aleatorios por nodo. <code>secondarysort</code> Define una ordenaci\u00f3n secundaria para la fase de reducci\u00f3n. sort Ordena los datos escritos por el escritor aleatorio. sudoku un solucionador de sudokus. 1 par\u00e1metro de entrada, el archivo que representa el sudoku a resolver. teragen genera datos para la ordenaci\u00f3n de terabytes (terasort). terasort ejecuta la ordenaci\u00f3n de terabytes (terasort). teravalidate comprueba los resultados de la ordenaci\u00f3n de terabytes (terasort). wordcount Cuenta las palabras de los archivos de entrada. 2 par\u00e1metros en la llamada: - Ruta al fichero del que se quiere contar - Directorio de salida, donde crear\u00e1 los ficheros de salida <code>wordmean</code> Cuenta la longitud media de las palabras de los archivos de entrada. <code>wordmedian</code> Cuenta la mediana de las palabras de los archivos de entrada. wordstandarddeviation Cuenta la desviaci\u00f3n est\u00e1ndar de la longitud de las palabras de los archivos de entrada."},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%203%20Hadoop%2C%20ejercicios%2011ce913de6c4801d9a1fecb53c37ad66/#2-ejercicios","title":"2. Ejercicios","text":"<pre><code>**1. Cuenta las veces que aparece la palabra \"allowed\" en los ficheros de configuraci\u00f3n de hadoop.**\n** Los ficheros de configuraci\u00f3n de hadoop son archivos XML, busca todos los archivos y copialos \nen una carpeta, por ejemplo:\n/tmp/ejercicio1\n\n**2. Resuelve el siguiente sudoku:**\n8 5 ? 3 9 ? ? ? ?\n? ? 2 ? ? ? ? ? ?\n? ? 6 ? 1 ? ? ? 2\n? ? 4 ? ? 3 ? 5 9\n? ? 8 9 ? 1 4 ? ?\n3 2 ? 4 ? ? 8 ? ?\n9 ? ? ? 8 ? 5 ? ?\n? ? ? ? ? ? 2 ? ?\n? ? ? ? 4 5 ? 7 8\n\nPista: jar tf hadoop-mapreduce-examples-3.3.6.jar | grep -i sudoku\n\n**3. Cuenta las palabras del libro \"Romeo y Julieta\"**\nhttps://raw.githubusercontent.com/lynnlangit/learning-hadoop-and-spark/master/0b-Example-Datasets/shakespeare-davinci/romeo.txt\n\n** Ejemplo:\nhttps://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Source_Code\n</code></pre>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%203%20Hadoop%2C%20ejercicios%2011ce913de6c4801d9a1fecb53c37ad66/#3-posibles-errores","title":"3. Posibles errores","text":"<p>ERROR 1 El directorio /tmp/salida ya existe, dar\u00e1 error si no se borra</p> <p>ERROR 2 Cannot execute /home/debian/hadoop-3.2.3//libexec/hadoop-config.sh En .bashrc hemos a\u00f1adido una barra al final de HADOOP_HOME Modificar archivo, guardar cambios y luego ejecutar: source .bashrc (para que los cambios se apliquen a la sesi\u00f3n) ERROR: JAVA_HOME /usr/lib/jvm/java-17-openjdk-amd64 does not exist La variable de sesi\u00f3n JAVA_HOME no es correcta, revisa la carpeta de java</p> <p>ERROR 3 ERROR: JAVA_HOME /usr/lib/jvm/java-17-openjdk-amd64 does not exist La variable de sesi\u00f3n JAVA_HOME no es correcta, revisa la carpeta de java</p>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%203b%20Hadoop%2C%20ejercicios%20%28soluciones%29%2011ce913de6c480a58efef799646e5fb7/","title":"UD01 3b. Hadoop, ejercicios (soluciones).","text":""},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%203b%20Hadoop%2C%20ejercicios%20%28soluciones%29%2011ce913de6c480a58efef799646e5fb7/#1-ejemplos-de-mapreduce","title":"1. Ejemplos de mapreduce:","text":"<p>El fichero de ejemplos hadoop-mapreduce-examples, contiene los siguientes:</p> aggregatewordcount Cuenta las palabras de los archivos de entrada. aggregatewordhist Calcula el histograma de las palabras de los archivos de entrada. <code>bbp</code> Uusa una f\u00f3rmula Bailey-Borwein-Plouffe para calcular los d\u00edgitos exactos de Pi. dbcount Cuenta los registros de vistas de p\u00e1gina almacenados en una base de datos. distbbp Usa una f\u00f3rmula de tipo BBP para calcular los bits exactos de Pi. grep Cuenta las coincidencias de una expresi\u00f3n regular en la entrada. join Realiza una uni\u00f3n de conjuntos de datos ordenados con particiones equiparables. multifilewc Cuenta las palabras de varios archivos. pentomino Programa para la colocaci\u00f3n de mosaicos con el fin de encontrar soluciones a problemas de pentomin\u00f3. pi Calcula Pi mediante un m\u00e9todo cuasi Monte Carlo. randomtextwriter Escribe 10\u00a0GB de datos de texto aleatorios por nodo. <code>randomwriter</code> Escribe 10\u00a0GB de datos aleatorios por nodo. <code>secondarysort</code> Define una ordenaci\u00f3n secundaria para la fase de reducci\u00f3n. sort Ordena los datos escritos por el escritor aleatorio. sudoku un solucionador de sudokus. 1 par\u00e1metro de entrada, el archivo que representa el sudoku a resolver. teragen genera datos para la ordenaci\u00f3n de terabytes (terasort). terasort ejecuta la ordenaci\u00f3n de terabytes (terasort). teravalidate comprueba los resultados de la ordenaci\u00f3n de terabytes (terasort). wordcount Cuenta las palabras de los archivos de entrada. 2 par\u00e1metros en la llamada: - Ruta al fichero del que se quiere contar - Directorio de salida, donde crear\u00e1 los ficheros de salida <code>wordmean</code> Cuenta la longitud media de las palabras de los archivos de entrada. <code>wordmedian</code> Cuenta la mediana de las palabras de los archivos de entrada. wordstandarddeviation Cuenta la desviaci\u00f3n est\u00e1ndar de la longitud de las palabras de los archivos de entrada."},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%203b%20Hadoop%2C%20ejercicios%20%28soluciones%29%2011ce913de6c480a58efef799646e5fb7/#3-ejercicios","title":"3. Ejercicios","text":"<pre><code>1. Cuenta las veces que aparece la palabra \"allowed\" en los ficheros de configuraci\u00f3n de hadoop.\n\n2. Resuelve el siguiente sudoku:\n8 5 ? 3 9 ? ? ? ?\n? ? 2 ? ? ? ? ? ?\n? ? 6 ? 1 ? ? ? 2\n? ? 4 ? ? 3 ? 5 9\n? ? 8 9 ? 1 4 ? ?\n3 2 ? 4 ? ? 8 ? ?\n9 ? ? ? 8 ? 5 ? ?\n? ? ? ? ? ? 2 ? ?\n? ? ? ? 4 5 ? 7 8\n\nPista: jar tf hadoop-mapreduce-examples-3.3.6.jar | grep -i sudoku\n\n3. Cuenta las palabras del libro \"Romeo y Julieta\"\nhttps://raw.githubusercontent.com/lynnlangit/learning-hadoop-and-spark/master/0b-Example-Datasets/shakespeare-davinci/romeo.txt\n\nEjemplo:\nhttps://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Source_Code\n</code></pre> <ul> <li> <p>Soluciones</p> <pre><code>**2. Sudoku**\n$ pwd\n/opt/hadoop/share/hadoop/mapreduce\n$ mkdir /tmp/sudoku/entrada\n$ wget https://raw.githubusercontent.com/naver/hadoop/master/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/dancing/puzzle1.dta -P /tmp/sudoku/entrada/\n**SOLUCION**\n$ hadoop jar hadoop-mapreduce-examples-3.3.6.jar sudoku /tmp/input/puzzle1.dta\n\n**3. Cuenta palabras**\n$ hadoop jar hadoop-mapreduce-examples-3.3.6.jar wordcount /tmp/input/romeo.txt /tmp/salidaromeo\n</code></pre> </li> </ul>"},{"location":"UD01/_PENDENT/UD01%20-%20Big%20Data%20Hadoop%20118e913de6c4806493b8e271ad30161a/UD01%203b%20Hadoop%2C%20ejercicios%20%28soluciones%29%2011ce913de6c480a58efef799646e5fb7/#4-errores","title":"4. Errores","text":"<p>ERROR 1 Cannot execute /home/debian/hadoop-3.2.3//libexec/hadoop-config.sh En .bashrc hemos a\u00f1adido una barra al final de HADOOP_HOME Modificar archivo, guardar cambios y luego ejecutar: source .bashrc (para que los cambios se apliquen a la sesi\u00f3n) ERROR: JAVA_HOME /usr/lib/jvm/java-17-openjdk-amd64 does not exist La variable de sesi\u00f3n JAVA_HOME no es correcta, revisa la carpeta de java</p> <p>ERROR 2 ERROR: JAVA_HOME /usr/lib/jvm/java-17-openjdk-amd64 does not exist La variable de sesi\u00f3n JAVA_HOME no es correcta, revisa la carpeta de java</p>"},{"location":"UD02/1.instalacion/","title":"HDFS. Cluster Hadoop pseudodistribuido.","text":"<p>Custer Pseudodistribuido</p> <p>Tambi\u00e9n conocido como Cluster de un solo nodo. Como solo tenemos un nodo, el mismo nodo ser\u00e1 el maestro y el esclavo (no pasar\u00e1 nunca en producci\u00f3n ya que siempre tendremos un maestro y varios esclavos).</p>"},{"location":"UD02/1.instalacion/#requisitos","title":"Requisitos","text":"<ul> <li>Hadoop descargado y descomprimido en /opt (lo hicimos anteriormente).</li> <li>El usuario hadoop ha de poder conectarse como usuario hadoop sin password<ul> <li>El usuario <code>hadoop</code>ha de poder realizar un <code>ssh hadoop@localhost</code> y ha de loguearse autom\u00e1ticamente, sin que se le pida password.</li> </ul> </li> <li>PROBAR SIN ESTE PUNTO El usuario hadoop ha de poder conectarse como root por ssh sin password.<ul> <li>Al ejecutar como hadoop <code>$ ssh root@localhost</code>no ha de pedir contrase\u00f1a, la primera vez tendremos que aceptar la key pero a partir de ese momento se loguear\u00e1 autom\u00e1ticamente al ejecutar el comando.</li> </ul> </li> </ul>"},{"location":"UD02/1.instalacion/#creacion-configuracion-del-cluster","title":"Creaci\u00f3n / configuraci\u00f3n del cluster","text":"<p>Como usuario <code>hadoop</code> Accedemos por ssh a la m\u00e1quina virtual en la que hab\u00edamos descomprimido hadoop.</p> <pre><code>cd /opt/hadoop/etc/hadoop/\n\n$ ls\ncapacity-scheduler.xml      hadoop-user-functions.sh.example  kms-log4j.properties        ssl-client.xml.example\nconfiguration.xsl           hdfs-rbf-site.xml                 kms-site.xml                ssl-server.xml.example\ncontainer-executor.cfg      **hdfs-site.xml**                     log4j.properties            user_ec_policies.xml.template\n**core-site.xml**               httpfs-env.sh                     mapred-env.cmd              workers\nhadoop-env.cmd              httpfs-log4j.properties           mapred-env.sh               yarn-env.cmd\nhadoop-env.sh               httpfs-site.xml                   mapred-queues.xml.template  yarn-env.sh\nhadoop-metrics2.properties  kms-acls.xml                      **mapred-site.xml**             yarnservice-log4j.properties\nhadoop-policy.xml           kms-env.sh                        shellprofile.d              **yarn-site.xml**\n</code></pre> <p>Ficheros m\u00e1s importantes. <pre><code>core-site.xml \u2192 configuraci\u00f3n general del cluster.\nhdfs-site.xml \u2192 configuraci\u00f3n sistema de ficheros hdfs.\nmapred-site.xml \u2192 configuraci\u00f3n de mapreduce. # de moment no\nhadoop-env.sh -&gt; entorno del servidor\nyarn-site.xml \u2192 configuraci\u00f3n del modo de trabajo del proceso yarn. # de moment no\n</code></pre></p>"},{"location":"UD02/1.instalacion/#core-sitexml","title":"core-site.xml","text":"<p>Inicialmente est\u00e1 vac\u00edo.</p> <p>Lo modificamos para indicarle: name \u2192 Qu\u00e9 sistema de fichero vamos a utilizar en hadoop (por defecto hdfs, hay otros). value \u2192 D\u00f3nde se encuentra el servidor maestro que va a contener los datos (Namenode) estar\u00e1 en nodo1 (la m\u00e1quina donde me encuentro, puerto 9000)</p> <pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;/name&gt;\n        &lt;value&gt;hdfs://HOSTNAME:9000&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"UD02/1.instalacion/#hdfs-sitexml","title":"hdfs-site.xml","text":"<p><code>dfs.replication</code> \u2192 Por defecto cada bloque se replica 3 veces, como tenemos 1 nodo, indicamos que solo hay 1 nodo que no replique.</p> <p><code>dfs.namenode.name.dir</code>\u2192 D\u00f3nde se encuentra la informaci\u00f3n del maestro (los metadatos que guarda el maestro). Solo se indica en los clusters \u201cmaestro\u201d, pero como estamos haciendo un cluster pseudodistribuido lo indicamos.</p> <p><code>dfs.datanode.data.dir</code>\u2192 En cada esclavo d\u00f3nde se guardan los datos. Solo se indica en los clusters \u201cesclavos\u201d, pero como estamos haciendo un cluster pseudodistribuido lo indicamos.</p> <pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;/name&gt;\n        &lt;value&gt;1&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n        &lt;value&gt;/datos/namenode&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n        &lt;value&gt;/datos/datanode&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"UD02/1.instalacion/#hadoop-envsh","title":"hadoop-env.sh","text":"<pre><code>export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64\n</code></pre>"},{"location":"UD02/1.instalacion/#directorios-y-sistema-de-ficheros","title":"Directorios y sistema de ficheros","text":"<p>Como usuario <code>root</code> 1. Creamos los directorios configurados en el punto anterior <pre><code>/datos/namenode\n/datos/datanode\n</code></pre></p> <ol> <li>Cambiamos el propietario y grupo de /datos a <code>hadoop</code>. <pre><code>$ ls -la /datos\ntotal 16\ndrwxr-xr-x  4 hadoop hadoop 4096 oct 26 08:28 .\ndrwxr-xr-x 19 root   root   4096 oct 26 08:28 ..\ndrwxr-xr-x  2 hadoop hadoop 4096 oct 26 08:28 datanode\ndrwxr-xr-x  2 hadoop hadoop 4096 oct 26 08:28 namenode\n</code></pre></li> </ol> <p>Como usuario <code>hadoop</code></p> <ol> <li>Creamos el sistema de ficheros del namenode (lo crear\u00e1 donde le hemos indicado en el xml). <pre><code># Formateamos el namenode\n$ hdfs namenode -format\n\n# Podemos de ver lo que ha creado...\n$ ls /datos/namenode/*\n</code></pre></li> </ol>"},{"location":"UD02/1.instalacion/#arrancamos-hdfs","title":"Arrancamos HDFS","text":"<p>Hadoop</p> <p>Hadoop tiene dos partes: DATOS y PROCESOS, actualmente estamos trabajando en la parte de DATOS.</p> <p>Arrancamos los procesos de HDFS. Debe arrancar el NAMENODE, el SECONDARY NAMENODE y el DATANODE.</p> <p>Vamos a la carpeta <code>sbin</code> dentro de hadoop. <pre><code>$ cd /opt/hadoop/sbin/\n$ start-dfs.sh\n# 1. Arranca namenode\n# 2. Arranca datanode\n# 3. Arranca secondarynamenode\n</code></pre></p> <p>ERROR 1</p> <p>$ start-dfs.sh Starting namenodes on [localhost] localhost: hadoop@localhost: Permission denied (publickey,password). Starting datanodes localhost: hadoop@localhost: Permission denied (publickey,password). Starting secondary namenodes [hadoopcasa] hadoopcasa: hadoop@hadoopcasa: Permission denied (publickey,password).</p> <p>SOLUCI\u00d3N: El problema es que el usuario hadoop no puede loguearse sin password: Como usuario <code>hadoop</code> : cd ssh-keygen -t rsa cd .ssh cat id_rsa.pub &gt;&gt; authorized_keys</p> <p>ERROR 2</p> <p>$ start-dfs.sh Starting namenodes on [localhost] localhost: ERROR: JAVA_HOME is not set and could not be found. Starting datanodes localhost: ERROR: JAVA_HOME is not set and could not be found. Starting secondary namenodes [hadoopcasa] hadoopcasa: ERROR: JAVA_HOME is not set and could not be found.</p> <p>SOLUCI\u00d3N: No has modificado el archivo hadoop-env.sh tal y como se indicaba anteriormente. La variable JAVA_HOME la hab\u00edamos definido ya en .bashrc, tambi\u00e9n se ha de definir en hadoop-env.sh</p> <p>Una vez arrancado hadoop correctamente, vamos a ver los procesos que ha creado.</p> <p>Dentro de las JDK de java, tenemos un comando para ver los procesos java en ejecuci\u00f3n:</p> <pre><code>$ jps\n3218 DataNode\n3143 NameNode\n3592 Jps\n3485 SecondaryNameNode\n\n# Tambi\u00e9n podemos utilizar\n$ ps -fe | grep java\n</code></pre> <p>Comprobamos las carpetas de datos</p> <pre><code>$ ls /datos/namenode/\ncurrent  in_use.lock\n\n# Ahora esta carpeta ya tiene datos\n$ ls -a /datos/datanode/\n.  ..  current  in_use.lock\n</code></pre> <p>Para acceder a la administraci\u00f3n HDFS via web se utilizan 2 puertos: * 50070 -&gt; Hadoop 2 (versiones anteriores de hadoop) * 9870 -&gt; Hadoop 3, versi\u00f3n actual.</p> <p>Por lo que podemos acceder a la web de administraci\u00f3n desde: http://HOSTNAME_O_IP:PUERTO http://192.168.64.14:9870/</p> <p>Una vez en la web de administraci\u00f3n, pesta\u00f1a DATANODES podemos acceder a un determinado nodo, en nuestro caso al ser un cluster pseudodistribuido solamente tenemos un nodo. http://debianh:9864/ \u2192 Menos opciones ya que accedemos a un nodo determinado</p> <p> </p>"},{"location":"UD02/1.instalacion/#3-trabajar-con-hfs","title":"3. Trabajar con HFS","text":"<p>En <code>/datos/namenode/current</code> hay 3 tipos de ficheros: <pre><code>-rw-r--r-- 1 hadoop hadoop      42 oct 26 09:09 edits_0000000000000000001-0000000000000000002\n-rw-r--r-- 1 hadoop hadoop      42 oct 26 10:09 edits_0000000000000000003-0000000000000000004\n-rw-r--r-- 1 hadoop hadoop      42 oct 26 12:34 edits_0000000000000000005-0000000000000000006\n-rw-r--r-- 1 hadoop hadoop 1048576 oct 26 12:34 edits_inprogress_0000000000000000007\n-rw-r--r-- 1 hadoop hadoop     401 oct 26 10:09 fsimage_0000000000000000004\n-rw-r--r-- 1 hadoop hadoop      62 oct 26 10:09 fsimage_0000000000000000004.md5\n-rw-r--r-- 1 hadoop hadoop     401 oct 26 12:34 fsimage_0000000000000000006\n-rw-r--r-- 1 hadoop hadoop      62 oct 26 12:34 fsimage_0000000000000000006.md5\n-rw-r--r-- 1 hadoop hadoop       2 oct 26 12:34 seen_txid\n-rw-r--r-- 1 hadoop hadoop     214 oct 26 08:35 VERSION\n</code></pre></p> <pre><code>$ cat VERSION\n#Thu Oct 26 08:35:28 CEST 2023\nnamespaceID=623528578\nblockpoolID=BP-1493409649-127.0.1.1-1698302128453\nstorageType=NAME_NODE\ncTime=1698302128453\nclusterID=CID-ca9bde81-b05d-4fcc-8c4c-b54887eada3b\nlayoutVersion=-66\n</code></pre> <p>Si paramos el cluster con <code>stop-dfs.sh</code> y lo volvemos a arrancar los n\u00fameros en los nombres de ficheros incrementan.</p> <ul> <li>edits_: cambios dentro de la base de datos de HDFS.</li> <li>edits_inprogress_: lo que se est\u00e1 escribiendo en este momento.</li> <li>fsimage_: copia \u201cfoto\u201d, de un momento en el tiempo del sistema de ficheros.</li> <li> <p>Fichero VERSION</p> <ul> <li> <p><code>namespaceID</code>: identificador \u00fanico para el sistema de archivos HDFS en un cl\u00faster. Este identificador se utiliza para distinguir entre diferentes instancias del sistema de archivos HDFS en cl\u00fasteres distintos. Cada cl\u00faster de Hadoop debe tener un <code>namespaceID</code> \u00fanico para evitar conflictos. Si clonas o replica un cl\u00faster Hadoop, es importante que el <code>namespaceID</code> sea diferente en cada cl\u00faster para que no haya confusiones.</p> </li> <li> <p><code>blockpoolID</code>: identificador \u00fanico para el \"block pool\" en HDFS. El \"block pool\" es una colecci\u00f3n de bloques de datos que se utilizan para almacenar los datos de los archivos en HDFS. Cada \"block pool\" tiene su propio <code>blockpoolID</code>, que se utiliza para diferenciar entre m\u00faltiples \"block pools\" en el mismo cl\u00faster. Esto es importante para la escalabilidad y la administraci\u00f3n de bloques en el sistema de archivos.</p> </li> <li> <p><code>clusterID</code>: identificador \u00fanico para el cl\u00faster Hadoop. Este valor se utiliza para identificar un cl\u00faster espec\u00edfico y es importante para asegurarse de que los nodos del cl\u00faster se est\u00e9n conectando al cl\u00faster correcto. El <code>clusterID</code> es necesario para garantizar que no haya problemas de conexi\u00f3n entre nodos cuando hay varios cl\u00fasteres en la misma red o en escenarios de recuperaci\u00f3n de desastres.</p> </li> </ul> </li> </ul>"},{"location":"UD02/1.instalacion/#otros-errores","title":"Otros errores","text":"<ol> <li> <p>Permission denied: user=dr.who, access=WRITE, inode=\"/\":hadoop:supergroup:drwxr-xr-x </p> </li> <li> <p>Error en el sistema de ficheros HDFS, podemos utilizar fsck</p> </li> </ol> <p>En el log de datanode: <code>$ tail -f logs/hadoop-hadoop-datanode-debianh.log</code></p> <p>2023-10-26 18:24:38,407 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool (Datanode Uuid 6dfbb007-34b1-4a07-a045-274aad0e2936) service to debianh/127.0.1.1:9000. Exiting.</p> <pre><code>$ hdfs fsck / -includeSnapshots\n# Borramos la carpeta current del namenode\n$ rm -rf /datos/datanode/current\n\n# Iniciamos datenode unicamente\n$ hdfs --daemon start datanode\n\n$ jps\n2688 NameNode\n3486 DataNode\n3582 Jps\n\n# Cuando ya no caiga DataNode\n$ start-all.sh\n</code></pre> <ol> <li>Eliminar los warnings Error: WARN util.NativeCodeLoader</li> </ol> <p></p> <p>No encuentra librer\u00edas nativas, no importa, es un warning (podr\u00eda ir m\u00e1s lento debido a este error)</p> <p>Para eliminar el warning hay que a\u00f1adir en .bashrc</p> <pre><code>export HADOOP_HOME_WARN_SUPRESS=1\nexport HADOOP_ROOT_LOGGER=\"WARN,DRFA\"\n</code></pre>"},{"location":"UD02/2.comandosHDFS/","title":"UD02 2. Comandos HDFS","text":"<p>ATENCI\u00d3N</p> <p>Hay que asegurarse que est\u00e1 arrancado HDFS</p> <p>Mostramos todas las opciones posibles del comando hdfs dfs</p> <pre><code>$ hdfs dfs #Muestra todos los comandos posibles (**emula comandos linux**)\n# El comando hdfs se encuentra dentro de /opt/hadoop/bin\n</code></pre> <ul> <li> <p>Salida del comando</p> <pre><code>Usage: hadoop fs [generic options]\n    [-appendToFile [-n] &lt;localsrc&gt; ... &lt;dst&gt;]\n    [-cat [-ignoreCrc] &lt;src&gt; ...]\n    [-checksum [-v] &lt;src&gt; ...]\n    [-chgrp [-R] GROUP PATH...]\n    [-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]\n    [-chown [-R] [OWNER][:[GROUP]] PATH...]\n    [-concat &lt;target path&gt; &lt;src path&gt; &lt;src path&gt; ...]\n    [-copyFromLocal [-f] [-p] [-l] [-d] [-t &lt;thread count&gt;] [-q &lt;thread pool queue size&gt;] &lt;localsrc&gt; ... &lt;dst&gt;]\n    [-copyToLocal [-f] [-p] [-crc] [-ignoreCrc] [-t &lt;thread count&gt;] [-q &lt;thread pool queue size&gt;] &lt;src&gt; ... &lt;localdst&gt;]\n    [-count [-q] [-h] [-v] [-t [&lt;storage type&gt;]] [-u] [-x] [-e] [-s] &lt;path&gt; ...]\n    [-cp [-f] [-p | -p[topax]] [-d] [-t &lt;thread count&gt;] [-q &lt;thread pool queue size&gt;] &lt;src&gt; ... &lt;dst&gt;]\n    [-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]\n    [-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]\n    [-df [-h] [&lt;path&gt; ...]]\n    [-du [-s] [-h] [-v] [-x] &lt;path&gt; ...]\n    [-expunge [-immediate] [-fs &lt;path&gt;]]\n    [-find &lt;path&gt; ... &lt;expression&gt; ...]\n    [-get [-f] [-p] [-crc] [-ignoreCrc] [-t &lt;thread count&gt;] [-q &lt;thread pool queue size&gt;] &lt;src&gt; ... &lt;localdst&gt;]\n    [-getfacl [-R] &lt;path&gt;]\n    [-getfattr [-R] {-n name | -d} [-e en] &lt;path&gt;]\n    [-getmerge [-nl] [-skip-empty-file] &lt;src&gt; &lt;localdst&gt;]\n    [-head &lt;file&gt;]\n    [-help [cmd ...]]\n    [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [&lt;path&gt; ...]]\n    [-mkdir [-p] &lt;path&gt; ...]\n    [-moveFromLocal [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]\n    [-moveToLocal &lt;src&gt; &lt;localdst&gt;]\n    [-mv &lt;src&gt; ... &lt;dst&gt;]\n    [-put [-f] [-p] [-l] [-d] [-t &lt;thread count&gt;] [-q &lt;thread pool queue size&gt;] &lt;localsrc&gt; ... &lt;dst&gt;]\n    [-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]\n    [-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ...]\n    [-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]\n    [-setfacl [-R] [{-b|-k} {-m|-x &lt;acl_spec&gt;} &lt;path&gt;]|[--set &lt;acl_spec&gt; &lt;path&gt;]]\n    [-setfattr {-n name [-v value] | -x name} &lt;path&gt;]\n    [-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]\n    [-stat [format] &lt;path&gt; ...]\n    [-tail [-f] [-s &lt;sleep interval&gt;] &lt;file&gt;]\n    [-test -[defswrz] &lt;path&gt;]\n    [-text [-ignoreCrc] &lt;src&gt; ...]\n    [-touch [-a] [-m] [-t TIMESTAMP (yyyyMMdd:HHmmss) ] [-c] &lt;path&gt; ...]\n    [-touchz &lt;path&gt; ...]\n    [-truncate [-w] &lt;length&gt; &lt;path&gt; ...]\n    [-usage [cmd ...]]\n\nGeneric options supported are:\n-conf &lt;configuration file&gt;        specify an application configuration file\n-D &lt;property=value&gt;               define a value for a given property\n-fs &lt;file:///|hdfs://namenode:port&gt; specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\n-jt &lt;local|resourcemanager:port&gt;  specify a ResourceManager\n-files &lt;file1,...&gt;                specify a comma-separated list of files to be copied to the map reduce cluster\n-libjars &lt;jar1,...&gt;               specify a comma-separated list of jar files to be included in the classpath\n-archives &lt;archive1,...&gt;          specify a comma-separated list of archives to be unarchived on the compute machines\n\nThe general command line syntax is:\ncommand [genericOptions] [commandOptions]\n</code></pre> </li> </ul> <p>Visualizamos el contenido actual del sistema de ficheros HDFS.</p> <pre><code>$ hdfs dfs -ls /\n</code></pre> <p>Ejercicio 1: - Crear un fichero simple en local (prueba.txt). - Crear un directorio en el sistema de ficheros DFS (temporal) - Copiar el archivo que hemos creado al directorio remoto.</p> <ul> <li>Soluci\u00f3n <pre><code>$ echo \"Hola\" &gt; prueba.txt\n$ hdfs dfs -mkdir /temporal\n$ hdfs dfs -ls /\n# Subimos un fichero de nuestro sistema a HDFS\n$ hdfs dfs -put prueba.txt /temporal \n$ hdfs dfs -ls /\n</code></pre></li> </ul> <p>Desde el explorador la web de administraci\u00f3n, podemos ver informaci\u00f3n del archivo y bloques. </p> <p>Nos fijamos en <code>Bloock ID</code>  y <code>Bloock Pool</code></p> <p>\u00bfC\u00f3mo hacerlo a trav\u00e9s de un comando?</p> <pre><code>$ hdfs fsck /hola.txt -files -blocks\n\nConnecting to namenode via http://debianh:9870/fsck?ugi=hadoop&amp;files=1&amp;blocks=1&amp;path=%2Fhola.txt\n    FSCK started by hadoop (auth:SIMPLE) from /127.0.0.1 for path /hola.txt at Mon Nov 06 14:08:52 CET 2023\n\n/hola.txt 5 bytes, replicated: replication=1, 1 block(s):  OK\n 0. **BP-673766993-127.0.1.1-1698337131957**:blk_**1073741825**_1001 len=5 Live_repl=1\n</code></pre> <p>Ahora vamos a comprobar c\u00f3mo HDFS ha guardado el archivo en local. Para ello vamos a: <pre><code>$ cd /datos/datanode/current\n</code></pre></p> <p>Encontraremos una carpeta con el mismo nombre que el <code>Bloock Pool</code>, en mi caso entrar\u00e9 con:</p> <pre><code>cd BP-673766993-127.0.1.1-1698337131957\n# Accedemos a sus subdirectorios\ncd current/finalized/subdir0/subdir0/ \n</code></pre> <p>En este momento podremos ver el bloque que debe encajar con el <code>Block ID</code></p> <pre><code>$ ls\nblk_1073741825\n\n$ cat blk_1073741825\nhola\n</code></pre>"},{"location":"UD02/8.clusterdocker/","title":"Cluster pseudodistribuido en docker","text":"<p>NO DISPONIBLE</p> <p>Contenido pendiente de finalizar y revisar</p>"},{"location":"UD02/8.clusterdocker/#opcion-1","title":"Opci\u00f3n 1","text":"<pre><code>docker run -ti -p 8042 -p 8088 -p 19888 -p 50070 -p 50075 harisekhon/hadoop\n</code></pre>"},{"location":"UD02/8.clusterdocker/#revisar-1","title":"Revisar 1","text":"<p>https://medium.com/@bayuadiwibowo/deploying-a-big-data-ecosystem-dockerized-hadoop-spark-hive-and-zeppelin-654014069c82</p>"},{"location":"UD02/8.clusterdocker/#revisar-2","title":"Revisar 2","text":"<p>https://www.writecode.es/2019-02-25-cluster_hadoop_docker/</p> <p>Danger</p> <p>SIN TERMINAR</p> <ul> <li>Lo vamos a hacer sobre debian 11 slim (debian 11 tiene java 11, debian 12 java 17).</li> <li>Creamos una carpeta para preparar la imagen y all\u00ed creamos el archivo Dockerfile.</li> </ul>"},{"location":"UD02/8.clusterdocker/#creacion-imagen-debian-11","title":"Creaci\u00f3n imagen debian 11","text":"<pre><code>#En una pesta\u00f1a del terminal corremos un contenedor con debian 11 slim para ir probando los comandos\n\n#Indico la plataforma porque estoy con macos m1\n\n## Hago un pull\ndocker pull --platform linux/amd64 debian:11-slim\n## Y despu\u00e9s un run\ndocker run --platform linux/amd64 -it debian:11-slim\n</code></pre> <p>En otra pesta\u00f1a nos ponemos con el Dockerfile, creamos el archivo con el siguiente contenido, por el momento una debian 11, con locales en espa\u00f1ol, actualizada y con algunos paquetes instalados</p> <pre><code>FROM debian:11-slim\n\n# Configuraci\u00f3n de entorno\nENV LANG=es_ES.UTF-8 \\\n    LANGUAGE=es_ES:es \\\n    LC_ALL=es_ES.UTF-8\n\n# Instalaci\u00f3n de dependencias\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    locales openjdk-11-jdk net-tools curl netcat gnupg libsnappy-dev vim \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/* \\\n    &amp;&amp; localedef -i es_ES -c -f UTF-8 -A /usr/share/locale/locale.alias es_ES.UTF-8\n</code></pre> <p>Podemos hacer un build del Dockerfile que tenemos para ver c\u00f3mo va quedando:</p> <pre><code>docker build -t hadoop-base-image --platform linux/amd64 .\n</code></pre> <p>Ya tenemos una imagen creada seg\u00fan el Dockerfile</p> <pre><code>docker image ls\n\nREPOSITORY                     TAG       IMAGE ID       CREATED          SIZE\nhadoop-base-image              latest    4bfe812532fc   6 minutes ago    668MB\n</code></pre> <p>Podemos \"arrancarla\", en modo interactivo (-it), cuando salimos se borra lo que hemos hecho <pre><code>docker run --platform linux/amd64 -it hadoop-base-image\n</code></pre></p>"},{"location":"UD02/8.clusterdocker/#descarga-e-instalacion-hadoop","title":"Descarga e instalaci\u00f3n hadoop","text":"<p>Modificamos Dockerfile con:</p> <pre><code>FROM debian:11-slim\n\n# Configuraci\u00f3n de entorno\nENV LANG=es_ES.UTF-8 \\\n    LANGUAGE=es_ES:es \\\n    LC_ALL=es_ES.UTF-8 \\\n    HADOOP_VERSION=3.4.0 \\\n    HADOOP_HOME=/opt/hadoop\n\n# Instalaci\u00f3n de dependencias\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    locales openjdk-11-jdk net-tools curl netcat gnupg libsnappy-dev vim \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/* \\\n    &amp;&amp; localedef -i es_ES -c -f UTF-8 -A /usr/share/locale/locale.alias es_ES.UTF-8\n\n# Descarga e instalaci\u00f3n de Hadoop\n# No hacemos ning\u00fan enlace, nos descargamos hadoop\n# lo descomprimimos en OPT y renombramos a hadoop\nRUN curl -O https://downloads.apache.org/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz &amp;&amp; \\\n    tar -xzf hadoop-${HADOOP_VERSION}.tar.gz -C /opt/ &amp;&amp; \\\n    mv /opt/hadoop-${HADOOP_VERSION} $HADOOP_HOME &amp;&amp; \\\n    rm hadoop-${HADOOP_VERSION}.tar.gz\n\n\n# Configuraci\u00f3n de variables de entorno para Hadoop y Java\nENV PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin \\\n    JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64\n\n# Configuraci\u00f3n b\u00e1sica de Hadoop (core-site.xml y hdfs-site.xml)\nRUN echo '&lt;?xml version=\"1.0\"?&gt; \\\n    &lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt; \\\n    &lt;configuration&gt; \\\n        &lt;property&gt; \\\n            &lt;name&gt;fs.defaultFS&lt;/name&gt; \\\n            &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; \\\n        &lt;/property&gt; \\\n    &lt;/configuration&gt;' &gt; $HADOOP_HOME/etc/hadoop/core-site.xml &amp;&amp; \\\n    echo '&lt;?xml version=\"1.0\"?&gt; \\\n    &lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt; \\\n    &lt;configuration&gt; \\\n        &lt;property&gt; \\\n            &lt;name&gt;dfs.replication&lt;/name&gt; \\\n            &lt;value&gt;1&lt;/value&gt; \\\n        &lt;/property&gt; \\\n    &lt;/configuration&gt;' &gt; $HADOOP_HOME/etc/hadoop/hdfs-site.xml\n\n# Crear directorios de Hadoop necesarios para almacenamiento de datos\nRUN mkdir -p /opt/hadoop/hdfs/namenode &amp;&amp; \\\n    mkdir -p /opt/hadoop/hdfs/datanode\n\n# Configuraci\u00f3n del puerto para Hadoop (en caso de necesitar mapear)\nEXPOSE 9870 9000\n\n# Comando de inicio para HDFS\nCMD [\"bash\"]\n</code></pre> <p>Reconstruimos de nuevo la imagen: <pre><code>docker build -t hadoop-base-image --platform linux/amd64 .\n</code></pre></p> <p>Y la levantamos: <pre><code>docker run --platform linux/amd64 -it hadoop-base-image\n</code></pre></p> <p>Y devuelve el siguiente error: <pre><code>/************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at facb9e116dc3/192.168.215.2\n************************************************************/\nIniciando HDFS...\nStarting namenodes on [localhost]\nERROR: Attempting to operate on hdfs namenode as root\nERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.\nStarting datanodes\nERROR: Attempting to operate on hdfs datanode as root\nERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.\nStarting secondary namenodes [facb9e116dc3]\nERROR: Attempting to operate on hdfs secondarynamenode as root\nERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.\n</code></pre></p>"},{"location":"UD02/8.clusterdocker/#ultima-correccion","title":"\u00daltima correcci\u00f3n","text":"<p>Este error ocurre porque Hadoop no est\u00e1 dise\u00f1ado para ejecutarse como root y necesita usuarios espec\u00edficos definidos para ejecutar los procesos de namenode, datanode, y secondarynamenode.</p> <p>Para solucionarlo, puedes crear un usuario no-root en el Dockerfile y configurar las variables de entorno: HDFS_NAMENODE_USER HDFS_DATANODE_USER HDFS_SECONDARYNAMENODE_USER</p> <pre><code>FROM debian:11-slim\n\nENV LANG=es_ES.UTF-8 \\\n    LANGUAGE=es_ES:es \\\n    LC_ALL=es_ES.UTF-8 \\\n    HADOOP_VERSION=3.4.0 \\\n    HADOOP_HOME=/opt/hadoop \\\n    HDFS_NAMENODE_USER=hadoop \\\n    HDFS_DATANODE_USER=hadoop \\\n    HDFS_SECONDARYNAMENODE_USER=hadoop\n\n# Instalaci\u00f3n de dependencias\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    locales openjdk-11-jdk net-tools curl netcat-openbsd gnupg libsnappy-dev vim openssh-client openssh-server \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/* \\\n    &amp;&amp; localedef -i es_ES -c -f UTF-8 -A /usr/share/locale/locale.alias es_ES.UTF-8\n\n# Crear usuario no-root para Hadoop\nRUN useradd -m hadoop\n\n# Descargar e instalar Hadoop\nRUN curl -O https://downloads.apache.org/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz &amp;&amp; \\\n    tar -xzf hadoop-${HADOOP_VERSION}.tar.gz -C /opt/ &amp;&amp; \\\n    mv /opt/hadoop-${HADOOP_VERSION} $HADOOP_HOME &amp;&amp; \\\n    rm hadoop-${HADOOP_VERSION}.tar.gz &amp;&amp; \\\n    chown -R hadoop:hadoop $HADOOP_HOME\n\n# Configuraci\u00f3n de variables de entorno para Hadoop y Java\nENV PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin \\\n    JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64\n\n# Configuraci\u00f3n b\u00e1sica de Hadoop\nRUN echo '&lt;?xml version=\"1.0\"?&gt; \\\n    &lt;configuration&gt; \\\n        &lt;property&gt; \\\n            &lt;name&gt;fs.defaultFS&lt;/name&gt; \\\n            &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; \\\n        &lt;/property&gt; \\\n    &lt;/configuration&gt;' &gt; $HADOOP_HOME/etc/hadoop/core-site.xml &amp;&amp; \\\n    echo '&lt;?xml version=\"1.0\"?&gt; \\\n    &lt;configuration&gt; \\\n        &lt;property&gt; \\\n            &lt;name&gt;dfs.replication&lt;/name&gt; \\\n            &lt;value&gt;1&lt;/value&gt; \\\n        &lt;/property&gt; \\\n    &lt;/configuration&gt;' &gt; $HADOOP_HOME/etc/hadoop/hdfs-site.xml\n\n# Crear directorios de Hadoop necesarios y asignar permisos al usuario\nRUN mkdir -p /opt/hadoop/hdfs/namenode &amp;&amp; \\\n    mkdir -p /opt/hadoop/hdfs/datanode &amp;&amp; \\\n    chown -R hadoop:hadoop /opt/hadoop/hdfs\n\n# Configurar SSH para que funcione sin clave en localhost\nRUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -N '' &amp;&amp; \\\n\u00a0 \u00a0 ssh-keygen -t rsa -f /home/hadoop/.ssh/id_rsa -q -N \"\" &amp;&amp; \\\n\u00a0 \u00a0 cat /home/hadoop/.ssh/id_rsa.pub &gt;&gt; /home/hadoop/.ssh/authorized_keys &amp;&amp; \\\n\u00a0 \u00a0 chmod 600 /home/hadoop/.ssh/authorized_keys &amp;&amp; \\\n\u00a0 \u00a0 chown -R hadoop:hadoop /home/hadoop/.ssh\n\u00a0 \u00a0 \n# Script de inicio para formateo y arranque\nRUN echo '#!/bin/bash \\n\\\nif [ ! -d \"/opt/hadoop/hdfs/namenode/current\" ]; then \\n\\\n    echo \"Formateando namenode...\" \\n\\\n    $HADOOP_HOME/bin/hdfs namenode -format \\n\\\nfi \\n\\\necho \"Iniciando HDFS...\" \\n\\\n$HADOOP_HOME/sbin/start-dfs.sh \\n\\\ntail -f /dev/null' &gt; /opt/start-hadoop.sh &amp;&amp; chmod +x /opt/start-hadoop.sh\n\n# Cambiar al usuario hadoop\nUSER hadoop\n\n# Establecer script de inicio\nCMD [\"/opt/start-hadoop.sh\"]\n</code></pre> <p>Reconstruimos la imagen y la levantamos: <pre><code>docker build -t hadoop-base-image --platform linux/amd64 .\n</code></pre></p>"},{"location":"UD02/9.ejercicio1_wordcount/","title":"El quijote","text":"<p>https://medium.com/@guillermovc/setting-up-hadoop-with-docker-and-using-mapreduce-framework-c1cd125d4f7b</p> <p>https://www.geeksforgeeks.org/generating-word-cloud-python/</p>"},{"location":"UD02/_TODO/","title":"TODO","text":"<p>https://princetonits.com/blog/technology/how-to-configure-replication-factor-and-block-size-for-hdfs/</p>"},{"location":"UD02/_TODO/#integridad-ficheros","title":"Integridad ficheros","text":""},{"location":"UD02/_TODO/#api","title":"API","text":"<p>https://hadoop.apache.org/docs/r1.0.4/webhdfs.html</p> <p>https://hevodata.com/learn/webhdfs/</p>"},{"location":"UD02/_TODO/#dataset-demo","title":"Dataset demo","text":"<p>If you have trouble downloading the ml-100k data set from grouplens.org, use this download location instead:</p> <p>http://media.sundog-soft.com/es/ml-100k.zip</p> <p>Instalar dataset a trav\u00e9s de la l\u00ednea de comandos:</p> <p>https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5951204#content</p> <p>*Cap\u00edtulo anterior, instalar a trav\u00e9s de Hortonworks</p>"},{"location":"UD02/_PENDENT/UD02%203%20Checkpoint%2C%20fsimage%20y%20edits%20128e913de6c48145920bef840eb92c25/","title":"UD02 3. Checkpoint, fsimage y edits","text":"<p>Vamos a realizar un primer trabajo de mantenimiento, la creaci\u00f3n de un checkpoint.</p> <p>El comando <code>hdfs dfsadmin -saveNamespace</code> en Hadoop se utiliza para realizar una operaci\u00f3n de \"checkpoint\" manual en el sistema de archivos distribuido Hadoop HDFS (Hadoop Distributed File System). Un \"checkpoint\" es un proceso en el que se guarda una copia de los metadatos del sistema de archivos, lo que incluye informaci\u00f3n sobre la estructura del sistema de archivos, la ubicaci\u00f3n de los bloques de datos y otra informaci\u00f3n cr\u00edtica. Esta operaci\u00f3n se utiliza generalmente en situaciones en las que se quiere crear una copia de respaldo de los metadatos del sistema de archivos, por ejemplo, como parte de un procedimiento de respaldo regular o antes de realizar cambios importantes en el cl\u00faster Hadoop.</p> <ul> <li>Algunas situaciones en las que se utiliza:<ol> <li>Realizar respaldos: Antes de realizar una actualizaci\u00f3n importante del cl\u00faster Hadoop o de aplicar cambios cr\u00edticos en los datos, puedes ejecutar esta operaci\u00f3n para asegurarte de que tienes una copia de seguridad actualizada de los metadatos del sistema de archivos.</li> <li>Recuperaci\u00f3n de desastres: En caso de un fallo cr\u00edtico en el sistema de archivos o p\u00e9rdida de metadatos, puedes utilizar un checkpoint guardado con <code>hdfs dfsadmin -saveNamespace</code> para restaurar los metadatos del sistema de archivos.</li> <li>Migraci\u00f3n de datos: Al migrar datos a un nuevo cl\u00faster Hadoop, puedes usar esta operaci\u00f3n para crear una copia de seguridad de los metadatos antes de la migraci\u00f3n.</li> </ol> </li> </ul> <p>Pasos a seguir:</p> <ol> <li>Arrancamos dfs</li> <li>Nos aseguramos que est\u00e9n en marcha los procesos una vez termine el proceso de arranque</li> <li>Accedemos a la carpeta de datos del namenode y comprobamos el contenido del directorio current.</li> <li>Comprobamos el contenido del fichero de VERSION</li> <li>Vamos a realizar un checkpoint manual (sincronizar el sistema de ficheros), para esto:<ol> <li>Entramos en modo seguro <code>hdfs dfsadmin -safemode enter</code></li> <li>Revisamos en la interfaz web que estemos en modo seguro realmente.</li> <li>Tambi\u00e9n se puede comprobar con un <code>hdfs dfsadmin -safemode get</code></li> <li>Realizamos un checkpoint <code>hdfs dfsadmin -saveNamespace</code></li> <li>Volvemos a entrar a modo normal <code>hdfs dfsadmin -safemode leave</code></li> </ol> </li> <li>Comprobamos el archivo de logs de hadoop <code>hadoop-hadoop-namenode-debianh.log</code></li> <li> <p>\u00bfD\u00f3nde ha guardado el checkpoint? <code>hdfs getconf -confKey dfs.namenode.checkpoint.dir</code></p> </li> <li> <p>Sol</p> <pre><code>1. start-dfs.sh\n2. jps\n    769 SecondaryNameNode\n    965 Jps\n    631 DataNode\n    553 NameNode\n3. /datos/namenode/current$ ls\nedits_0000000000000000001-0000000000000000007  edits_0000000000000000049-0000000000000000050\nedits_0000000000000000008-0000000000000000008  edits_0000000000000000051-0000000000000000051\nedits_0000000000000000009-0000000000000000009  edits_0000000000000000052-0000000000000000053\nedits_0000000000000000010-0000000000000000010  edits_0000000000000000054-0000000000000000054\nedits_0000000000000000011-0000000000000000011  edits_0000000000000000055-0000000000000000055\nedits_0000000000000000012-0000000000000000014  edits_inprogress_0000000000000000056\nedits_0000000000000000015-0000000000000000016  fsimage_0000000000000000054\nedits_0000000000000000017-0000000000000000017  fsimage_0000000000000000054.md5\nedits_0000000000000000018-0000000000000000018  fsimage_0000000000000000055\nedits_0000000000000000019-0000000000000000019  fsimage_0000000000000000055.md5\nedits_0000000000000000020-0000000000000000030  seen_txid\nedits_0000000000000000031-0000000000000000048  VERSION \n</code></pre> </li> </ol>"},{"location":"UD02/_PENDENT/UD02%204%20Comandos%20HDFS%20-%20Ejercicios%20128e913de6c481bea255c9faaaf5a970/","title":"UD02 4. Comandos HDFS - Ejercicios","text":"\u2139\ufe0f **UD02 - Ejercicio cargar fichero de logs:**  1. Descargamos un fichero m\u00e1s grande (access_log.gz ) 2. Lo descomprimimos. Quedar\u00e1 un archivo de 482mb. 3. Lo movemos a HDFS, dentro la carpeta /temporal 4. Comprobamos en cuantos bloques se encuentra. 5. \u00bfA qu\u00e9 archivos apunta en la m\u00e1quina virtual?   \u2139\ufe0f **UD02 - Ejercicios 2**  1. Crea un fichero \u201csaludo.txt\u201d en local, que contenga el texto \u201cHola\u201d.      S\u00fabelo a HDFS, a la carpeta /temporal (si no existe hay que crearla)      Borra el fichero en local      Muestra el contenido del fichero (en remoto).  2. Copia el fichero saludo.txt a local con el nombre (saludolocal.txt) 3. Entra a la web de administraci\u00f3n para ver que existe el fichero. 4. Borra el fichero remoto. 5. Aseg\u00farate que se ha borrado el fichero con ls. 6. Borra el directorio temporal.  <ul> <li> <p>Sol</p> <pre><code>$ hdfs dfs -cat /temporal/prueba.txt\n$ hdfs dfs -get /temporal/prueba.txt /tmp/borrar.txt\n$ hdfs dfs -mkdir directorio1\n$ hdfs dfs -rm /temporal/prueba.txt\n</code></pre> </li> </ul>  \u2139\ufe0f **UD02 - Ejercicios 3**  1. Crea un fichero \u201cotrosaludo.txt\u201d en local, que contenga el texto \u201cHola\u201d.      **MU\u00c9VELO** a HDFS, dentro de la carpeta /ejercicios/saludos/      Comprueba que ya no existe el fichero en local  2. Crea un directorio en local llamado prueba      Dentro de este directorio crea un fichero llamado ejercicioprueba.txt      Mueve todo el directorio prueba a HDFS, dentro de la carpeta /ejercicios      Comprueba que ya no existe la carpeta en local      Realiza una copia de HDFS a local de la carpeta que acabas de subir.   <ul> <li> <p>Sol</p> <pre><code># Move file / Folder from Local disk to HDFS\n$ hdfs dfs -moveFromLocal /local-file-path /hdfs-file-path\n# Copy\n$ hdfs dfs -copyFromLocal  /hdfs-file-path /local-file-path\n\n# Move a File to HDFS from Local\n$ hdfs dfs -moveToLocal /hdfs-file-path /local-file-path\n# Copy\n$ hdfs dfs -copyToLocal  /hdfs-file-path /local-file-path\n</code></pre> <p>https://sparkbyexamples.com/apache-hadoop/hadoop-hdfs-dfs-commands-and-starting-hdfs-dfs-services/</p> </li> </ul>  \u2139\ufe0f **UD02 - Ejercicios 4**  1. Crea un archivo en /tmp llamado archivogrande que tenga un tama\u00f1o de 500MB (aproximadamente)       -&gt; comando dd 2. Crea una carpeta en HDFS llamada datos2. 3. Sube el archivo a la carpeta creada.   <ul> <li> <p>Sol</p> <pre><code># Crear archivo de 500Mb\ndd if=/dev/zero of=/tmp/archivogrande bs=1024 count=512k\n\n# Verificar el tama\u00f1o del archivo creado\ndu -sh /tmp/archivogrande\n</code></pre> </li> </ul>"},{"location":"UD02/_PENDENT/UD02%205%20Administracio%CC%81n%20128e913de6c481c99f20e685acd85afb/","title":"UD02 5. Administraci\u00f3n","text":"<p>Con la herramienta <code>dfsadmin</code> podemos examinar el estado del cluster HDFS.</p> <pre><code>$ hdfs dfsadmin\n\n# Ejemplo:\n$ hdfs dfsadmin -safemode enter\n</code></pre> <ul> <li>Opciones dfsadmin<ol> <li>hdfs dfsadmin -report: Resumen completo del sistema HDFS; estado de todos los nodos del cl\u00faster, su capacidad, el espacio utilizado\u2026</li> <li>hdfs fsck: Comprobar la integridad del sistema de archivos HDFS. Para verificar un directorio hay que a\u00f1adirlo como segundo par\u00e1metro. <code>hdfs fsck /datos/prueba</code></li> <li>hdfs dfsadmin -printTopology: Este comando revela la topolog\u00eda del cl\u00faster HDFS. Proporciona informaci\u00f3n sobre la distribuci\u00f3n de nodos y muestra a qu\u00e9 rack pertenece cada nodo.</li> <li>hdfs dfsadmin -listOpenFiles: Una tarea cr\u00edtica en la administraci\u00f3n de HDFS es garantizar que no haya archivos abiertos que puedan causar problemas en el sistema. Este comando lista todos los archivos abiertos en el cl\u00faster, lo que facilita la identificaci\u00f3n y soluci\u00f3n de problemas.</li> <li>hdfs dfsadmin -safemode enter: El modo seguro de HDFS es una caracter\u00edstica importante para prevenir modificaciones accidentales en el sistema de archivos. Al ingresar al modo seguro, se evita la escritura y modificaci\u00f3n de datos en el cl\u00faster. Esto puede ser \u00fatil durante operaciones de mantenimiento o actualizaciones cr\u00edticas.</li> <li>hdfs dfsadmin -safemode leave: Cuando se completa la operaci\u00f3n en modo seguro y se requiere que el sistema vuelva a estar en pleno funcionamiento, se puede salir del modo seguro con este comando.</li> </ol> </li> </ul> <pre><code>**Ejercicios hdfs dfsadmin:**\n\n1. Muestra un resumen de recursos.\n2. Comprueba el estado del sistema de ficheros.\n3. Comprueba el estado del directorio datos2.\n4. Muestra la topolog\u00eda actual.\n# Hadoop es consciente de los racks que tiene la m\u00e1quina (se lo decimos nosotros), \nas\u00ed organiza mejor los bloques (los replica en racks distintos)\n5. \u00bfHay alg\u00fan fichero abierto?\n</code></pre> <ul> <li> <p>Soluciones</p> <pre><code>hdfs dfsadmin -report\n  \"Under replicated blocks\" -&gt; Si configuramos como r\u00e9plica por ejemplo 3 y hay \n    alg\u00fan bloque con menos. Si esto baja de un determinado porcentaje, hadoop se pone\n  en modo seguro porque piensa que hay alg\u00fan problema.\nhdfs fsck /\nhdfs fsck /datos2\nhdfs dfsadmin -printTopology\nhdfs dfsadmin -listOpenFiles\n</code></pre> </li> </ul>"},{"location":"UD02/_PENDENT/UD02%206%20Snapshots%20128e913de6c481c980fae8fd7bdbd980/","title":"UD02 6. Snapshots","text":"\u2139\ufe0f Un snapshot es una \u201cfoto\u201d de un sistema de ficheros en un momento determinado.   <p>Puede ser utilizado para operaciones de: backup, recuperaci\u00f3n, mantener un hist\u00f3rico\u2026</p> <p>En esta pr\u00e1ctica vamos a realizar un snapshot y utilizarlo para recuperar un fichero que hemos borrado accidentalmente.</p> <p>Pasos a seguir:</p> <ol> <li>Creamos un directorio llamado <code>datos</code> dentro de DFS</li> <li>Subimos a ese directorio un fichero llamado <code>f1.txt</code> que contenga \u201cEsto es una prueba\u201d.</li> </ol> <p>Ahora vamos a ver d\u00f3nde ha dejado este fichero:</p> <ul> <li>\u00bfC\u00f3mo se hace desde webdfs?</li> <li>\u00bfC\u00f3mo se hace desde cmd? Utiliza <code>hdfs fsck</code> con las opciones <code>-files -blocks -locations</code></li> </ul> <p></p> <ul> <li> <p>Soluci\u00f3n</p> <p>hdfs fsck /datos/f1.txt -blocks -locations -files</p> </li> <li> <p>Activamos para que se puedan hacer snapshots y realizamos uno</p> </li> </ul> <pre><code>hdfs **dfsadmin** -allowSnapshot /datos\n\nhdfs **dfs** -createSnapshot /datos snap1\n## La creaci\u00f3n del snapshot no se hace con dfsadmin sino con dfs\n\nhdfs dfs -ls /datos/.snapshot/snap1\n## Nos muestra el fichero tal y como estaba cuando hicimos el snap\n</code></pre> <ul> <li>\u00bfEl snapshot aparece en webdfs? Compru\u00e9balo.</li> <li>Borramos el fichero f1.txt en HDFS</li> <li> <p>Sol</p> <p>hdfs dfs -rm /datos/f1.txt</p> </li> </ul> <pre><code># El fichero ya no debe de existir\nhdfs dfs -ls /datos\n</code></pre> <ol> <li>Recuperamos el fichero del snapshot</li> </ol> <pre><code>hadoop fs -cp /datos/.snapshot/snap1/f1.txt /datos/\n## -cp solo hace copias entre HDFS, para \"sacar\" el fichero de HDFS hay que utilizar -get\n\nhdfs dfs -ls /datos\n</code></pre>"},{"location":"UD02/_PENDENT/UD02%207%20Resumen%20instalacio%CC%81n%20hadoop%20128e913de6c481239ebfd71a231c804e/","title":"UD02 7. Resumen instalaci\u00f3n hadoop","text":"<p>https://www.rosehosting.com/blog/how-to-install-hadoop-on-debian-11/</p> <pre><code>#### Conexi\u00f3n con la m\u00e1quina por ssh\nssh root@IP_Address -p Port_number\n\napt update -y\nsudo apt upgrade -y\n\n#### Creaci\u00f3n y configuraci\u00f3n acceso ssh sin password del user hadoop\nuseradd -r hadoop -m -d /opt/hadoop --shell /bin/bash\nsu - hadoop\nssh-keygen -t rsa\ncat ~/.ssh/id_rsa.pub &gt; ~/.ssh/authorized_keys\nssh localhost # Tiene que entrar sin poner el password\nexit\n\n#### Instalamos JAVA desde apt\napt install default-jdk default-jre -y\njava -version\n\n#### Descarga e instalaci\u00f3n de hadoop\nsu - hadoop\nwget https://dlcdn.apache.org/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz -O hadoop-3.2.3.tar.gz\ntar -xzvf hadoop-3.2.3.tar.gz -C /opt/hadoop --strip-components=1\n# Comprobamos donde est\u00e1 instalada la JVM\nls /usr/lib/jvm\n# El directorio de instalaci\u00f3n ser\u00e1 similar a /usr/lib/jvm/java-11-openjdk-amd64\n\n#### A\u00f1adimos variables al .bashrc del user hadoop (su home est\u00e1 en /opt/hadoop)\necho 'export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64\nexport HADOOP_HOME=/opt/hadoop\nexport PATH=$PATH:$HADOOP_HOME/bin\nexport PATH=$PATH:$HADOOP_HOME/sbin\nexport HADOOP_MAPRED_HOME=$HADOOP_HOME\nexport HADOOP_COMMON_HOME=$HADOOP_HOME\nexport HADOOP_HDFS_HOME=$HADOOP_HOME\nexport YARN_HOME=$HADOOP_HOME\nexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native\nexport HADOOP_OPTS=\"-Djava.library.path=$HADOOP_HOME/lib\"' &gt;&gt; /opt/hadoop/.bashrc\n\n# Cargamos el nuevo entorno\nsource /opt/hadoop/.bashrc\n\n#### Configuramos hadoop\n\n#### xxx\n</code></pre>"}]}